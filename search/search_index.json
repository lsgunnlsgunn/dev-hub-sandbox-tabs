{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Substrate Developer Hub provides a centralized location for developer resources and documentation to serve the Substrate developer and chain builder community. Fundamentals First Substrate empowers builders Blockchain basics Choosing a development platform Substrate architecture ... and more Learn by Doing Build a local blockchain Simulate a network Start a trusted validator network Add a module to the runtime ... and more Get Technical Command-line tools FRAME pallets Rust API Polkadot-JS API ... and more","title":"Substrate Developer Hub"},{"location":"#fundamentals-first","text":"Substrate empowers builders Blockchain basics Choosing a development platform Substrate architecture ... and more","title":"Fundamentals First"},{"location":"#learn-by-doing","text":"Build a local blockchain Simulate a network Start a trusted validator network Add a module to the runtime ... and more","title":"Learn by Doing"},{"location":"#get-technical","text":"Command-line tools FRAME pallets Rust API Polkadot-JS API ... and more","title":"Get Technical"},{"location":"quickstart/","text":"Quick start All of the Substrate tutorials and how-to guides require you to run a Substrate node in your development environment. To provide you with a working environment that includes the most common set of features to build a blockchain, the Substrate Developer Hub repository maintains its own snapshot of the Substrate node template . The node template includes everything you need to get started without any of the extraneous modules or tools that you might want to add later. Although you can also compile the node template by cloning files directly the Substrate repository, it isn't recommended because frequent code changes are likely to introduce stability and compatibility issues that cause tutorials or how-to examples to fail. This Quick start assumes that you are setting up a development environment for the first time and want to try out running a single blockchain client\u2014called a node\u2014on your local computer. To keep things simple, you'll connect to the local node using a web browser and look up a balance for a predefined sample account. Before you begin Before you begin, verify the following: You have good internet connection and access to a shell terminal on your local computer. You are generally familiar with software development and using command-line interfaces. You have the Rust compiler and toolchain installed. To check whether you have Rust installed, run the rustup show command. If Rust is installed, this command displays version information for the toolchain and compiler. If Rust is not installed, the command doesn't return any output. For information about installing Rust, see Install Rust and Rust compiler and toolchain . Build the development environment node Clone the node template repository using the latest branch by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-node-template Change to the root of the cloned directory by running the following command: bash cd substrate-node-template Compile the node template using the nightly toolchain by running the following command: bash cargo +nightly build --package node-template --release Because of the number of packages involved, compiling the node can take several minutes. Verify and start the node Verify that your node is ready to use and see information about the command-line options available by running the following command: bash ./target/release/node-template --help The usage information displays the command-line options you can use to: start the node work with accounts modify node operations View account information for the predefined alice account by running the following command: bash ./target/release/node-template key inspect //alice The command displays the following account information: Secret Key URI //alice is account: Secret seed: 0xc166b100911b1e9f780bb66d13badf2c1edbe94a1220f1a0584c09490158be31 Public key (hex): 0xc81ebbec0559a6acf184535eb19da51ed3ed8c4ac65323999482aaf9b6696e27 Account ID: 0xc81ebbec0559a6acf184535eb19da51ed3ed8c4ac65323999482aaf9b6696e27 Public key (SS58): 5Gb6Zfe8K8NSKrkFLCgqs8LUdk7wKweXM5pN296jVqDpdziR SS58 Address: 5Gb6Zfe8K8NSKrkFLCgqs8LUdk7wKweXM5pN296jVqDpdziR Start the node in development mode by running the following command: ./target/release/node-template --dev In development mode, the chain doesn't require any peer computers to finalize blocks. As the node starts, the terminal displays output about the operations performed. If you see messages that blocks are being proposed and finalized, you have a running node. ... Idle (0 peers), best: #3 (0xcc78\u20265cb1), finalized #1 ... ... Starting consensus session on top of parent ... ... Prepared block for proposing at 4 (0 ms) ... Connect to the node Create a simple HTML file with JavaScript to interact with the blockchain. For example, create an index.html file that uses JavaScript and HTML to: take an account address as input look up the account balance using an onClick event display the balance for the account as output. This sample index.html provides a simple example of how to use JavaScript and HTMLto get an account balance. Open the index.html file in a web browser. Copy and paste the SS58 Address for the alice account in the input field, then click Get Balance . Stop the node Go to the terminal that displays blockchain operations. Stop the local blockchain and clear all state by pressing Control-c.","title":"Quick start"},{"location":"quickstart/#quick-start","text":"All of the Substrate tutorials and how-to guides require you to run a Substrate node in your development environment. To provide you with a working environment that includes the most common set of features to build a blockchain, the Substrate Developer Hub repository maintains its own snapshot of the Substrate node template . The node template includes everything you need to get started without any of the extraneous modules or tools that you might want to add later. Although you can also compile the node template by cloning files directly the Substrate repository, it isn't recommended because frequent code changes are likely to introduce stability and compatibility issues that cause tutorials or how-to examples to fail. This Quick start assumes that you are setting up a development environment for the first time and want to try out running a single blockchain client\u2014called a node\u2014on your local computer. To keep things simple, you'll connect to the local node using a web browser and look up a balance for a predefined sample account.","title":"Quick start"},{"location":"quickstart/#before-you-begin","text":"Before you begin, verify the following: You have good internet connection and access to a shell terminal on your local computer. You are generally familiar with software development and using command-line interfaces. You have the Rust compiler and toolchain installed. To check whether you have Rust installed, run the rustup show command. If Rust is installed, this command displays version information for the toolchain and compiler. If Rust is not installed, the command doesn't return any output. For information about installing Rust, see Install Rust and Rust compiler and toolchain .","title":"Before you begin"},{"location":"quickstart/#build-the-development-environment-node","text":"Clone the node template repository using the latest branch by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-node-template Change to the root of the cloned directory by running the following command: bash cd substrate-node-template Compile the node template using the nightly toolchain by running the following command: bash cargo +nightly build --package node-template --release Because of the number of packages involved, compiling the node can take several minutes.","title":"Build the development environment node"},{"location":"quickstart/#verify-and-start-the-node","text":"Verify that your node is ready to use and see information about the command-line options available by running the following command: bash ./target/release/node-template --help The usage information displays the command-line options you can use to: start the node work with accounts modify node operations View account information for the predefined alice account by running the following command: bash ./target/release/node-template key inspect //alice The command displays the following account information: Secret Key URI //alice is account: Secret seed: 0xc166b100911b1e9f780bb66d13badf2c1edbe94a1220f1a0584c09490158be31 Public key (hex): 0xc81ebbec0559a6acf184535eb19da51ed3ed8c4ac65323999482aaf9b6696e27 Account ID: 0xc81ebbec0559a6acf184535eb19da51ed3ed8c4ac65323999482aaf9b6696e27 Public key (SS58): 5Gb6Zfe8K8NSKrkFLCgqs8LUdk7wKweXM5pN296jVqDpdziR SS58 Address: 5Gb6Zfe8K8NSKrkFLCgqs8LUdk7wKweXM5pN296jVqDpdziR Start the node in development mode by running the following command: ./target/release/node-template --dev In development mode, the chain doesn't require any peer computers to finalize blocks. As the node starts, the terminal displays output about the operations performed. If you see messages that blocks are being proposed and finalized, you have a running node. ... Idle (0 peers), best: #3 (0xcc78\u20265cb1), finalized #1 ... ... Starting consensus session on top of parent ... ... Prepared block for proposing at 4 (0 ms) ...","title":"Verify and start the node"},{"location":"quickstart/#connect-to-the-node","text":"Create a simple HTML file with JavaScript to interact with the blockchain. For example, create an index.html file that uses JavaScript and HTML to: take an account address as input look up the account balance using an onClick event display the balance for the account as output. This sample index.html provides a simple example of how to use JavaScript and HTMLto get an account balance. Open the index.html file in a web browser. Copy and paste the SS58 Address for the alice account in the input field, then click Get Balance .","title":"Connect to the node"},{"location":"quickstart/#stop-the-node","text":"Go to the terminal that displays blockchain operations. Stop the local blockchain and clear all state by pressing Control-c.","title":"Stop the node"},{"location":"community/","text":"Thank you for your interest in contributing to documentation for the Substrate development framework. As a member of the community, you are invited and encouraged to contribute by submitting issues, offering suggestions for improvements to existing content, adding review comments to existing pull requests, proposing new content, or creating new pull requests to fix issues or provide new content. We value, respect, and appreciate all contributions from the developer community and only ask that you agree to abide by our Code of conduct and review our Contributor guidelines . To learn more about how to contribute, including guidelines for how to structure content and how to participate in our bounty program that pays you for contributing, see the following topics: Before you contribute Basic workflow for all contributions Contributor guidelines Writing guidelines Bounty program Before you contribute Before contributing, take a few minutes to review the contributor guidelines. The contributor guidelines are intended to make the contribution process easy and effective for everyone involved in addressing your issue, assessing changes, and finalizing your pull requests. Before contributing, consider the following: If you want to report an issue or request help, click Issues . You can also post a message to the community forum , ask a question on StackOverflow , or submit a support request. If you are reporting a bug, provide as much information about the problem as possible, including the version you are using. If you want to contribute directly to this repository, typical fixes might include any of the following: Spelling, grammar, or typo fixes. Code indentation, white space, or formatting changes. Broken or missing links. Note that any contribution to this repository must be submitted in the form of a pull request. If you are creating a pull request, be sure that the pull request only implements one bug fix. If you are new to working with GitHub repositories and creating pull requests, consider exploring First Contributions or How to Contribute to an Open Source Project on GitHub . Basic workflow for all contributions If you want to contribute in this repository, you should follow the recommended workflow and adhere to the best practices described in this section. Following the recommended workflow helps to ensure that updates and improvements can be integrated smoothly for all contributors and maintainers. Here's a summary of the steps to follow: Make sure you have a GitHub account, an internet connection, and access to a terminal shell or GitHub Desktop application for running commands. Clone the repository to your local machine or click Fork to create a copy of the repository under your GitHub account or organization name. Create a new branch for your fix by running a command similar to the following: bash git switch -c my-branch-name-here Open the file you want to fix in a text editor and make the appropriate changes for the issue you are trying to address. Add the file contents of the changed files to the index git uses to manage the state of the project by running a command similar to the following: bash git add path-to-changed-file Commit your changes to store the contents you added to the index along with a descriptive message by running a command similar to the following: bash git commit -m \"Description of the fix being committed.\" Push the changes to the remote repository by running a command similar to the following: bash git push origin my-branch-name-here Create a new pull request for the branch you pushed to the upstream GitHub repository. Be sure to provide a title that includes a short description of the changes made. After you submit the pull request, it needs to be reviewed and approved. Don't worry if your pull request is not immediately approved, for example, if changes are requested or if a reviewer asks for additional information. Make changes or add comments to the pull request, as needed. Celebrate your success after your pull request is merged! Contributor guidelines The most valuable contributions from the community typically take the form of how-to guides or tutorials that help other developers solve specific problems, learn specific skills, or demonstrate specific tasks. If you would like to contribute, you might be wondering \u201cWhat is the difference between a \u2018how-to\u2019 guide and a tutorial?\u201d. How-to guides A how-to guide describes how to achieve a goal or complete a task. Only the information that is pertinent to achieving that goal or completing the task is included. With how-to guides, readers have enough information to know what they want to do\u2014for example, open a bank account\u2014but not necessarily enough information to know how to do it\u2014for example, 1) select an institution, 2) fill out an application, 3) deposit a minimum amount of currency. How-to guides often include links to additional information, but should not include explanations that take the focus away from what the reader wants to accomplish. Tutorials A tutorial is a hands-on illustration or lesson that enables the reader to achieve a highly-predictable result. Tutorials assume that readers have no prior knowledge on the subject being covered and that they require explicit guidance to complete each step to reach a well-known outcome. Typically, a tutorial is a guided tour that helps the reader complete one organic task from start to finish. There are no detours and the information should not be broken out into subtopics because the steps must be completed in order, not in a sequence of the reader\u2019s choosing. The single most important aspect of a tutorial is that it should always result in a successful, expected outcome. The successful outcome is what inspires confidence and delight in the reader. The single most important distinction between a how-to guide and a tutorial is that in a tutorial the author decides what the goal should be and the author eliminates all distractions that would detract from the successful achievement of the goal. Recommendations for writing how-to guides The Substrate Developer Hub is intended to provide a modular and extensible framework of resources for the Substrate developer community and broader ecosystem. To achieve this goal, we want to make it easy for contributors to integrate new content that follows a few guiding principles and basic conventions for structure and style. As a content creator, you should keep the following general principles in mind: \u25fc\ufe0f Modularity. Each guide has a well-defined and useful focus. However, if there\u2019s information that\u2019s useful in more than one guide, you can abstract it into a standalone topic and reuse it in multiple places. \ud83d\udd17 Linking. Guides should use links where they are useful\u2014for example, to guide readers to concepts or reference topics\u2014but be mindful that stale links frustrate readers. \u23ef\ufe0f Examples. Useful code examples are a critical component of creating a useful guide. \ud83d\udef0\ufe0f Related references. Guides can include links to related resources, like Rust docs, video content, or other guides and tutorials. Using the How-to guide template We recommend you use the how-to guide template to structure articles that you want to submit as to \u201chow-to\u201d topics. You can download a copy of the Markdown template directly from here . After downloading the template, rename the file and replace the description of each section with the relevant content. The following template outline provides suggestions for the content to put in each section of the how-to guide. [Guide title] The guide title should summarize the goal of the article. For \u201chow-to\u201d guides, the title should complete the \u201cHow do I \u2026?\u201d sentence. The first paragraph of the article should provide a brief overview of what the article is about and why this information is useful to its audience. The overview section does not require a heading and it might be more than one paragraph. The opening section of each article sets the stage for what follows and should answer the obvious questions so readers can decide whether the content is relevant to them. Readers should know\u2014just from reading this section\u2014whether they should continue or the content doesn\u2019t apply to them and they should move on to something else. For your overview, try to answer the following questions: What is this article about? What is the purpose or goal to be accomplished by following the procedure or technique? Why would someone want to use this procedure or technique? For example, are there specific use case scenarios that are applicable? When would someone use this procedure? For example, is this an activity that is done once or repeated? Is it a pattern or a unique case? Where is the procedure or technique applicable? Who would use this procedure or technique? For example, are special skills required? Do specific permissions or restrictions apply? The overview section is also a good place to link to other resources, including other guides. As the content creator, you want readers to have confidence that the guide will be useful for them. Before you begin This section is optional but recommended . Use the Before you begin heading and use the section body to describe any prerequisites that apply to your article. This section should answer the following questions: What should someone have before reading this article? What should someone know before reading this article? What should someone do before reading this article? [Logical name for a set of steps] Instead of a generic Steps heading, describe what the steps accomplish. For most procedures and techniques, use clear, concise headings to describe each part of the procedure or technique. Use the generic Steps heading only if the article has one set of steps that achieve a single goal. For example, use Steps if an article is tightly focused on a single use case and a more descriptive heading would simply repeat the article title. For the content in this section: Each step should be action driven. In most cases, each step starts with a verb and ends with a period. The paragraph following a step should describe the result or outcome the reader should expect. If you feel a step needs any additional information, link to that information rather than embedding too much extraneous detail within the step. Code snippets can help illustrate the steps but should not overwhelm the focus on \"how do I do this\" not on \"what do I do\". Keep in mind that most steps have results and readers like confirmation that they have taken the correct action as they progress through a procedure. Examples Provide links to one or more code-based examples that make practical use of your article. This section should include at least one reference to a repository that exposes what this guide covers in the form of a working example. You can use reference an existing codebase within Substrate or new code in any publicly-available repository. Related resources This section is optional. If you include it, add a bulleted list of links to similar guides, other Developer Hub ressources, or related material. For example, you might add links to other how-to guides, tutorials, or Rust docs. Content categories and tags The How-to guides are grouped into categories to help keep them organized in the how-to-guides repository. The current groupings reflect the different areas of development within Substrate: Basics. Where the really simple guides live, those that can be referenced by more complex ones. Pallet design. Everything to do with building custom pallets with or without FRAME. Weights. Any content that covers configuring weights for specific use cases. Testing. A collection of guides for testing. Storage migrations. Anything to do with storage migrations. Consensus. Consensus models, client-related content, bridging, node configurations. Parachains. Development for projects deploying on Polkadot. The source files use tags to identify the categories that apply. As a content contributor, you should use tags to identify the level of complexity and the most appropriate category for your content. You can specify the content category for your article by adding one of the following tags: basics client consensus currency fees frame-v1 migration node pallet design proof-of-work runtime storage testing weights Complexity Specify the level of complexity by adding the most appropriate tag from the following list: beginner intermediate advanced","title":"Welcome to the Substrate developer community"},{"location":"community/#before-you-contribute","text":"Before contributing, take a few minutes to review the contributor guidelines. The contributor guidelines are intended to make the contribution process easy and effective for everyone involved in addressing your issue, assessing changes, and finalizing your pull requests. Before contributing, consider the following: If you want to report an issue or request help, click Issues . You can also post a message to the community forum , ask a question on StackOverflow , or submit a support request. If you are reporting a bug, provide as much information about the problem as possible, including the version you are using. If you want to contribute directly to this repository, typical fixes might include any of the following: Spelling, grammar, or typo fixes. Code indentation, white space, or formatting changes. Broken or missing links. Note that any contribution to this repository must be submitted in the form of a pull request. If you are creating a pull request, be sure that the pull request only implements one bug fix. If you are new to working with GitHub repositories and creating pull requests, consider exploring First Contributions or How to Contribute to an Open Source Project on GitHub .","title":"Before you contribute"},{"location":"community/#basic-workflow-for-all-contributions","text":"If you want to contribute in this repository, you should follow the recommended workflow and adhere to the best practices described in this section. Following the recommended workflow helps to ensure that updates and improvements can be integrated smoothly for all contributors and maintainers. Here's a summary of the steps to follow: Make sure you have a GitHub account, an internet connection, and access to a terminal shell or GitHub Desktop application for running commands. Clone the repository to your local machine or click Fork to create a copy of the repository under your GitHub account or organization name. Create a new branch for your fix by running a command similar to the following: bash git switch -c my-branch-name-here Open the file you want to fix in a text editor and make the appropriate changes for the issue you are trying to address. Add the file contents of the changed files to the index git uses to manage the state of the project by running a command similar to the following: bash git add path-to-changed-file Commit your changes to store the contents you added to the index along with a descriptive message by running a command similar to the following: bash git commit -m \"Description of the fix being committed.\" Push the changes to the remote repository by running a command similar to the following: bash git push origin my-branch-name-here Create a new pull request for the branch you pushed to the upstream GitHub repository. Be sure to provide a title that includes a short description of the changes made. After you submit the pull request, it needs to be reviewed and approved. Don't worry if your pull request is not immediately approved, for example, if changes are requested or if a reviewer asks for additional information. Make changes or add comments to the pull request, as needed. Celebrate your success after your pull request is merged!","title":"Basic workflow for all contributions"},{"location":"community/#contributor-guidelines","text":"The most valuable contributions from the community typically take the form of how-to guides or tutorials that help other developers solve specific problems, learn specific skills, or demonstrate specific tasks. If you would like to contribute, you might be wondering \u201cWhat is the difference between a \u2018how-to\u2019 guide and a tutorial?\u201d.","title":"Contributor guidelines"},{"location":"community/#how-to-guides","text":"A how-to guide describes how to achieve a goal or complete a task. Only the information that is pertinent to achieving that goal or completing the task is included. With how-to guides, readers have enough information to know what they want to do\u2014for example, open a bank account\u2014but not necessarily enough information to know how to do it\u2014for example, 1) select an institution, 2) fill out an application, 3) deposit a minimum amount of currency. How-to guides often include links to additional information, but should not include explanations that take the focus away from what the reader wants to accomplish.","title":"How-to guides"},{"location":"community/#tutorials","text":"A tutorial is a hands-on illustration or lesson that enables the reader to achieve a highly-predictable result. Tutorials assume that readers have no prior knowledge on the subject being covered and that they require explicit guidance to complete each step to reach a well-known outcome. Typically, a tutorial is a guided tour that helps the reader complete one organic task from start to finish. There are no detours and the information should not be broken out into subtopics because the steps must be completed in order, not in a sequence of the reader\u2019s choosing. The single most important aspect of a tutorial is that it should always result in a successful, expected outcome. The successful outcome is what inspires confidence and delight in the reader. The single most important distinction between a how-to guide and a tutorial is that in a tutorial the author decides what the goal should be and the author eliminates all distractions that would detract from the successful achievement of the goal.","title":"Tutorials"},{"location":"community/#recommendations-for-writing-how-to-guides","text":"The Substrate Developer Hub is intended to provide a modular and extensible framework of resources for the Substrate developer community and broader ecosystem. To achieve this goal, we want to make it easy for contributors to integrate new content that follows a few guiding principles and basic conventions for structure and style. As a content creator, you should keep the following general principles in mind: \u25fc\ufe0f Modularity. Each guide has a well-defined and useful focus. However, if there\u2019s information that\u2019s useful in more than one guide, you can abstract it into a standalone topic and reuse it in multiple places. \ud83d\udd17 Linking. Guides should use links where they are useful\u2014for example, to guide readers to concepts or reference topics\u2014but be mindful that stale links frustrate readers. \u23ef\ufe0f Examples. Useful code examples are a critical component of creating a useful guide. \ud83d\udef0\ufe0f Related references. Guides can include links to related resources, like Rust docs, video content, or other guides and tutorials.","title":"Recommendations for writing how-to guides"},{"location":"community/#using-the-how-to-guide-template","text":"We recommend you use the how-to guide template to structure articles that you want to submit as to \u201chow-to\u201d topics. You can download a copy of the Markdown template directly from here . After downloading the template, rename the file and replace the description of each section with the relevant content. The following template outline provides suggestions for the content to put in each section of the how-to guide.","title":"Using the How-to guide template"},{"location":"community/#guide-title","text":"The guide title should summarize the goal of the article. For \u201chow-to\u201d guides, the title should complete the \u201cHow do I \u2026?\u201d sentence. The first paragraph of the article should provide a brief overview of what the article is about and why this information is useful to its audience. The overview section does not require a heading and it might be more than one paragraph. The opening section of each article sets the stage for what follows and should answer the obvious questions so readers can decide whether the content is relevant to them. Readers should know\u2014just from reading this section\u2014whether they should continue or the content doesn\u2019t apply to them and they should move on to something else. For your overview, try to answer the following questions: What is this article about? What is the purpose or goal to be accomplished by following the procedure or technique? Why would someone want to use this procedure or technique? For example, are there specific use case scenarios that are applicable? When would someone use this procedure? For example, is this an activity that is done once or repeated? Is it a pattern or a unique case? Where is the procedure or technique applicable? Who would use this procedure or technique? For example, are special skills required? Do specific permissions or restrictions apply? The overview section is also a good place to link to other resources, including other guides. As the content creator, you want readers to have confidence that the guide will be useful for them.","title":"[Guide title]"},{"location":"community/#before-you-begin","text":"This section is optional but recommended . Use the Before you begin heading and use the section body to describe any prerequisites that apply to your article. This section should answer the following questions: What should someone have before reading this article? What should someone know before reading this article? What should someone do before reading this article?","title":"Before you begin"},{"location":"community/#logical-name-for-a-set-of-steps","text":"Instead of a generic Steps heading, describe what the steps accomplish. For most procedures and techniques, use clear, concise headings to describe each part of the procedure or technique. Use the generic Steps heading only if the article has one set of steps that achieve a single goal. For example, use Steps if an article is tightly focused on a single use case and a more descriptive heading would simply repeat the article title. For the content in this section: Each step should be action driven. In most cases, each step starts with a verb and ends with a period. The paragraph following a step should describe the result or outcome the reader should expect. If you feel a step needs any additional information, link to that information rather than embedding too much extraneous detail within the step. Code snippets can help illustrate the steps but should not overwhelm the focus on \"how do I do this\" not on \"what do I do\". Keep in mind that most steps have results and readers like confirmation that they have taken the correct action as they progress through a procedure.","title":"[Logical name for a set of steps]"},{"location":"community/#examples","text":"Provide links to one or more code-based examples that make practical use of your article. This section should include at least one reference to a repository that exposes what this guide covers in the form of a working example. You can use reference an existing codebase within Substrate or new code in any publicly-available repository.","title":"Examples"},{"location":"community/#related-resources","text":"This section is optional. If you include it, add a bulleted list of links to similar guides, other Developer Hub ressources, or related material. For example, you might add links to other how-to guides, tutorials, or Rust docs.","title":"Related resources"},{"location":"community/#content-categories-and-tags","text":"The How-to guides are grouped into categories to help keep them organized in the how-to-guides repository. The current groupings reflect the different areas of development within Substrate: Basics. Where the really simple guides live, those that can be referenced by more complex ones. Pallet design. Everything to do with building custom pallets with or without FRAME. Weights. Any content that covers configuring weights for specific use cases. Testing. A collection of guides for testing. Storage migrations. Anything to do with storage migrations. Consensus. Consensus models, client-related content, bridging, node configurations. Parachains. Development for projects deploying on Polkadot. The source files use tags to identify the categories that apply. As a content contributor, you should use tags to identify the level of complexity and the most appropriate category for your content. You can specify the content category for your article by adding one of the following tags: basics client consensus currency fees frame-v1 migration node pallet design proof-of-work runtime storage testing weights","title":"Content categories and tags"},{"location":"community/#complexity","text":"Specify the level of complexity by adding the most appropriate tag from the following list: beginner intermediate advanced","title":"Complexity"},{"location":"community/bounty/","text":"IMPORTANT: This section is still work in progress. There is no official Substrate Developer Hub bounty program at this time. To encourage community support and contributions to the developer ecosystem, we have established a bounty program. The bounty program provides prizes\u2014in the form of XXX\u2014to content developers who submit articles that expand and improve Substrate documentation by covering new \u201chow-to\u201d type topics. Participate To participate in the program: On the Issues page for the Substrate Developer Hub documentation repository, select the how-to guide and new content labels to filter the list of issues displayed. Select an issue that you are interested in that requires a guide. For example: How to call a function from another pallet How to use benchmarking to calculate weights If there isn\u2019t an issue for the topic you want to contribute, create an issue describing what you want to cover and at least one use case where it is applicable first. It\u2019s valuable to know the issues that are important to the community to help us prioritize the topics to cover. Use the how-to-guide template to organize the information for your topic. Be sure your article includes the following required sections. Overview Steps Examples If applicable , your article should also include the following sections: Use cases Before you begin Related resources Before submitting, verify your content meets the following requirements: Follows the how-to guide template structure. States a clear goal in the guide title or the overview section. Focuses on achieving the stated goal. Includes a link to working code or an example repo. Provides supporting references where relevant. Add the appropriate tags to describe your content [complexity] and [category]. Create a branch in the how-to-guides repository. Create a Pull Request (PR) for the article you want to contribute. Add the Bounty submission label to the PR for your article. Update the issue you selected or created with a link to the PR for your article. The article you submit will be evaluated as part of the Pull Request review and judged based on the following criteria: Usefulness. The material your article covers does not already exist and presents at least one clear use case. Structure. You\u2019ve followed the how-to guide template structure and the conventions described in the [contributor guidelines]. Correctness and completeness. Each step is clearly articulated, correct, and complete. Reproducibility. The steps achieve the expected result consistently.","title":"Bounties"},{"location":"community/bounty/#participate","text":"To participate in the program: On the Issues page for the Substrate Developer Hub documentation repository, select the how-to guide and new content labels to filter the list of issues displayed. Select an issue that you are interested in that requires a guide. For example: How to call a function from another pallet How to use benchmarking to calculate weights If there isn\u2019t an issue for the topic you want to contribute, create an issue describing what you want to cover and at least one use case where it is applicable first. It\u2019s valuable to know the issues that are important to the community to help us prioritize the topics to cover. Use the how-to-guide template to organize the information for your topic. Be sure your article includes the following required sections. Overview Steps Examples If applicable , your article should also include the following sections: Use cases Before you begin Related resources Before submitting, verify your content meets the following requirements: Follows the how-to guide template structure. States a clear goal in the guide title or the overview section. Focuses on achieving the stated goal. Includes a link to working code or an example repo. Provides supporting references where relevant. Add the appropriate tags to describe your content [complexity] and [category]. Create a branch in the how-to-guides repository. Create a Pull Request (PR) for the article you want to contribute. Add the Bounty submission label to the PR for your article. Update the issue you selected or created with a link to the PR for your article. The article you submit will be evaluated as part of the Pull Request review and judged based on the following criteria: Usefulness. The material your article covers does not already exist and presents at least one clear use case. Structure. You\u2019ve followed the how-to guide template structure and the conventions described in the [contributor guidelines]. Correctness and completeness. Each step is clearly articulated, correct, and complete. Reproducibility. The steps achieve the expected result consistently.","title":"Participate"},{"location":"community/site-building/","text":"This repository is used to build the documentation in the Substrate Developer Hub. Before you modify the structure or content in any way, be sure you know the conventions to follow and how to avoid making changes that break the site. New pages and moving files The i18n folder is used for translation and for the rendering of the navigation and elements sections. Your index.mdx file's title is not the source for this. If you are adding or renaming a page, you must add it correctly in src/components/DevNavMenu.tsx and possibly the gatsby-config.js and gatsby-node.js files. Internal link conventions All /rustdoc/ internal links must end with .html or .html#some-ID . Reasoning can be found in #425 . Check rendering images by clearing .cache From time to time, the development server local cache becomes corrupted. To fix this issue, run the following command: yarn clean && yarn dev PLEASE do this when reviewing a page before every PR - this ensures your state is what the build CI sees as well. New or updated yarn packages From time to time, BREAKING changes happen in the yarn dependencies. To fix this issue, run the following command: git checkout main && git pull && yarn install && yarn clean && yarn dev Change the branch above to your working brach of choice, or start a new on for a new PR based on latest main this way. NOTE: Discard the \"private\": false, field that this steps adds to the package.json file.","title":"Site builder guidelines"},{"location":"community/site-building/#new-pages-and-moving-files","text":"The i18n folder is used for translation and for the rendering of the navigation and elements sections. Your index.mdx file's title is not the source for this. If you are adding or renaming a page, you must add it correctly in src/components/DevNavMenu.tsx and possibly the gatsby-config.js and gatsby-node.js files.","title":"New pages and moving files"},{"location":"community/site-building/#internal-link-conventions","text":"All /rustdoc/ internal links must end with .html or .html#some-ID . Reasoning can be found in #425 .","title":"Internal link conventions"},{"location":"community/site-building/#check-rendering-images-by-clearing-cache","text":"From time to time, the development server local cache becomes corrupted. To fix this issue, run the following command: yarn clean && yarn dev PLEASE do this when reviewing a page before every PR - this ensures your state is what the build CI sees as well.","title":"Check rendering images by clearing .cache"},{"location":"community/site-building/#new-or-updated-yarn-packages","text":"From time to time, BREAKING changes happen in the yarn dependencies. To fix this issue, run the following command: git checkout main && git pull && yarn install && yarn clean && yarn dev Change the branch above to your working brach of choice, or start a new on for a new PR based on latest main this way. NOTE: Discard the \"private\": false, field that this steps adds to the package.json file.","title":"New or updated yarn packages"},{"location":"community/style-guide/","text":"This guide focuses on best practices for writing technical documentation and on the style conventions to use when developing documentation for Parity Technologies products and audiences. The goal of this guide is to help members of the documentation team and any one interested in contributing to documentation write material that is clear, concise, and consistent. If you can't find the answer to a style, voice, or terminology question in this guide, consult the following resources: Microsoft Style Guide Chicago Manual of Style Merriam-Webster Dictionary General guidance for writing engaging content There are three keys to writing content that engages the audience: Use the second person point of view to directly address the reader. Use an active voice and present tense whenever possible. Use a conversational tone that is not too formal or too chummy. Point of view In most cases, address the reader directly. For tutorials, use either first person plural\u2014we, us, our, ours\u2014or second person point of view. Because tutorials provide a more guided approach to a topic, using the first person plural is a more natural and commonly-accepted practice than in other types of documentation. Use the first person point of view sparingly and with intention. When overused, the first person narrative can overwhelm the sense of a shared experience and obscure the reader\u2019s journey. Do not use \u201cI\u201d or \u201cme\u201d unless it appears in the text of a user interface element. Do not use \u201cwe\u201d to refer to Parity or the Substrate Developer Hub team. For example, if you are documenting a recommended setting or practice, use \u201cParity Technologies recommends....\u201d not \u201cWe recommend...\u201d. Passive constructions In spite of the axiom to never use the passive voice, there are situations where a passive sentence structure might be appropriate. Don\u2019t twist a sentence into knots just to avoid a passive construction. Passive voice does have its place, but be wary of using it. When writing about software, it\u2019s often tempting to describe what\u2019s happening from the code point of view. However, there\u2019s almost always a human being with a goal or task to complete who is initiating the activity that the software is executing. If you keep this human presence in mind, your writing will be more dynamic, easier to follow, and more interesting to read. Contractions and conversational tone Contractions are generally acceptable because they give documentation a more natural conversational tone\u2014at least for English speakers. Be conscious of when and why you use contractions. To keep the tone conversational but concise, adhere to the following common-sense guidelines: Use common, well-known words whenever possible. Don\u2019t use flowery language or literary flourish words and phrases like \u201cand so forth\u201d, \u201calbeit\u201d, \u201cheretofore\u201d, or \u201cthus\u201d. Try to be precise in word choice. For example: Don\u2019t use \u201cwhen\u201d\u2014implying eventuality and time\u2014as interchangeable with \u201cif\u201d, which implies the possibility of something happening. Don\u2019t use phrases that introduce ambiguity. For example, instead of \u201cWhen the process completes...\u201d use \u201cAfter the process completes...\u201d. Think carefully about word choices like using \u201csince\u201d (implying a period of time) instead of \u201cbecause\u201d (implying cause and result) or using \u201conce\u201d (single occurrence) instead of \u201cafter\u201d (each time). Avoid using dead language words and phrases even if they are generally accepted as English words in practice. For example: Instead of \u201ci.e.\u201d, use \u201cthat is\u201d or rewrite the sentence to make the meaning clear without needing extra qualification. Instead of \u201ce.g.\u201d, use \u201cfor example\u201d. Instead of \u201cvia\u201d, use an appropriate English substitute such as \u201cby\u201d, \u201cthrough\u201d, or \u201cusing\u201d. Instead of \u201cetc.\u201d, use \u201cand so on\u201d or revise the content to make the term unnecessary. For example, revise to use such as or like followed by an example or two. Instead of \u201ccaveat\u201d, use an appropriate English substitute such as \u201cnotice\u201d, \u201ccaution\u201d, or \u201cwarning\u201d. Avoid adding unnecessary words or phrases. For example: Instead of \u201cIn order to\u201d, just use \u201cto\u201d. Instead of \u201cas well as\u201d, just use \u201cand\u201d. Instead of \u201cand then\u201d, just use \u201cthen\u201d. Avoid jargon, colloquialisms, and idiomatic phrases. Avoid adverbs and subjective statements. For example, don\u2019t use words and phrases that include easily, rapidly, simply, quickly. Experienced developers who truly prefer to skip the tutorial... We can quickly test if this code is functioning as expected... Headings All heading levels should use the following conventions: Use sentence style case. Use active, present tense verbs in headings wherever appropriate, especially in the context of tutorials and how-to guides. Serve as a summary of the content they contain. Avoid generic headings like overview and introduction, if possible. While generic heading can be conceptually useful, they add no value to the content or the navigational experience. Always contain content. A heading should never be immediately followed by another heading. As a best practice, avoid using headings strictly for navigation. Limit heading levels As a best practice, avoid building an information hierarchy with more than three heading levels. Most content can be effectively organized using two internal heading levels, making it easier to navigate and scan for relevant topics. Topic titles Avoid using gerunds (verbs that end with -ing) in titles and headings. Procedure titles and headings should answer the question: What are you trying to do? For example, if the answer to What are you trying to do? is I want to create an account , the article heading should be Create an account . In most cases, concept and reference topics are named with a noun phrase, such as Event hooks . Lists Introduce lists with a heading, a sentence, or a fragment that ends with a colon. Use numbered lists for processes and procedures that must be completed in sequential order. Use bulleted lists for items that don't need to appear in order. Make all list items parallel in structure. For example, start each item in the list using a noun or a phrase that starts with a verb. Bullets Bullets are for unordered lists. The order of items in a bulleted list can imply importance, but generally all list items are peers. Each list item should start with a capital letter and end with a period unless all of the list items are single words or short phrases of no more than four words. Use parallel structure in phrasing the items in a list. For example, each list item might start with a verb, noun, or gerund. Numbered steps Only use numbered paragraphs for steps in procedures. If a procedure has more than nine steps, always consider breaking it into subsections with headings. Ideally, each procedure or subtask should be three to six steps, not have nested sub-steps, and have minimal embedded paragraphs describing what happens\u2014the result or outcome to expect\u2014in an unnumbered paragraph following the step. Don't combine different actions into one step except when two actions complete a task, such as \"Enter the user name, then click Next .\" Pronouns Use gender-neutral pronouns, like \u201cthey\u201d whenever possible. Generally, you can change any noun from singular to plural to have subject-verb-pronoun agreement and avoid the use of gender-specific pronouns like \u201che\u201d, \u201chim\u201d, \u201chis\u201d or \u201cshe\u201d, \u201cher\u201d, \u201chers\u201d. Be wary of impersonal and potentially ambiguous pronouns such as: all, another, any each, either few, many, neither, none, one, other same, several, some, such that, them, these, those If you use any of these impersonal pronouns, be sure you answer \u201cof what?\u201d, \u201cof which?\u201d, or \u201cas what?\u201d in the sentence. Terminology and usage conventions This section covers common terminology, style, and usage questions and recommended practices. Above and below Don't use above to mean earlier or as an adjective preceding a noun ( the above section ) or following a noun ( the code above ). Use a hyperlink, or use previous , preceding , or earlier . Don't use below to mean later or as an adjective preceding a noun ( the below section ) or following a noun ( the code below ). Use a hyperlink, or use later or the following . For example: Use the preceding code to display information about the database. Use the following code to display information about the database. Dates and numbers Use the DD Mon YYYY or DD Month YYYY format for dates. In body text, spell out whole numbers from zero through nine. Use numerals for 10 or greater. Use commas in numbers with four or more digits. Use more than instead of over (over is a spatial term). Emphasis and admonitionments Use bold formatting for user interface elements that the user interacts with, including: Dialog titles Field labels Buttons labels Options displayed in the user interface Don't use bold, italics, or underlining for emphasis. If there's text that requires more attention than the surrounding body, consider isolating it as a standalone note or tip. Use admonishment components sparingly! They are generally disruptive to the reader\u2019s experience. Ask yourself if it is really necessary to stop the reader\u2019s forward progress by adding a Note, Caution, or Tip component. Note Indicates neutral or positive information that emphasizes or supplements important points of the main text. A note supplies information that may apply only in special cases. Examples are memory limitations, equipment configurations, or details that apply to specific versions of a program. Tip Helps users apply the techniques and procedures described in the text to their specific needs. A tip suggests alternative methods that may not be obvious and helps users understand the benefits and capabilities of the product. A tip is not essential to the basic understanding of the text. Caution Advises users that failure to take or avoid a specific action could result in loss of data. Images Diagrams and illustrations can help readers visualize and internalize complex ideas and processes. So, use them liberally but with intention. Images also help to break up long text flows, but they should always reinforce and reflect the text immediately preceding or immediately following the image. If you include screenshots, only include the relevant parts of the screen and use callouts to highlight how what is captured in the image is relevant to the text. Be wary of using diagrams or illustrations that include any information\u2014visual or textual\u2014that is likely to get stale. Log in formats Most Linux distributions and macOS use log in to describe how a user initiates an interactive session. Windows uses log on. Use log in as two words with no hyphen when describing an action (verb usage). Use login as one word when used as a noun (rare but some platforms use login to mean user or an identity). Use log-in with a hyphen when modifying a noun (adjective usage). Optional steps Use (Optional) to the beginning of steps that are optional. For example: Open a new terminal. Open the attributes file in a text editor. (Optional) Add a custom field. Punctuation Element How to use it apostrophe (\u2018) Use in contractions for a conversational tone. Avoid using the possessive form. capitalization Use sentence style capitalization for all headings. When referring to elements in the user interface, follow the capitalization that is used in the labels or text. Do not capitalize common terms. colon (:) Use a colon at the end of the statement that introduces a procedure, bulleted list, or table. comma (,) Use a serial comma to separate three or more items in a series, including the item before the conjunction. em dash (\u2014) Use an em dash (\u2014) to set off a parenthetical phrase with more emphasis than parentheses provide. Don\u2019t add spaces around an em dash. Don\u2019t capitalize the first word after an em dash unless the word is a proper noun. hyphenation (-) Avoid using hyphenated compound words. Use hyphens only if the meaning is unclear without them or if the only recognized form of the word includes a hyphen. quotation marks (\" \") Avoid using quotation marks unless you need to quote a message or as tring that would otherwise be confusing given its surrounding context. semicolons (;) Don't use semicolons instead of commas to separate items in a list. If you think the content should use semicolons, consider rewriting it into subtopics or an unordered bullet list. Slashes (/) and backslashes () Avoid using slashes or backslashes except when documenting paths that require either forward or backward slashes. Never use and/or in documentation. Software versions Use or later or and later to refer to multiple versions of software. For example: Firefox 3.6 or later Rust compiler (rustc) version 1.55.0 and later Tense Use present tense whenever possible. Use past tense only if you must describe something that has already occurred. Use future tense only if you must describe something that has not yet occurred but can be safely assumed. User interface elements In general, you should avoid writing about user interface elements. Instead, documentation should always focus on what the audience needs to do or wants to accomplish and not what is displayed on the screen. Element What to do button Use bold for the button label. Don't include \"button\" in the description. For example: Click Submit . checkbox Use checkbox, not box or check box, if you need to refer to a checkbox in the user interface. Use select and clear with checkboxes, not turn on and turn off, mark and unmark, check and uncheck, or unselect and deselect. click Use click to describe taking action on a standalone button. Do not use click on. Click and select are not interchangeable. dialog If you need to refer to a dialog box, use dialog. Don't use pop-up window, dialog box, or dialogue box. dropdown Use dropdown as an adjective, not as a noun. For example, use dropdown list . Verb usage Verb How to use it allow, enable Avoid using software as a point of view and consider rewriting to focus on the human interacting with the software. can, may, might Use the verb can when describing ability, capability, or capacity. Avoid using the verb may because it implies permission. Use the past tense might when describing the possibility or eventuality of an outcome. clear Use _ clear rather than deselect or unselect if you have to describe removing a selection from a checkbox. displays Use the transitive verb displays rather than the intransitive verb appears. Use displays with a direct object. For example, The command displays log messages. ensure Use ensure to mean to make sure or to guarantee. Remember that this is not interchangeable with assure (to make confident) and insure (to provide insurance). enter, type Use enter to instruct the user to input a value by pressing the Enter or Return key. Use type to instruct the user to type a value in a field. select Use select to describe taking action on a menu item, checkbox, or radio button. Note that click and select are not interchangeable. set up, setup Use set up \u2014two words, no hyphen\u2014when used as a verb. Don't hyphenate. Use setup \u2014one word, no hyphen\u2014when used as an adjective or as a noun. want, wish Use want instead of wish or desire when the user has a choice of actions. Word choice Word in question How to use it affect, effect Use affect as a verb and use effect as a noun. app, application Use application or applications unless there\u2019s a specific reason for using the shorthand term app or apps . back-end, front-end Using the hyphen in these terms is still more common than not using it. Both forms are acceptable, but for consistency use the hyphen. email It hasn\u2019t been e-mail for thirty-plus years. Never use emails. Don\u2019t use email as a verb. file name Use file name as two words, not filename . its, it\u2019s Use its as a possessive meaning belonging to or associated with an object or idea previously mentioned. Because it is a vague pronoun, be sure what it refers to can be easily identified. Use it\u2019s only as a contraction for it is or it has . please Avoid using please in documentation unless there\u2019s a specific reason for using it. For example, you might use please if quoting the content of a message that asks the user to do something inconvenient. prerequisite As a section title, use Before you begin instead. If you use prerequisite in the text, there\u2019s no hyphen. that, which Use that at the beginning of a clause that\u2019s necessary for the sentence to make sense. Don\u2019t put a comma before it. Don't use that when introducing a clause referring to people. Use who . Use which at the beginning of a clause that adds supporting or parenthetical information to a sentence. If you can omit the clause and the sentence still makes sense, use which , and put a comma before it. user name Use user name as two words, not username. Best practices and common mistakes This section highlights best practices and common mistakes to avoid. Make every word count Concise sentences are easier to read, comprehend, and translate. Use simple words with precise meanings. Remove words that don\u2019t add substance. Avoid using passive to be verbs like been and being. Avoid weak or vague verbs, such as have , make , and do . When in doubt, choose the simple word or phrase over a more formal or complex one. For example: Use this Not this use utilize, make use of remove extract, take away, eliminate tell inform, let know to in order to, as a means to also in addition connect establish connectivity Whenever possible, choose words that have one clear meaning. Omit unnecessary adverbs\u2014words that describe how, when, or where. Unless they're important to the meaning of a statement, leave them out. Be consistent Use one term consistently to represent one concept. For example, if you use extrinsic, dispatchable, and transaction interchangeably or ambiguously, you\u2019ll leave the reader confused and uncertain. If terminology changes, be prepared to root out old terminology. If you use words that can be both nouns and verbs\u2014for example, words like file, post, mark, screen, record, and report\u2014use sentence structure and context to eliminate ambiguity. Avoid dangling participles Participles are modifiers so they must have a noun to modify. A dangling participle is a participle that doesn\u2019t have a noun to modify. If you misplace or leave out the word being modified, you\u2019ll end up with a sentence that is difficult to understand, illogical, or ambiguous (though potentially amusing). Here are a few examples of sentences with dangling participles: Looking around the yard, dandelions sprouted in every corner. Walking through the kitchen, the smoke alarm was going off. Driving like a maniac, the deer was hit and killed. You can correct these sentences by bringing the participle phrase closer to the subject the phrase is intended to modify or changing the word order of the sentence to clarify who is doing what. You can also fix these types of problems by changing the tense or using the active voice. For example: Looking around the yard, I saw dandelions had sprouted in every corner. As I was walking through the kitchen, the smoke alarm was going off. Driving like a maniac, he hit a deer and killed it. Dangling prepositions In modern English, it\u2019s perfectly acceptable to end a sentence with a preposition. Don\u2019t twist a sentence into knots just to avoid using a preposition at the end. This is something you might be interested in. This is an example you should pay attention to. Cross-reference formats Most cross-references should include information that clarifies what the reader can expect to be found in the referenced topic. For cross-references to topics in the Substrate documentation, use the following formats: For more information about [task or concept], see [topic-title]. For cross-references in a glossary entry to other glossary entries, use the following format: See [topic]. For cross-references to external resources, use the title of the destination instead of the URL of the destination. Avoid using links to unnamed destinations. For example, don\u2019t use links like click here or see this article . Writing concept topics Concept topics answer \u201cwhy?\u201d and \u201cwhat is\u2026?\u201d questions. Use concept topics to: Explain abstract ideas. Introduce new terminology. Offer analysis. Provide background information. The goal of a concept topic is to help the reader understand the bigger picture, the key components of a system or architecture, relationships between components. Concept topics tend to be relatively stable, requiring little, if any, ongoing maintenance. At a minimum, a concept topic includes at least one heading and one or more body paragraphs. A concept topic can also include: One or more examples. Two or more subsections, marked by subheadings. A list of related topics. Builder notes This repository has some conventions and peculiarities that you need to take into account when modifying it (in any way). Please read this entire section to avoid common gotchas and help make your life and the maintainers lives easier. New pages and moving files The i18n folder is used for translation but also for the rendering of the navigation elements sections . Your index.mdx file's title is not the source for this. If you are adding or renaming a page, you must add it correctly in src/components/DevNavMenu.tsx and possibly gatsby-config.js and gatsby-node.js . Internal link conventions All /rustdoc/ internal links must end with .html or .html#some-ID . Reasoning can be found in #425 . Check rendering images by clearing .cache From time to time, the development server local cache becomes corrupted. To fix this in a one liner: yarn clean && yarn dev PLEASE do this when reviewing a page before every PR - this ensures your state is what the build CI see as well. New or updated yarn packages From time to time, BREAKING changes happen in the yarn dependencies. To fix this in a one liner on main : git checkout main && git pull && yarn install && yarn clean && yarn dev Change the branch above to your working brach of choice, or start a new on for a new PR based on latest main this way. NOTE: please discard the \"private\": false, field this adds to package.json .","title":"Writing style guidelines"},{"location":"community/style-guide/#general-guidance-for-writing-engaging-content","text":"There are three keys to writing content that engages the audience: Use the second person point of view to directly address the reader. Use an active voice and present tense whenever possible. Use a conversational tone that is not too formal or too chummy.","title":"General guidance for writing engaging content"},{"location":"community/style-guide/#point-of-view","text":"In most cases, address the reader directly. For tutorials, use either first person plural\u2014we, us, our, ours\u2014or second person point of view. Because tutorials provide a more guided approach to a topic, using the first person plural is a more natural and commonly-accepted practice than in other types of documentation. Use the first person point of view sparingly and with intention. When overused, the first person narrative can overwhelm the sense of a shared experience and obscure the reader\u2019s journey. Do not use \u201cI\u201d or \u201cme\u201d unless it appears in the text of a user interface element. Do not use \u201cwe\u201d to refer to Parity or the Substrate Developer Hub team. For example, if you are documenting a recommended setting or practice, use \u201cParity Technologies recommends....\u201d not \u201cWe recommend...\u201d.","title":"Point of view"},{"location":"community/style-guide/#passive-constructions","text":"In spite of the axiom to never use the passive voice, there are situations where a passive sentence structure might be appropriate. Don\u2019t twist a sentence into knots just to avoid a passive construction. Passive voice does have its place, but be wary of using it. When writing about software, it\u2019s often tempting to describe what\u2019s happening from the code point of view. However, there\u2019s almost always a human being with a goal or task to complete who is initiating the activity that the software is executing. If you keep this human presence in mind, your writing will be more dynamic, easier to follow, and more interesting to read.","title":"Passive constructions"},{"location":"community/style-guide/#contractions-and-conversational-tone","text":"Contractions are generally acceptable because they give documentation a more natural conversational tone\u2014at least for English speakers. Be conscious of when and why you use contractions. To keep the tone conversational but concise, adhere to the following common-sense guidelines: Use common, well-known words whenever possible. Don\u2019t use flowery language or literary flourish words and phrases like \u201cand so forth\u201d, \u201calbeit\u201d, \u201cheretofore\u201d, or \u201cthus\u201d. Try to be precise in word choice. For example: Don\u2019t use \u201cwhen\u201d\u2014implying eventuality and time\u2014as interchangeable with \u201cif\u201d, which implies the possibility of something happening. Don\u2019t use phrases that introduce ambiguity. For example, instead of \u201cWhen the process completes...\u201d use \u201cAfter the process completes...\u201d. Think carefully about word choices like using \u201csince\u201d (implying a period of time) instead of \u201cbecause\u201d (implying cause and result) or using \u201conce\u201d (single occurrence) instead of \u201cafter\u201d (each time). Avoid using dead language words and phrases even if they are generally accepted as English words in practice. For example: Instead of \u201ci.e.\u201d, use \u201cthat is\u201d or rewrite the sentence to make the meaning clear without needing extra qualification. Instead of \u201ce.g.\u201d, use \u201cfor example\u201d. Instead of \u201cvia\u201d, use an appropriate English substitute such as \u201cby\u201d, \u201cthrough\u201d, or \u201cusing\u201d. Instead of \u201cetc.\u201d, use \u201cand so on\u201d or revise the content to make the term unnecessary. For example, revise to use such as or like followed by an example or two. Instead of \u201ccaveat\u201d, use an appropriate English substitute such as \u201cnotice\u201d, \u201ccaution\u201d, or \u201cwarning\u201d. Avoid adding unnecessary words or phrases. For example: Instead of \u201cIn order to\u201d, just use \u201cto\u201d. Instead of \u201cas well as\u201d, just use \u201cand\u201d. Instead of \u201cand then\u201d, just use \u201cthen\u201d. Avoid jargon, colloquialisms, and idiomatic phrases. Avoid adverbs and subjective statements. For example, don\u2019t use words and phrases that include easily, rapidly, simply, quickly. Experienced developers who truly prefer to skip the tutorial... We can quickly test if this code is functioning as expected...","title":"Contractions and conversational tone"},{"location":"community/style-guide/#headings","text":"All heading levels should use the following conventions: Use sentence style case. Use active, present tense verbs in headings wherever appropriate, especially in the context of tutorials and how-to guides. Serve as a summary of the content they contain. Avoid generic headings like overview and introduction, if possible. While generic heading can be conceptually useful, they add no value to the content or the navigational experience. Always contain content. A heading should never be immediately followed by another heading. As a best practice, avoid using headings strictly for navigation.","title":"Headings"},{"location":"community/style-guide/#limit-heading-levels","text":"As a best practice, avoid building an information hierarchy with more than three heading levels. Most content can be effectively organized using two internal heading levels, making it easier to navigate and scan for relevant topics.","title":"Limit heading levels"},{"location":"community/style-guide/#topic-titles","text":"Avoid using gerunds (verbs that end with -ing) in titles and headings. Procedure titles and headings should answer the question: What are you trying to do? For example, if the answer to What are you trying to do? is I want to create an account , the article heading should be Create an account . In most cases, concept and reference topics are named with a noun phrase, such as Event hooks .","title":"Topic titles"},{"location":"community/style-guide/#lists","text":"Introduce lists with a heading, a sentence, or a fragment that ends with a colon. Use numbered lists for processes and procedures that must be completed in sequential order. Use bulleted lists for items that don't need to appear in order. Make all list items parallel in structure. For example, start each item in the list using a noun or a phrase that starts with a verb.","title":"Lists"},{"location":"community/style-guide/#bullets","text":"Bullets are for unordered lists. The order of items in a bulleted list can imply importance, but generally all list items are peers. Each list item should start with a capital letter and end with a period unless all of the list items are single words or short phrases of no more than four words. Use parallel structure in phrasing the items in a list. For example, each list item might start with a verb, noun, or gerund.","title":"Bullets"},{"location":"community/style-guide/#numbered-steps","text":"Only use numbered paragraphs for steps in procedures. If a procedure has more than nine steps, always consider breaking it into subsections with headings. Ideally, each procedure or subtask should be three to six steps, not have nested sub-steps, and have minimal embedded paragraphs describing what happens\u2014the result or outcome to expect\u2014in an unnumbered paragraph following the step. Don't combine different actions into one step except when two actions complete a task, such as \"Enter the user name, then click Next .\"","title":"Numbered steps"},{"location":"community/style-guide/#pronouns","text":"Use gender-neutral pronouns, like \u201cthey\u201d whenever possible. Generally, you can change any noun from singular to plural to have subject-verb-pronoun agreement and avoid the use of gender-specific pronouns like \u201che\u201d, \u201chim\u201d, \u201chis\u201d or \u201cshe\u201d, \u201cher\u201d, \u201chers\u201d. Be wary of impersonal and potentially ambiguous pronouns such as: all, another, any each, either few, many, neither, none, one, other same, several, some, such that, them, these, those If you use any of these impersonal pronouns, be sure you answer \u201cof what?\u201d, \u201cof which?\u201d, or \u201cas what?\u201d in the sentence.","title":"Pronouns"},{"location":"community/style-guide/#terminology-and-usage-conventions","text":"This section covers common terminology, style, and usage questions and recommended practices.","title":"Terminology and usage conventions"},{"location":"community/style-guide/#above-and-below","text":"Don't use above to mean earlier or as an adjective preceding a noun ( the above section ) or following a noun ( the code above ). Use a hyperlink, or use previous , preceding , or earlier . Don't use below to mean later or as an adjective preceding a noun ( the below section ) or following a noun ( the code below ). Use a hyperlink, or use later or the following . For example: Use the preceding code to display information about the database. Use the following code to display information about the database.","title":"Above and below"},{"location":"community/style-guide/#dates-and-numbers","text":"Use the DD Mon YYYY or DD Month YYYY format for dates. In body text, spell out whole numbers from zero through nine. Use numerals for 10 or greater. Use commas in numbers with four or more digits. Use more than instead of over (over is a spatial term).","title":"Dates and numbers"},{"location":"community/style-guide/#emphasis-and-admonitionments","text":"Use bold formatting for user interface elements that the user interacts with, including: Dialog titles Field labels Buttons labels Options displayed in the user interface Don't use bold, italics, or underlining for emphasis. If there's text that requires more attention than the surrounding body, consider isolating it as a standalone note or tip. Use admonishment components sparingly! They are generally disruptive to the reader\u2019s experience. Ask yourself if it is really necessary to stop the reader\u2019s forward progress by adding a Note, Caution, or Tip component.","title":"Emphasis and admonitionments"},{"location":"community/style-guide/#note","text":"Indicates neutral or positive information that emphasizes or supplements important points of the main text. A note supplies information that may apply only in special cases. Examples are memory limitations, equipment configurations, or details that apply to specific versions of a program.","title":"Note"},{"location":"community/style-guide/#tip","text":"Helps users apply the techniques and procedures described in the text to their specific needs. A tip suggests alternative methods that may not be obvious and helps users understand the benefits and capabilities of the product. A tip is not essential to the basic understanding of the text.","title":"Tip"},{"location":"community/style-guide/#caution","text":"Advises users that failure to take or avoid a specific action could result in loss of data.","title":"Caution"},{"location":"community/style-guide/#images","text":"Diagrams and illustrations can help readers visualize and internalize complex ideas and processes. So, use them liberally but with intention. Images also help to break up long text flows, but they should always reinforce and reflect the text immediately preceding or immediately following the image. If you include screenshots, only include the relevant parts of the screen and use callouts to highlight how what is captured in the image is relevant to the text. Be wary of using diagrams or illustrations that include any information\u2014visual or textual\u2014that is likely to get stale.","title":"Images"},{"location":"community/style-guide/#log-in-formats","text":"Most Linux distributions and macOS use log in to describe how a user initiates an interactive session. Windows uses log on. Use log in as two words with no hyphen when describing an action (verb usage). Use login as one word when used as a noun (rare but some platforms use login to mean user or an identity). Use log-in with a hyphen when modifying a noun (adjective usage).","title":"Log in formats"},{"location":"community/style-guide/#optional-steps","text":"Use (Optional) to the beginning of steps that are optional. For example: Open a new terminal. Open the attributes file in a text editor. (Optional) Add a custom field.","title":"Optional steps"},{"location":"community/style-guide/#punctuation","text":"Element How to use it apostrophe (\u2018) Use in contractions for a conversational tone. Avoid using the possessive form. capitalization Use sentence style capitalization for all headings. When referring to elements in the user interface, follow the capitalization that is used in the labels or text. Do not capitalize common terms. colon (:) Use a colon at the end of the statement that introduces a procedure, bulleted list, or table. comma (,) Use a serial comma to separate three or more items in a series, including the item before the conjunction. em dash (\u2014) Use an em dash (\u2014) to set off a parenthetical phrase with more emphasis than parentheses provide. Don\u2019t add spaces around an em dash. Don\u2019t capitalize the first word after an em dash unless the word is a proper noun. hyphenation (-) Avoid using hyphenated compound words. Use hyphens only if the meaning is unclear without them or if the only recognized form of the word includes a hyphen. quotation marks (\" \") Avoid using quotation marks unless you need to quote a message or as tring that would otherwise be confusing given its surrounding context. semicolons (;) Don't use semicolons instead of commas to separate items in a list. If you think the content should use semicolons, consider rewriting it into subtopics or an unordered bullet list. Slashes (/) and backslashes () Avoid using slashes or backslashes except when documenting paths that require either forward or backward slashes. Never use and/or in documentation.","title":"Punctuation"},{"location":"community/style-guide/#software-versions","text":"Use or later or and later to refer to multiple versions of software. For example: Firefox 3.6 or later Rust compiler (rustc) version 1.55.0 and later","title":"Software versions"},{"location":"community/style-guide/#tense","text":"Use present tense whenever possible. Use past tense only if you must describe something that has already occurred. Use future tense only if you must describe something that has not yet occurred but can be safely assumed.","title":"Tense"},{"location":"community/style-guide/#user-interface-elements","text":"In general, you should avoid writing about user interface elements. Instead, documentation should always focus on what the audience needs to do or wants to accomplish and not what is displayed on the screen. Element What to do button Use bold for the button label. Don't include \"button\" in the description. For example: Click Submit . checkbox Use checkbox, not box or check box, if you need to refer to a checkbox in the user interface. Use select and clear with checkboxes, not turn on and turn off, mark and unmark, check and uncheck, or unselect and deselect. click Use click to describe taking action on a standalone button. Do not use click on. Click and select are not interchangeable. dialog If you need to refer to a dialog box, use dialog. Don't use pop-up window, dialog box, or dialogue box. dropdown Use dropdown as an adjective, not as a noun. For example, use dropdown list .","title":"User interface elements"},{"location":"community/style-guide/#verb-usage","text":"Verb How to use it allow, enable Avoid using software as a point of view and consider rewriting to focus on the human interacting with the software. can, may, might Use the verb can when describing ability, capability, or capacity. Avoid using the verb may because it implies permission. Use the past tense might when describing the possibility or eventuality of an outcome. clear Use _ clear rather than deselect or unselect if you have to describe removing a selection from a checkbox. displays Use the transitive verb displays rather than the intransitive verb appears. Use displays with a direct object. For example, The command displays log messages. ensure Use ensure to mean to make sure or to guarantee. Remember that this is not interchangeable with assure (to make confident) and insure (to provide insurance). enter, type Use enter to instruct the user to input a value by pressing the Enter or Return key. Use type to instruct the user to type a value in a field. select Use select to describe taking action on a menu item, checkbox, or radio button. Note that click and select are not interchangeable. set up, setup Use set up \u2014two words, no hyphen\u2014when used as a verb. Don't hyphenate. Use setup \u2014one word, no hyphen\u2014when used as an adjective or as a noun. want, wish Use want instead of wish or desire when the user has a choice of actions.","title":"Verb usage"},{"location":"community/style-guide/#word-choice","text":"Word in question How to use it affect, effect Use affect as a verb and use effect as a noun. app, application Use application or applications unless there\u2019s a specific reason for using the shorthand term app or apps . back-end, front-end Using the hyphen in these terms is still more common than not using it. Both forms are acceptable, but for consistency use the hyphen. email It hasn\u2019t been e-mail for thirty-plus years. Never use emails. Don\u2019t use email as a verb. file name Use file name as two words, not filename . its, it\u2019s Use its as a possessive meaning belonging to or associated with an object or idea previously mentioned. Because it is a vague pronoun, be sure what it refers to can be easily identified. Use it\u2019s only as a contraction for it is or it has . please Avoid using please in documentation unless there\u2019s a specific reason for using it. For example, you might use please if quoting the content of a message that asks the user to do something inconvenient. prerequisite As a section title, use Before you begin instead. If you use prerequisite in the text, there\u2019s no hyphen. that, which Use that at the beginning of a clause that\u2019s necessary for the sentence to make sense. Don\u2019t put a comma before it. Don't use that when introducing a clause referring to people. Use who . Use which at the beginning of a clause that adds supporting or parenthetical information to a sentence. If you can omit the clause and the sentence still makes sense, use which , and put a comma before it. user name Use user name as two words, not username.","title":"Word choice"},{"location":"community/style-guide/#best-practices-and-common-mistakes","text":"This section highlights best practices and common mistakes to avoid.","title":"Best practices and common mistakes"},{"location":"community/style-guide/#make-every-word-count","text":"Concise sentences are easier to read, comprehend, and translate. Use simple words with precise meanings. Remove words that don\u2019t add substance. Avoid using passive to be verbs like been and being. Avoid weak or vague verbs, such as have , make , and do . When in doubt, choose the simple word or phrase over a more formal or complex one. For example: Use this Not this use utilize, make use of remove extract, take away, eliminate tell inform, let know to in order to, as a means to also in addition connect establish connectivity Whenever possible, choose words that have one clear meaning. Omit unnecessary adverbs\u2014words that describe how, when, or where. Unless they're important to the meaning of a statement, leave them out.","title":"Make every word count"},{"location":"community/style-guide/#be-consistent","text":"Use one term consistently to represent one concept. For example, if you use extrinsic, dispatchable, and transaction interchangeably or ambiguously, you\u2019ll leave the reader confused and uncertain. If terminology changes, be prepared to root out old terminology. If you use words that can be both nouns and verbs\u2014for example, words like file, post, mark, screen, record, and report\u2014use sentence structure and context to eliminate ambiguity.","title":"Be consistent"},{"location":"community/style-guide/#avoid-dangling-participles","text":"Participles are modifiers so they must have a noun to modify. A dangling participle is a participle that doesn\u2019t have a noun to modify. If you misplace or leave out the word being modified, you\u2019ll end up with a sentence that is difficult to understand, illogical, or ambiguous (though potentially amusing). Here are a few examples of sentences with dangling participles: Looking around the yard, dandelions sprouted in every corner. Walking through the kitchen, the smoke alarm was going off. Driving like a maniac, the deer was hit and killed. You can correct these sentences by bringing the participle phrase closer to the subject the phrase is intended to modify or changing the word order of the sentence to clarify who is doing what. You can also fix these types of problems by changing the tense or using the active voice. For example: Looking around the yard, I saw dandelions had sprouted in every corner. As I was walking through the kitchen, the smoke alarm was going off. Driving like a maniac, he hit a deer and killed it.","title":"Avoid dangling participles"},{"location":"community/style-guide/#dangling-prepositions","text":"In modern English, it\u2019s perfectly acceptable to end a sentence with a preposition. Don\u2019t twist a sentence into knots just to avoid using a preposition at the end. This is something you might be interested in. This is an example you should pay attention to.","title":"Dangling prepositions"},{"location":"community/style-guide/#cross-reference-formats","text":"Most cross-references should include information that clarifies what the reader can expect to be found in the referenced topic. For cross-references to topics in the Substrate documentation, use the following formats: For more information about [task or concept], see [topic-title]. For cross-references in a glossary entry to other glossary entries, use the following format: See [topic]. For cross-references to external resources, use the title of the destination instead of the URL of the destination. Avoid using links to unnamed destinations. For example, don\u2019t use links like click here or see this article .","title":"Cross-reference formats"},{"location":"community/style-guide/#writing-concept-topics","text":"Concept topics answer \u201cwhy?\u201d and \u201cwhat is\u2026?\u201d questions. Use concept topics to: Explain abstract ideas. Introduce new terminology. Offer analysis. Provide background information. The goal of a concept topic is to help the reader understand the bigger picture, the key components of a system or architecture, relationships between components. Concept topics tend to be relatively stable, requiring little, if any, ongoing maintenance. At a minimum, a concept topic includes at least one heading and one or more body paragraphs. A concept topic can also include: One or more examples. Two or more subsections, marked by subheadings. A list of related topics.","title":"Writing concept topics"},{"location":"community/style-guide/#builder-notes","text":"This repository has some conventions and peculiarities that you need to take into account when modifying it (in any way). Please read this entire section to avoid common gotchas and help make your life and the maintainers lives easier.","title":"Builder notes"},{"location":"community/style-guide/#new-pages-and-moving-files","text":"The i18n folder is used for translation but also for the rendering of the navigation elements sections . Your index.mdx file's title is not the source for this. If you are adding or renaming a page, you must add it correctly in src/components/DevNavMenu.tsx and possibly gatsby-config.js and gatsby-node.js .","title":"New pages and moving files"},{"location":"community/style-guide/#internal-link-conventions","text":"All /rustdoc/ internal links must end with .html or .html#some-ID . Reasoning can be found in #425 .","title":"Internal link conventions"},{"location":"community/style-guide/#check-rendering-images-by-clearing-cache","text":"From time to time, the development server local cache becomes corrupted. To fix this in a one liner: yarn clean && yarn dev PLEASE do this when reviewing a page before every PR - this ensures your state is what the build CI see as well.","title":"Check rendering images by clearing .cache"},{"location":"community/style-guide/#new-or-updated-yarn-packages","text":"From time to time, BREAKING changes happen in the yarn dependencies. To fix this in a one liner on main : git checkout main && git pull && yarn install && yarn clean && yarn dev Change the branch above to your working brach of choice, or start a new on for a new PR based on latest main this way. NOTE: please discard the \"private\": false, field this adds to package.json .","title":"New or updated yarn packages"},{"location":"faq-dropbox/","text":"This section provides answers to commonly-asked questions and a collection box for solutions to common problems, troubleshooting suggestions, and tips and tricks from the Parity development team and community members. For information about contributing content to the FAQ dropbox, see Contributing FAQ articles.","title":"FAQ dropbox"},{"location":"main-docs/","text":"Substrate empowers builders Substrate takes a modular and flexible approach to blockchain development. With every design decision, you can choose between the complexity of technical freedom and the ease of developing with predefined modules. The following diagram illustrates the nature of this flexibility. The main use cases for Substrate blockchains reflect this sliding scale between technical freedom and development ease. At one end of the spectrum, you can deploy predefined Substrate nodes with minimal configuration and launch a blockchain with virtually no development effort. At the other end of the spectrum, you can design and implement a Substrate-based blockchain from scratch, giving you the technical freedom to innovate. Naturally, the most common use case falls between these two extremes. In the middle of the spectrum, you can use FRAME \u2014an acronym for Framework for Runtime Aggregation of Modularized Entities\u2014to create a customized Substrate runtime . With this approach, you can choose how much control you have over the blockchain logic by selecting and configuring the modules\u2014called pallets \u2014that you want to use from a library. If a pallet doesn't exist for the functionality you need, you can use FRAME to create your own custom pallet, then add it to your customized runtime. Where to go next Explore the following resources to learn more. Tell me more Blockchain basics Choosing a development platform Substrate node architecture Runtime development and FRAME Guide me Build a local blockchain Simulate a network Start a trusted validator network","title":"Substrate empowers builders"},{"location":"main-docs/#substrate-empowers-builders","text":"Substrate takes a modular and flexible approach to blockchain development. With every design decision, you can choose between the complexity of technical freedom and the ease of developing with predefined modules. The following diagram illustrates the nature of this flexibility. The main use cases for Substrate blockchains reflect this sliding scale between technical freedom and development ease. At one end of the spectrum, you can deploy predefined Substrate nodes with minimal configuration and launch a blockchain with virtually no development effort. At the other end of the spectrum, you can design and implement a Substrate-based blockchain from scratch, giving you the technical freedom to innovate. Naturally, the most common use case falls between these two extremes. In the middle of the spectrum, you can use FRAME \u2014an acronym for Framework for Runtime Aggregation of Modularized Entities\u2014to create a customized Substrate runtime . With this approach, you can choose how much control you have over the blockchain logic by selecting and configuring the modules\u2014called pallets \u2014that you want to use from a library. If a pallet doesn't exist for the functionality you need, you can use FRAME to create your own custom pallet, then add it to your customized runtime.","title":"Substrate empowers builders"},{"location":"main-docs/#where-to-go-next","text":"Explore the following resources to learn more.","title":"Where to go next"},{"location":"main-docs/#tell-me-more","text":"Blockchain basics Choosing a development platform Substrate node architecture Runtime development and FRAME","title":"Tell me more"},{"location":"main-docs/#guide-me","text":"Build a local blockchain Simulate a network Start a trusted validator network","title":"Guide me"},{"location":"main-docs/01-why-substrate/","text":"","title":"Why Substrate?"},{"location":"main-docs/01-why-substrate/choose-a-dev-platform/","text":"Choosing a development platform for your project Cover the main tenets: Flexible (extensible, customizable, adaptable) Open source Multi-chain interoperability Future proof upgradeability Scalability Ease of development < > technical freedom and control Technical freedom < > burden of responsibility Evaluate: Is the Substrate / Polkadot vision right for your project/business model? Evaluate: Is Substrate / Polkadot the right tool for the requirements of your project/business model? At a high-level, summarize: What is possible on smart contract platforms and how that compares to developing a Substrate runtime You can build smart contracts to run on a Substrate network What Substrate offers that traditional smart contract platforms","title":"Choosing a development platform for your project"},{"location":"main-docs/01-why-substrate/choose-a-dev-platform/#choosing-a-development-platform-for-your-project","text":"Cover the main tenets: Flexible (extensible, customizable, adaptable) Open source Multi-chain interoperability Future proof upgradeability Scalability Ease of development < > technical freedom and control Technical freedom < > burden of responsibility Evaluate: Is the Substrate / Polkadot vision right for your project/business model? Evaluate: Is Substrate / Polkadot the right tool for the requirements of your project/business model? At a high-level, summarize: What is possible on smart contract platforms and how that compares to developing a Substrate runtime You can build smart contracts to run on a Substrate network What Substrate offers that traditional smart contract platforms","title":"Choosing a development platform for your project"},{"location":"main-docs/02-fundamentals/","text":"The topics in Fundamentals explain many of the core principles and unique features of the Substrate development environment and highlights some of the design decisions available to you as a blockchain builder. Substrate offers a modular and flexible library of tools that empower you to select, compose, modify, and reuse components to suit the specific purpose of the blockchain you want to create, whether that is a private network or publish a blockchain that can interact with other blockchains through the Polkadot network. The topics in Fundamentals are intended to help you learn what's possible when you build a Substrate-based blockchain and how Substrate can help you build a blockchain that best serves your specific project requirements or business model. Before you start building, though, you want to make sure you are in the right place. Blockchain basics provides context about the complexity associated with blockchain development and how Substrate simplifies the process by taking an approach that is modular, flexible, and interoperable. Choosing a development platform discusses how developing on a traditional smart contract platform differs from developing with Substrate and why Substrate might\u2014or might not\u2014suit your project requirements and goals. Blockchain network topology defines the network topology for different blockchain deployment scenarios and how they apply to Substrate-based blockchains. Private solo chain Private enterprise chain (permissioned?) Parachain Relay chain Substrate as the foundation for Polkadot, Kusama, testnets Substrate node architecture describes the key components of the Substrate node architecture and how these components relate to the design and architecture of your custom blockchain. Runtime as the core of Substrate chains highlights the importance of the Substrate runtime and introduces the core application interfaces and primitives required for Substrate runtime development. After you digest the information in these introductory sections, you'll be ready to start designing, building, and testing your own custom blockchain solution. Inbound request pool (extrinsic, peer-to-peer induction, Consensus (models, block authoring, selection, validation, finalization,life cycle of a message)) Economics (incentives, safety of the network, guardrails) Governance Software development (Rust, Wasm, frame and pallets, data storage, tech stack)","title":"Fundamentals"},{"location":"main-docs/02-fundamentals/accounts-and-keys/","text":"Substrate uses multiple sets of public/private key pairs to represent participants of the network, including validators, nominators and normal users. As an example, the Substrate node uses a Nominated Proof-of-Stake (NPoS) algorithm to select validators. Validators and nominators may hold significant amounts of funds, so Substrate's Staking pallet introduces account abstractions that help keep funds as secure as possible. These abstractions are: Stash Key : a Stash account is meant to hold large amounts of funds. Its private key should be as secure as possible in a cold wallet. Controller Key : a Controller account signals choices on behalf of the Stash account, like payout preferences, but should only hold a minimal amount of funds to pay transaction fees. Its private key should be secure as it can affect validator settings, but will be used somewhat regularly for validator maintenance. Session Keys : these are \"hot\" keys kept in the validator client and used for signing certain validator operations. They should never hold funds. green } title={ Further Learning } text={ Learn more about validators and nominators in the context of the Substrate's NPoS [Staking pallet](/rustdocs/latest/pallet_staking/index.html). } /> Account keys A key pair can represent an account and control funds, like normal accounts that you would expect from other blockchains. In the context of Substrate's Balances pallet , these accounts must have a minimum amount (an \"existential deposit\") to exist in storage. Account keys are defined generically and made concrete in the runtime. To continue with our example of Stash and Controller accounts, the keys to these accounts are distinguished by their intended use, not by any underlying cryptographic difference. When creating Stash or Controller keys, all cryptography supported for normal account keys are also supported. Stash keys The Stash keys are the public/private key pair that defines a Stash account. This account is like a \"savings account\" in that you should not make frequent transactions from it. Therefore, its private key should be treated with the utmost security, for example protected in a safe or layers of hardware security. Since the Stash key is kept offline, it designates a Controller account to make non-spending decisions with the weight of the Stash account's funds. It can also designate a Proxy account to vote in governance on its behalf. Controller keys The Controller keys are the public/private key pair that defines a Controller account. In the context of Substrate's NPoS model, the Controller key will signal one's intent to validate or nominate. The Controller key is used to set preferences like the rewards destination and, in the case of validators, to set their Session keys. The Controller account only needs to pay transaction fees, so it only needs a minimal amount of funds. The Controller key can never be used to spend funds from its Stash account. However, actions taken by the Controller can result in slashing, so it should still be well secured. Next steps Learn more Learn more about Session Keys in the this article . Learn about the cryptography used within Substrate . Examples Follow our tutorial to create a local network and generate keys . References Visit the reference docs for the session keys runtime API . Take a look at the default session keys in the Substrate node runtime .","title":"Accounts and keys"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#account-keys","text":"A key pair can represent an account and control funds, like normal accounts that you would expect from other blockchains. In the context of Substrate's Balances pallet , these accounts must have a minimum amount (an \"existential deposit\") to exist in storage. Account keys are defined generically and made concrete in the runtime. To continue with our example of Stash and Controller accounts, the keys to these accounts are distinguished by their intended use, not by any underlying cryptographic difference. When creating Stash or Controller keys, all cryptography supported for normal account keys are also supported.","title":"Account keys"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#stash-keys","text":"The Stash keys are the public/private key pair that defines a Stash account. This account is like a \"savings account\" in that you should not make frequent transactions from it. Therefore, its private key should be treated with the utmost security, for example protected in a safe or layers of hardware security. Since the Stash key is kept offline, it designates a Controller account to make non-spending decisions with the weight of the Stash account's funds. It can also designate a Proxy account to vote in governance on its behalf.","title":"Stash keys"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#controller-keys","text":"The Controller keys are the public/private key pair that defines a Controller account. In the context of Substrate's NPoS model, the Controller key will signal one's intent to validate or nominate. The Controller key is used to set preferences like the rewards destination and, in the case of validators, to set their Session keys. The Controller account only needs to pay transaction fees, so it only needs a minimal amount of funds. The Controller key can never be used to spend funds from its Stash account. However, actions taken by the Controller can result in slashing, so it should still be well secured.","title":"Controller keys"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#next-steps","text":"","title":"Next steps"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#learn-more","text":"Learn more about Session Keys in the this article . Learn about the cryptography used within Substrate .","title":"Learn more"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#examples","text":"Follow our tutorial to create a local network and generate keys .","title":"Examples"},{"location":"main-docs/02-fundamentals/accounts-and-keys/#references","text":"Visit the reference docs for the session keys runtime API . Take a look at the default session keys in the Substrate node runtime .","title":"References"},{"location":"main-docs/02-fundamentals/architecture/","text":"A Substrate node is designed to be modular and adaptable to change. This article presents the architecture of a Substrate node, using the node template as a reference whicih provides a set of core components ready to use out of the box. Any of these components can be swapped out for different ones, depending on the target optimization or use case. A Substrate node can be thought of as video gaming environment, where the console is the client (or the \"outer part\") and the current game being played is the current runtime (i.e. everything \"on-chain\"). Each of these components are created using Substrate's multitude of core libraries for building blockchain clients and their runtime logic. The architecture of a Substrate node contains: A runtime : the logic that defines how blocks are processed, including state transition logic. In Substrate, runtime code is compiled to Wasm and becomes part of the blockchain's storage state. This enables forkless runtime upgrades . Substrate clients can also include a \"native runtime\". Everything responsible for handling on-chain logic and state persistence happens in the runtime. A storage component : used to persist the evolving state of a Substrate blockchain. Substrate ships with a simple and highly efficient key-value storage mechanism . An executor : the component of the client that dispatches calls to the runtime is known as the executor , whose role is to select between the native code and interpreted Wasm. The executor will select to interpret the Wasm runtime if it implements a newer version . A network layer : the capabilities that allow the client to communicate with other network participants. Substrate uses the Rust implementation of the libp2p network stack . A consensus engine : the logic that allows network participants to agree on the state of the blockchain. Substrate makes it possible to supply custom consensus engines and also ships with several consensus mechanisms that have been built on top of Web3 Foundation research . An RPC API : the capabilities that allow blockchain users to interact with the network. Substrate provides HTTP and WebSocket RPC servers. A telemetry layer : client metrics that are exposed by the embedded Prometheus server. Runtime The runtime contains the business logic of the chain. It defines what transactions are valid and invalid and determines how the chain's state changes in response to transactions. The \"outer node\", everything other than the runtime is responsible for handling peer discovery, transaction pooling, block and transaction gossiping, consensus, and answering RPC calls from the outside world. While performing these tasks, the outer node sometimes needs to query the runtime for information, or provide information to the runtime. Runtime APIs and host functions Any blockchain protocol can be implemented with Substrate by implementing relevant runtime APIs and host functions. [ TODO: diagram to show how multiple protocols can be implemented with the same runtime api / host function interface ] |*some protocols*|*transport layer*| *some client* \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u2502 \u2502 \u2502 Runtime \u2502 <-- Runtime API -- \u2502 Client \u2502 \u2502 \u2502 -- Host functions--> \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Host functions and runtime APIs provide a means to deliver messages being passed between the runtime and the client. Substrate can facilitate a number of runtime implementations without needing to alter the host functions and runtime APIs that come out of the box. A host function is a function that is expressed outside of the runtime but passed in as an import to the runtime. One example is the benchmarking implementation in FRAME. Benchmarking host functions are required to extract benchmarks generated by the hardware running the node. A runtime API facilitates communication between the outer node and the runtime. For example, benchmarking requires a runtime API as well. In the example of a consensus protocol such as with a BABE and AURA runtime, the runtime needs to receive and send messages which is does through the transport layer. The ability for a runtime to actually answer to a request relies on the specific protocol primitive that the runtime and client need to commonly understand, which would correspond to some custom host function and runtime API interface. An important difference between changes in the runtime API versus the host function interface is that protocol primitives can be updated without having to update the node \u2014 as long as these changes don't require the node to modify behavior around consensus. However, any change on the host interface requires upgrading the node. Substrate provides developers with the ability to define their own custom runtime APIs using the impl_runtime_apis macro. At a minimum, a runtime must implement the Core and Metadata runtime APIs. In addition to these runtime APIs, the Substrate node template has the following runtime APIs: BlockBuilder : Provides the functionality required for building a block. TaggedTransactionQueue : Handles validating transactions in the transaction queue. OffchainWorkerApi : Handles off-chain capabilities . AuraApi : Handles block authorship with Aura consensus . SessionKeys : Generates and decodes session keys . GrandpaApi : Integrates the GRANDPA finality gadget into the runtime. AccountNonceApi : Handles querying transaction indices. TransactionPaymentApi : Handles querying information about transactions. Benchmark : Provides a way to benchmark a FRAME runtime. Learn more on how to design custom \"runtime API / host function\" interfaces in Substrate. Native and Wasm runtimes In order to provide its defining forkless runtime upgrade capabilities, Substrate runtimes are compiled to WebAssembly (Wasm) bytecode. Considered an optimization to Substrate, the native runtime is especially useful for development and testing environments. It is optional in the sense that production chains don't need to rely on native builds. The Wasm runtime on the other hand is not optional. A chain's Wasm binary is embedded in the client at compile time and required for any chain specification . It is possible to skip the Wasm runtime compilation for developement purposes. However, launching a chain without one will cause the the chain will panic. Being a core component to Substrate's design, it provides the possibility for on-chain upgradability and relay chain validation. There are ongoing discussions about removing the native runtime altogether. Refer to this open issue for more details. Here are some reasons why using a native runtime could be desired: For development and testing, native runtimes have better debugging support, while Wasm runtimes are more difficult to debug. Native execution is faster than Wasm execution and more efficient on slower hardware. However: The Wasm runtime is required in all Substrate chains. The Wasm runtime is the canonical encoding of the chains' state transition functions, which implies that something that isn't supported by a Wasm runtime won't be supported by the native runtime. In production, on-chain upgrades can only be done with Wasm runtimes. Storage Substrate uses a simple key-value data store implemented as a database-backed, modified Merkle tree . This allows any higher-level storage abstraction to be built ontop of this simple key-value storage layer. All events, extrinsics and pallet logic use this storage layer to persist state on-chain. For example, the Wasm runtime of a Substrate chain is stored at the magic key :code . User balances are stored as a StorageMap which uses the key-value database. This layer is built using the Rust implementation of Rocks DB . There is a different implementation under developement called Parity DB , also built in Rust but aims to optimize storage and retrieval of state data. In any case, Substrate is designed to support any key-value database implementation. [ TODO: Elaborate on storage layers, including externalities] Trie abstraction Substrate uses a Base-16 Modified Merkle Patricia tree (\"trie\") from paritytech/trie to provide a trie structure whose contents can be modified and whose root hash is recalculated efficiently. Substrate-based chains have a single main trie, called the state trie, whose root hash is placed in each block header. This is used to easily verify the state of the blockchain and provide a basis for light clients to verify proofs. This trie only stores content for the canonical chain, not forks. There is a separate state_db layer that maintains the trie state with references counted in memory for all non-canonical blocks. All trie nodes are stored in the database and part of the trie state can get pruned, i.e. a key-value pair can be deleted from storage when it is out of pruning range for non-archive nodes. Substrate also provides an API to generate new child tries with their own root hashes that can be used in the runtime. Learn about ways to design and implement the storage for your chain here . Executor The executor is responsible for dispatching and executing calls into the Substrate runtime. The native runtime is included as part of the node executable, while the Wasm binary is stored on the blockchain under a well known storage key . These two representations of the runtime may not be the same. After the runtime is upgraded, the executor determines which version of the runtime to use when dispatching calls. Before runtime execution begins, the Substrate client proposes which runtime execution environment should be used. This is controlled by the execution strategy, which can be configured for the different parts of the blockchain execution process. The strategies are listed in the ExecutionStrategy enum : NativeWhenPossible : Execute with native build (if available, WebAssembly otherwise). AlwaysWasm : Only execute with the WebAssembly build. Both : Execute with both native (where available) and WebAssembly builds. NativeElseWasm : Execute with the native build if possible; if it fails, then execute with WebAssembly. All strategies respect the runtime version, meaning if the native and Wasm runtime versions differ, the Wasm runtime is chosen. These are configurable using Substrate's CLI . Wasm execution The Wasm representation of the Substrate runtime is considered the canonical runtime. Because this Wasm runtime is placed in the blockchain storage, the network must come to consensus about this binary. Thus it can be verified to be consistent across all syncing nodes. The Wasm execution environment can be more restrictive than the native execution environment. For example, the Wasm runtime always executes in a 32-bit environment with a configurable memory limit (up to 4 GB). For these reasons, the blockchain prefers to do block construction with the Wasm runtime. Some logic executed in Wasm will always work in the native execution environment, but the same cannot be said the other way around. Wasm execution can help to ensure that block producers create valid blocks. Native execution The native runtime will only be used by the executor when it is chosen as the execution strategy and it is compatible with the requested runtime version (see Runtime Versioning ). For all other execution processes other than block construction, the native runtime is preferred since it is more performant. In any situation where the native executable should not be run, the canonical Wasm runtime is executed instead. Primitives The Substrate framework makes minimal assumptions about what your runtime must provide to the other layers of Substrate. As long as the runtime has primitives that are mutually understood by the client, it can execute its logic. These primitives can be broken down into two categories: everything enabling the implementation of a protocol (core primitives) and the protocol itself. Core primitives are the data types that need to be defined and must fulfill a particular interface in order to work within the Substrate framework. These are: Hash : A type which encodes a cryptographic digest of some data. Typically just a 256-bit quantity. DigestItem : A type which must be able to encode one of a number of \"hard-wired\" alternatives relevant to consensus and change-tracking as well as any number of \"soft-coded\" variants, relevant to specific modules within the runtime. Digest : A series of DigestItems. This encodes all information that is relevant for a light-client to have on hand within the block. Extrinsic : A type to represent a single piece of data external to the blockchain that is recognized by the blockchain. This typically involves one or more signatures, and some sort of encoded instructions (e.g. for transferring ownership of funds or calling into a smart contract). Header : A type which is representative (cryptographically or otherwise) of all information relevant to a block. It includes the parent hash, the storage root and the extrinsics trie root, the digest and a block number. Block : Essentially just a combination of Header and a series of Extrinsic s, together with a specification of the hashing algorithm to be used. BlockNumber : A type which encodes the total number of ancestors any valid block has. Typically a 32-bit quantity. Protocol primitives are a more abstract class of primitives. They are typically informed by consensus critical components which define the relationship between a client and a runtime. These relate to implementations of runtime APIs and host functions , whereby any consensus-breaking change on the host-function must be reflected in the runtime. Adhering to some set of protocol primitives is necessary for chains connecting to eachother such as in Polkadot's parachain model. For example, the Polkadot protocol specifies host functions and runtime APIs in its implementation for block authoring (BABE) and block finalization (GRANDPA). Any parachain that uses the Polkadot protocol must also expose the same runtime APIs and host functions. Similarly, any change in Polkadot's runtime APIs or host functions must be reflected in the parachain, otherwise there is no way for a relay chain and a parachain to reach consensus. This architecture makes it possible to implement any Substrate runtime, using any language or libraries provided that it adheres to the protocol and primitives it shares with the client.","title":"Node architecture"},{"location":"main-docs/02-fundamentals/architecture/#runtime","text":"The runtime contains the business logic of the chain. It defines what transactions are valid and invalid and determines how the chain's state changes in response to transactions. The \"outer node\", everything other than the runtime is responsible for handling peer discovery, transaction pooling, block and transaction gossiping, consensus, and answering RPC calls from the outside world. While performing these tasks, the outer node sometimes needs to query the runtime for information, or provide information to the runtime.","title":"Runtime"},{"location":"main-docs/02-fundamentals/architecture/#runtime-apis-and-host-functions","text":"Any blockchain protocol can be implemented with Substrate by implementing relevant runtime APIs and host functions. [ TODO: diagram to show how multiple protocols can be implemented with the same runtime api / host function interface ] |*some protocols*|*transport layer*| *some client* \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u2502 \u2502 \u2502 Runtime \u2502 <-- Runtime API -- \u2502 Client \u2502 \u2502 \u2502 -- Host functions--> \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Host functions and runtime APIs provide a means to deliver messages being passed between the runtime and the client. Substrate can facilitate a number of runtime implementations without needing to alter the host functions and runtime APIs that come out of the box. A host function is a function that is expressed outside of the runtime but passed in as an import to the runtime. One example is the benchmarking implementation in FRAME. Benchmarking host functions are required to extract benchmarks generated by the hardware running the node. A runtime API facilitates communication between the outer node and the runtime. For example, benchmarking requires a runtime API as well. In the example of a consensus protocol such as with a BABE and AURA runtime, the runtime needs to receive and send messages which is does through the transport layer. The ability for a runtime to actually answer to a request relies on the specific protocol primitive that the runtime and client need to commonly understand, which would correspond to some custom host function and runtime API interface. An important difference between changes in the runtime API versus the host function interface is that protocol primitives can be updated without having to update the node \u2014 as long as these changes don't require the node to modify behavior around consensus. However, any change on the host interface requires upgrading the node. Substrate provides developers with the ability to define their own custom runtime APIs using the impl_runtime_apis macro. At a minimum, a runtime must implement the Core and Metadata runtime APIs. In addition to these runtime APIs, the Substrate node template has the following runtime APIs: BlockBuilder : Provides the functionality required for building a block. TaggedTransactionQueue : Handles validating transactions in the transaction queue. OffchainWorkerApi : Handles off-chain capabilities . AuraApi : Handles block authorship with Aura consensus . SessionKeys : Generates and decodes session keys . GrandpaApi : Integrates the GRANDPA finality gadget into the runtime. AccountNonceApi : Handles querying transaction indices. TransactionPaymentApi : Handles querying information about transactions. Benchmark : Provides a way to benchmark a FRAME runtime. Learn more on how to design custom \"runtime API / host function\" interfaces in Substrate.","title":"Runtime APIs and host functions"},{"location":"main-docs/02-fundamentals/architecture/#native-and-wasm-runtimes","text":"In order to provide its defining forkless runtime upgrade capabilities, Substrate runtimes are compiled to WebAssembly (Wasm) bytecode. Considered an optimization to Substrate, the native runtime is especially useful for development and testing environments. It is optional in the sense that production chains don't need to rely on native builds. The Wasm runtime on the other hand is not optional. A chain's Wasm binary is embedded in the client at compile time and required for any chain specification . It is possible to skip the Wasm runtime compilation for developement purposes. However, launching a chain without one will cause the the chain will panic. Being a core component to Substrate's design, it provides the possibility for on-chain upgradability and relay chain validation. There are ongoing discussions about removing the native runtime altogether. Refer to this open issue for more details. Here are some reasons why using a native runtime could be desired: For development and testing, native runtimes have better debugging support, while Wasm runtimes are more difficult to debug. Native execution is faster than Wasm execution and more efficient on slower hardware. However: The Wasm runtime is required in all Substrate chains. The Wasm runtime is the canonical encoding of the chains' state transition functions, which implies that something that isn't supported by a Wasm runtime won't be supported by the native runtime. In production, on-chain upgrades can only be done with Wasm runtimes.","title":"Native and Wasm runtimes"},{"location":"main-docs/02-fundamentals/architecture/#storage","text":"Substrate uses a simple key-value data store implemented as a database-backed, modified Merkle tree . This allows any higher-level storage abstraction to be built ontop of this simple key-value storage layer. All events, extrinsics and pallet logic use this storage layer to persist state on-chain. For example, the Wasm runtime of a Substrate chain is stored at the magic key :code . User balances are stored as a StorageMap which uses the key-value database. This layer is built using the Rust implementation of Rocks DB . There is a different implementation under developement called Parity DB , also built in Rust but aims to optimize storage and retrieval of state data. In any case, Substrate is designed to support any key-value database implementation. [ TODO: Elaborate on storage layers, including externalities] Trie abstraction Substrate uses a Base-16 Modified Merkle Patricia tree (\"trie\") from paritytech/trie to provide a trie structure whose contents can be modified and whose root hash is recalculated efficiently. Substrate-based chains have a single main trie, called the state trie, whose root hash is placed in each block header. This is used to easily verify the state of the blockchain and provide a basis for light clients to verify proofs. This trie only stores content for the canonical chain, not forks. There is a separate state_db layer that maintains the trie state with references counted in memory for all non-canonical blocks. All trie nodes are stored in the database and part of the trie state can get pruned, i.e. a key-value pair can be deleted from storage when it is out of pruning range for non-archive nodes. Substrate also provides an API to generate new child tries with their own root hashes that can be used in the runtime. Learn about ways to design and implement the storage for your chain here .","title":"Storage"},{"location":"main-docs/02-fundamentals/architecture/#executor","text":"The executor is responsible for dispatching and executing calls into the Substrate runtime. The native runtime is included as part of the node executable, while the Wasm binary is stored on the blockchain under a well known storage key . These two representations of the runtime may not be the same. After the runtime is upgraded, the executor determines which version of the runtime to use when dispatching calls. Before runtime execution begins, the Substrate client proposes which runtime execution environment should be used. This is controlled by the execution strategy, which can be configured for the different parts of the blockchain execution process. The strategies are listed in the ExecutionStrategy enum : NativeWhenPossible : Execute with native build (if available, WebAssembly otherwise). AlwaysWasm : Only execute with the WebAssembly build. Both : Execute with both native (where available) and WebAssembly builds. NativeElseWasm : Execute with the native build if possible; if it fails, then execute with WebAssembly. All strategies respect the runtime version, meaning if the native and Wasm runtime versions differ, the Wasm runtime is chosen. These are configurable using Substrate's CLI . Wasm execution The Wasm representation of the Substrate runtime is considered the canonical runtime. Because this Wasm runtime is placed in the blockchain storage, the network must come to consensus about this binary. Thus it can be verified to be consistent across all syncing nodes. The Wasm execution environment can be more restrictive than the native execution environment. For example, the Wasm runtime always executes in a 32-bit environment with a configurable memory limit (up to 4 GB). For these reasons, the blockchain prefers to do block construction with the Wasm runtime. Some logic executed in Wasm will always work in the native execution environment, but the same cannot be said the other way around. Wasm execution can help to ensure that block producers create valid blocks. Native execution The native runtime will only be used by the executor when it is chosen as the execution strategy and it is compatible with the requested runtime version (see Runtime Versioning ). For all other execution processes other than block construction, the native runtime is preferred since it is more performant. In any situation where the native executable should not be run, the canonical Wasm runtime is executed instead.","title":"Executor"},{"location":"main-docs/02-fundamentals/architecture/#primitives","text":"The Substrate framework makes minimal assumptions about what your runtime must provide to the other layers of Substrate. As long as the runtime has primitives that are mutually understood by the client, it can execute its logic. These primitives can be broken down into two categories: everything enabling the implementation of a protocol (core primitives) and the protocol itself. Core primitives are the data types that need to be defined and must fulfill a particular interface in order to work within the Substrate framework. These are: Hash : A type which encodes a cryptographic digest of some data. Typically just a 256-bit quantity. DigestItem : A type which must be able to encode one of a number of \"hard-wired\" alternatives relevant to consensus and change-tracking as well as any number of \"soft-coded\" variants, relevant to specific modules within the runtime. Digest : A series of DigestItems. This encodes all information that is relevant for a light-client to have on hand within the block. Extrinsic : A type to represent a single piece of data external to the blockchain that is recognized by the blockchain. This typically involves one or more signatures, and some sort of encoded instructions (e.g. for transferring ownership of funds or calling into a smart contract). Header : A type which is representative (cryptographically or otherwise) of all information relevant to a block. It includes the parent hash, the storage root and the extrinsics trie root, the digest and a block number. Block : Essentially just a combination of Header and a series of Extrinsic s, together with a specification of the hashing algorithm to be used. BlockNumber : A type which encodes the total number of ancestors any valid block has. Typically a 32-bit quantity. Protocol primitives are a more abstract class of primitives. They are typically informed by consensus critical components which define the relationship between a client and a runtime. These relate to implementations of runtime APIs and host functions , whereby any consensus-breaking change on the host-function must be reflected in the runtime. Adhering to some set of protocol primitives is necessary for chains connecting to eachother such as in Polkadot's parachain model. For example, the Polkadot protocol specifies host functions and runtime APIs in its implementation for block authoring (BABE) and block finalization (GRANDPA). Any parachain that uses the Polkadot protocol must also expose the same runtime APIs and host functions. Similarly, any change in Polkadot's runtime APIs or host functions must be reflected in the parachain, otherwise there is no way for a relay chain and a parachain to reach consensus. This architecture makes it possible to implement any Substrate runtime, using any language or libraries provided that it adheres to the protocol and primitives it shares with the client.","title":"Primitives"},{"location":"main-docs/02-fundamentals/blockchain-basics/","text":"Blockchain basics Blockchain software enables individual computers\u2014called nodes\u2014to communicate with each other to form a decentralized peer-to-peer (P2P) network. To ensure the security of the data on the chain and the ongoing progress of the chain, the nodes use some form of consensus to agree on the state of data in each block of data and the order in which the blocks are processed. What is a blockchain node? At a high level, a blockchain node consists of the following key components: Storage Peer-to-peer networking Consensus capabilities Data handling capabilities for external or \"extrinsic\" information A Runtime Because of the complexity involved in building these components, most blockchain projects are forked from an existing blockchain project. For example, the Bitcoin repository was forked to create: Litecoin, ZCash, Namecoin, and Bitcoin Cash. Similarly, the Ethereum repository was forked to create Quorum, POA Network, KodakCoin, and Musicoin. However, the existing blockchain platforms were not designed to allow for modification. As a result, building a new blockchain by forking has serious limitations. State machines and handling conflicts A blockchain runtime is a state machine . It has some internal state, and state transition function that allows it to transition from its current state to a future state. In most runtimes there are states that have valid transitions to multiple future states, but a single transition must be selected. Blockchains must agree on: Some initial state, called \"genesis\". A series of state transitions, each called a \"block\". A final (current) state. In order to agree on the resulting state after a transition, all operations within a blockchain's state transition function must be deterministic. In centralized systems, the central authority chooses among mutually exclusive alternatives by recording state transitions in the order it sees them, and choosing the first of the competing alternatives when a conflict arises. In decentralized systems, the nodes will see transactions in different orders, and thus they must use a more elaborate method to exclude transactions. As a further complication, blockchain networks strive to be fault tolerant, which means that they should continue to provide consistent data even if some participants are not following the rules. Blockchains batch transactions into blocks and have some method to select which participant has the right to submit a block. For example, in a proof-of-work chain, the node that finds a valid proof of work first has the right to submit a block to the chain. What is Substrate? Substrate is an open source, modular, and extensible framework for building blockchains. Substrate is designed to be flexible and allow innovators to design and build a blockchain network that meets their needs. It provides all the core components you need to build a customized blockchain node. Where to go next Explore the following resources to learn more. Tell me (read related topics) Fundamentals Guide me (related tutorials) Build a local blockchain Simulate a two-node network Start a private network Show me (related video content) Teach me (how to) If you prefer to explore code directly, you can start building in the Developer Playground and consult the API reference to get details about the Rust crates you use.","title":"Blockchain basics"},{"location":"main-docs/02-fundamentals/blockchain-basics/#blockchain-basics","text":"Blockchain software enables individual computers\u2014called nodes\u2014to communicate with each other to form a decentralized peer-to-peer (P2P) network. To ensure the security of the data on the chain and the ongoing progress of the chain, the nodes use some form of consensus to agree on the state of data in each block of data and the order in which the blocks are processed.","title":"Blockchain basics"},{"location":"main-docs/02-fundamentals/blockchain-basics/#what-is-a-blockchain-node","text":"At a high level, a blockchain node consists of the following key components: Storage Peer-to-peer networking Consensus capabilities Data handling capabilities for external or \"extrinsic\" information A Runtime Because of the complexity involved in building these components, most blockchain projects are forked from an existing blockchain project. For example, the Bitcoin repository was forked to create: Litecoin, ZCash, Namecoin, and Bitcoin Cash. Similarly, the Ethereum repository was forked to create Quorum, POA Network, KodakCoin, and Musicoin. However, the existing blockchain platforms were not designed to allow for modification. As a result, building a new blockchain by forking has serious limitations.","title":"What is a blockchain node?"},{"location":"main-docs/02-fundamentals/blockchain-basics/#state-machines-and-handling-conflicts","text":"A blockchain runtime is a state machine . It has some internal state, and state transition function that allows it to transition from its current state to a future state. In most runtimes there are states that have valid transitions to multiple future states, but a single transition must be selected. Blockchains must agree on: Some initial state, called \"genesis\". A series of state transitions, each called a \"block\". A final (current) state. In order to agree on the resulting state after a transition, all operations within a blockchain's state transition function must be deterministic. In centralized systems, the central authority chooses among mutually exclusive alternatives by recording state transitions in the order it sees them, and choosing the first of the competing alternatives when a conflict arises. In decentralized systems, the nodes will see transactions in different orders, and thus they must use a more elaborate method to exclude transactions. As a further complication, blockchain networks strive to be fault tolerant, which means that they should continue to provide consistent data even if some participants are not following the rules. Blockchains batch transactions into blocks and have some method to select which participant has the right to submit a block. For example, in a proof-of-work chain, the node that finds a valid proof of work first has the right to submit a block to the chain.","title":"State machines and handling conflicts"},{"location":"main-docs/02-fundamentals/blockchain-basics/#what-is-substrate","text":"Substrate is an open source, modular, and extensible framework for building blockchains. Substrate is designed to be flexible and allow innovators to design and build a blockchain network that meets their needs. It provides all the core components you need to build a customized blockchain node.","title":"What is Substrate?"},{"location":"main-docs/02-fundamentals/blockchain-basics/#where-to-go-next","text":"Explore the following resources to learn more.","title":"Where to go next"},{"location":"main-docs/02-fundamentals/blockchain-basics/#tell-me-read-related-topics","text":"Fundamentals","title":"Tell me (read related topics)"},{"location":"main-docs/02-fundamentals/blockchain-basics/#guide-me-related-tutorials","text":"Build a local blockchain Simulate a two-node network Start a private network","title":"Guide me (related tutorials)"},{"location":"main-docs/02-fundamentals/blockchain-basics/#show-me-related-video-content","text":"","title":"Show me (related video content)"},{"location":"main-docs/02-fundamentals/blockchain-basics/#teach-me-how-to","text":"If you prefer to explore code directly, you can start building in the Developer Playground and consult the API reference to get details about the Rust crates you use.","title":"Teach me (how to)"},{"location":"main-docs/02-fundamentals/consensus/","text":"This article presents reference and conceptual information about the different consensus mechanisms used in Substrate. Blockchain nodes use consensus engines to agree on the blockchain's state. There are different consensus engines with various tradeoffs that are supported \"out-of-the-box\" in Substrate. Generally, two components are necessary for achieving consensus: Block authoring (or construction): the mechanism for nodes to create new blocks. Block finalization: the mechanism to handle forks and choose which chain is the canonical chain. Block authoring Some nodes in a blockchain network are able to produce new blocks, a process known as block authoring. Exactly which nodes may author blocks depends on which consensus engine you're using. In a centralized network, a single node might author all the blocks, whereas in a completely permissionless network, an algorithm must select the block author at each height. Substrate provides several block construction algorithms and also allows you to create your own. These are: Aura (based on Round-robin scheduling ). BABE (slot-based scheduling) Proof of Work Some examples: AURA and BABE (slot-based algorithms): there must be a known set of validators who are permitted to produce blocks. Time is divided up into discrete slots, and during each slot only some of the validators may produce a block. The specifics of which validators can author blocks during each slot vary from engine to engine. Proof of Work: in proof-of-work systems like Bitcoin, any node may produce a block at any time, so long as it has solved a computationally-intensive problem. Solving the problem takes CPU time, and thus miners can only produce blocks in proportion with their computing resources. Substrate provides a proof-of-work block production engine. Fork choice rules Forks occur when two blocks reference the same parent. Block finalization is a mechanism that resolves forks such that only the canonical chain exists. A fork choice rule is an algorithm that takes a blockchain and selects the \"best\" chain, and thus the one that should be extended. Substrate exposes this concept through the SelectChain Trait . Similarly, you could write your custom fork choice rule, or use an existing one like GRANDPA which comes out of the box. Some examples: GRANDPA , the finality gadget used in Polkadot-like chains. GHOST, the finality gadget used in Ethereum 1.0. In GRANDPA, the longest chain rule simply says that the best chain is the longest chain. Substrate provides this chain selection rule with the LongestChain struct . GRANDPA uses the longest chain rule in its voting mechanism. The Greedy Heaviest Observed SubTree (GHOST) rule says that, starting at the genesis block, each fork is resolved by choosing the branch that has the most blocks built on it recursively. Finality Users in any system want to know when their transactions are finalized, and blockchain is no different. In some traditional systems, finality happens when a receipt is handed over, or papers are signed. Using the block authoring schemes and fork choice rules described so far, transactions are never entirely finalized. There is always a chance that a longer (or heavier) chain will come along and revert your transaction. However, the more blocks are built on top of a particular block, the less likely it is to ever be reverted. In this way, block authoring along with a proper fork choice rule provides probabilistic finality. When deterministic finality is desired, a finality gadget can be added to the blockchain's logic. Members of a fixed authority set cast finality votes, and when enough votes have been cast for a certain block, the block is deemed final. In most systems, this threshold is 2/3. Blocks that have been finalized by such a gadget cannot be reverted without external coordination such as a hard fork. Some consensus systems couple block production and finality, as in, finalization is part of the block production process and a new block N+1 cannot be authored until block N is finalize. In Substrate, the two processes are isolated from one another. It allows you to use any block production engine on its own with probabilistic finality or couple it with a finality gadget to have determinsitic finality. In systems that use a finality gadget, the fork choice rule must be modified to consider the results of the finality game. For example, instead of taking the longest chain period, a node would take the longest chain that contains the most recently finalized block. Consensus engines in Substrate Although developers are welcome to implement their own, every Substrate node template comes with GRANDPA and AURA out of the box. Substrate also provides implementations of BABE and Proof of Work based consensus. Aura Aura provides a slot-based block authoring mechanism. In Aura a known set of authorities take turns producing blocks. BABE BABE provides slot-based block authoring with a known set of validators and typically used in proof-of-stake systems. Unlike Aura, slot assignment is based on the evaluation of a Verifiable Random Function (VRF). Each validator is assigned a weight for an epoch. This epoch is broken up into slots and the validator evaluates its VRF at each slot. For each slot that the validator's VRF output is below its weight, it is allowed to author a block. Because multiple validators may be able to produce a block during the same slot, forks are more common in BABE than they are in Aura, even in good network conditions. Substrate's implementation of BABE also has a fallback mechanism for when no authorities are chosen in a given slot. These \"secondary\" slot assignments allow BABE to achieve a constant block time. Proof of Work Proof-of-work block authoring is not slot-based and does not require a known authority set. In proof of work, anyone can produce a block at any time, so long as they can solve a computationally challenging problem (typically a hash preimage search). The difficulty of this problem can be tuned to provide a statistical target block time. GRANDPA GRANDPA provides block finalization. It has a known weighted authority set like BABE. However, GRANDPA does not author blocks; it just listens to gossip about blocks that have been produced by some authoring engine. GRANDPA validators vote on chains, not blocks, i.e. they vote on a block that they consider \"best\" and their votes are applied transitively to all previous blocks. Once more than 2/3 of the GRANDPA authorities have voted for a particular block, it is considered final. All deterministic finality algorithms, including GRANDPA, require at least 2f + 1 non-faulty nodes, where f is the number of faulty or malicious nodes. Learn more about where this threshold comes from and why it is ideal in the seminal paper Reaching Agreement in the Presence of Faults or on Wikipedia: Byzantine Fault . Not all consensus protocols define a single, canonical chain. Some protocols validate directed acyclic graphs (DAG) when two blocks with the same parent do not have conflicting state changes. See AlephBFT for such an example. Learn more BABE Research GRANDPA Research","title":"Consensus"},{"location":"main-docs/02-fundamentals/consensus/#block-authoring","text":"Some nodes in a blockchain network are able to produce new blocks, a process known as block authoring. Exactly which nodes may author blocks depends on which consensus engine you're using. In a centralized network, a single node might author all the blocks, whereas in a completely permissionless network, an algorithm must select the block author at each height. Substrate provides several block construction algorithms and also allows you to create your own. These are: Aura (based on Round-robin scheduling ). BABE (slot-based scheduling) Proof of Work Some examples: AURA and BABE (slot-based algorithms): there must be a known set of validators who are permitted to produce blocks. Time is divided up into discrete slots, and during each slot only some of the validators may produce a block. The specifics of which validators can author blocks during each slot vary from engine to engine. Proof of Work: in proof-of-work systems like Bitcoin, any node may produce a block at any time, so long as it has solved a computationally-intensive problem. Solving the problem takes CPU time, and thus miners can only produce blocks in proportion with their computing resources. Substrate provides a proof-of-work block production engine.","title":"Block authoring"},{"location":"main-docs/02-fundamentals/consensus/#fork-choice-rules","text":"Forks occur when two blocks reference the same parent. Block finalization is a mechanism that resolves forks such that only the canonical chain exists. A fork choice rule is an algorithm that takes a blockchain and selects the \"best\" chain, and thus the one that should be extended. Substrate exposes this concept through the SelectChain Trait . Similarly, you could write your custom fork choice rule, or use an existing one like GRANDPA which comes out of the box. Some examples: GRANDPA , the finality gadget used in Polkadot-like chains. GHOST, the finality gadget used in Ethereum 1.0. In GRANDPA, the longest chain rule simply says that the best chain is the longest chain. Substrate provides this chain selection rule with the LongestChain struct . GRANDPA uses the longest chain rule in its voting mechanism. The Greedy Heaviest Observed SubTree (GHOST) rule says that, starting at the genesis block, each fork is resolved by choosing the branch that has the most blocks built on it recursively.","title":"Fork choice rules"},{"location":"main-docs/02-fundamentals/consensus/#finality","text":"Users in any system want to know when their transactions are finalized, and blockchain is no different. In some traditional systems, finality happens when a receipt is handed over, or papers are signed. Using the block authoring schemes and fork choice rules described so far, transactions are never entirely finalized. There is always a chance that a longer (or heavier) chain will come along and revert your transaction. However, the more blocks are built on top of a particular block, the less likely it is to ever be reverted. In this way, block authoring along with a proper fork choice rule provides probabilistic finality. When deterministic finality is desired, a finality gadget can be added to the blockchain's logic. Members of a fixed authority set cast finality votes, and when enough votes have been cast for a certain block, the block is deemed final. In most systems, this threshold is 2/3. Blocks that have been finalized by such a gadget cannot be reverted without external coordination such as a hard fork. Some consensus systems couple block production and finality, as in, finalization is part of the block production process and a new block N+1 cannot be authored until block N is finalize. In Substrate, the two processes are isolated from one another. It allows you to use any block production engine on its own with probabilistic finality or couple it with a finality gadget to have determinsitic finality. In systems that use a finality gadget, the fork choice rule must be modified to consider the results of the finality game. For example, instead of taking the longest chain period, a node would take the longest chain that contains the most recently finalized block.","title":"Finality"},{"location":"main-docs/02-fundamentals/consensus/#consensus-engines-in-substrate","text":"Although developers are welcome to implement their own, every Substrate node template comes with GRANDPA and AURA out of the box. Substrate also provides implementations of BABE and Proof of Work based consensus.","title":"Consensus engines in Substrate"},{"location":"main-docs/02-fundamentals/consensus/#aura","text":"Aura provides a slot-based block authoring mechanism. In Aura a known set of authorities take turns producing blocks.","title":"Aura"},{"location":"main-docs/02-fundamentals/consensus/#babe","text":"BABE provides slot-based block authoring with a known set of validators and typically used in proof-of-stake systems. Unlike Aura, slot assignment is based on the evaluation of a Verifiable Random Function (VRF). Each validator is assigned a weight for an epoch. This epoch is broken up into slots and the validator evaluates its VRF at each slot. For each slot that the validator's VRF output is below its weight, it is allowed to author a block. Because multiple validators may be able to produce a block during the same slot, forks are more common in BABE than they are in Aura, even in good network conditions. Substrate's implementation of BABE also has a fallback mechanism for when no authorities are chosen in a given slot. These \"secondary\" slot assignments allow BABE to achieve a constant block time.","title":"BABE"},{"location":"main-docs/02-fundamentals/consensus/#proof-of-work","text":"Proof-of-work block authoring is not slot-based and does not require a known authority set. In proof of work, anyone can produce a block at any time, so long as they can solve a computationally challenging problem (typically a hash preimage search). The difficulty of this problem can be tuned to provide a statistical target block time.","title":"Proof of Work"},{"location":"main-docs/02-fundamentals/consensus/#grandpa","text":"GRANDPA provides block finalization. It has a known weighted authority set like BABE. However, GRANDPA does not author blocks; it just listens to gossip about blocks that have been produced by some authoring engine. GRANDPA validators vote on chains, not blocks, i.e. they vote on a block that they consider \"best\" and their votes are applied transitively to all previous blocks. Once more than 2/3 of the GRANDPA authorities have voted for a particular block, it is considered final. All deterministic finality algorithms, including GRANDPA, require at least 2f + 1 non-faulty nodes, where f is the number of faulty or malicious nodes. Learn more about where this threshold comes from and why it is ideal in the seminal paper Reaching Agreement in the Presence of Faults or on Wikipedia: Byzantine Fault . Not all consensus protocols define a single, canonical chain. Some protocols validate directed acyclic graphs (DAG) when two blocks with the same parent do not have conflicting state changes. See AlephBFT for such an example.","title":"GRANDPA"},{"location":"main-docs/02-fundamentals/consensus/#learn-more","text":"BABE Research GRANDPA Research","title":"Learn more"},{"location":"main-docs/02-fundamentals/node-and-network-types/","text":"Substrate provides tools to build all types of blockchain networks and protocols. This implies application specific networks and nodes. Networks Network architectures can fall into the following categories: Relay chains: these Substrate blockchains are desgined to provide decentralized security to other chains connected to it. Polkadot is an example of such a chain. Parachains: parachains are blockchains built to connect to some relay chain. Such chains need to implement the same consenus protocol as the relay chain they target. Solo-chains: these Substrate blockchains implement their own security protocol and are independant from any other chain. They could connect to other Substrate blockchains but would have to implement their own communication channels. For every type of chain, there are two types of testing networks: economically bearing test networks called canary networks or non-economically bearing test networks. [ TODO: Diagrams / illustrations for each type of chain ] Types of nodes Installing a Substrate node is necessary when developing runtimes locally. Substrate provides CLI flags to specify different behavior for how a node runs. For example, when running a node with the --dev flag, a temporary directory gets created to store state while the chain is running and gets purged each time the chain is killed. In production there could be different use cases to run specific types of nodes. Nodes provide ways to query on-chain state and write to it. There are three types of nodes you can run with any Substrate chain: Archive node: keeps a history of all the states of all blocks. An archive node is typically used for applications that require querying block state at any point in time. Full node: discards all finalized blocks older than some configurable number of blocks (256 by default), with the exception of the genesis block. A full node is pruned which requires much less space than an archive node. Light node: has only the runtime and current state. Light nodes are fast and ideal for devices with limited resources. It is possible to rebuild the state of the entire blockchain by using a full node and executing all the blocks from the genesis block. However, a full node requires more compution to query state or retrieve information about some previous state. On the other hand, an archive node requires less computation for querying state. Run a node Polkadot provides documentation on how to run an archive node here . Some useful CLI flags to specify the node type you want to run (using the --help flag on a nodes executable): --pruning <PRUNING_MODE> Specify the state pruning mode, a number of blocks to keep or 'archive'. Default is to keep all block states if the node is running as a validator (i.e. 'archive'), otherwise state is only kept for the last 256 blocks. --keep-blocks <COUNT> Specify the number of finalized blocks to keep in the database. Default is to keep all blocks. --light Experimental: Run in light client mode.","title":"Nodes and networks"},{"location":"main-docs/02-fundamentals/node-and-network-types/#networks","text":"Network architectures can fall into the following categories: Relay chains: these Substrate blockchains are desgined to provide decentralized security to other chains connected to it. Polkadot is an example of such a chain. Parachains: parachains are blockchains built to connect to some relay chain. Such chains need to implement the same consenus protocol as the relay chain they target. Solo-chains: these Substrate blockchains implement their own security protocol and are independant from any other chain. They could connect to other Substrate blockchains but would have to implement their own communication channels. For every type of chain, there are two types of testing networks: economically bearing test networks called canary networks or non-economically bearing test networks. [ TODO: Diagrams / illustrations for each type of chain ]","title":"Networks"},{"location":"main-docs/02-fundamentals/node-and-network-types/#types-of-nodes","text":"Installing a Substrate node is necessary when developing runtimes locally. Substrate provides CLI flags to specify different behavior for how a node runs. For example, when running a node with the --dev flag, a temporary directory gets created to store state while the chain is running and gets purged each time the chain is killed. In production there could be different use cases to run specific types of nodes. Nodes provide ways to query on-chain state and write to it. There are three types of nodes you can run with any Substrate chain: Archive node: keeps a history of all the states of all blocks. An archive node is typically used for applications that require querying block state at any point in time. Full node: discards all finalized blocks older than some configurable number of blocks (256 by default), with the exception of the genesis block. A full node is pruned which requires much less space than an archive node. Light node: has only the runtime and current state. Light nodes are fast and ideal for devices with limited resources. It is possible to rebuild the state of the entire blockchain by using a full node and executing all the blocks from the genesis block. However, a full node requires more compution to query state or retrieve information about some previous state. On the other hand, an archive node requires less computation for querying state.","title":"Types of nodes"},{"location":"main-docs/02-fundamentals/node-and-network-types/#run-a-node","text":"Polkadot provides documentation on how to run an archive node here . Some useful CLI flags to specify the node type you want to run (using the --help flag on a nodes executable): --pruning <PRUNING_MODE> Specify the state pruning mode, a number of blocks to keep or 'archive'. Default is to keep all block states if the node is running as a validator (i.e. 'archive'), otherwise state is only kept for the last 256 blocks. --keep-blocks <COUNT> Specify the number of finalized blocks to keep in the database. Default is to keep all blocks. --light Experimental: Run in light client mode.","title":"Run a node"},{"location":"main-docs/02-fundamentals/offchain-operations/","text":"TODO","title":"Offchain operations"},{"location":"main-docs/02-fundamentals/rust-basics/","text":"The goal of this article is to explain how Substrate uses Rust to achieve what it provides. In doing so, it explains how Substrate uses no_std and why, and what it has to do with compiling to Wasm . As a modern programming language, Rust provides a high degree of performance, type safety and memory efficiency. The Rust compiler helps developers be confident in the code they write, making it harder to write code with memory or concurency bugs. This is mostly owed to its type system which solves such issues at compile time. Among other characteristics this section will see, it's a language which gives Substrate a powerful edge that other languages don't offer. Useful context: Rust book How rustup works Why Rust? Cargo and crates.io Cargo is Rust's package management tool. It comes with a number of different types of commands for running tests, building documentation, benchmarks and more. Some common patterns for using cargo when developing with Substrate include: Generating source code documentation using cargo doc for any pallet or runtime. Running unit tests using cargo test for any runtime logic. Managing project dependencies using cargo update and cargo edit . Using cargo tree for resolving dependency issues. Using cargo remote to speed up compile times by using a remote machine. The complete list of cargo plugins can be found here . Crates.io is Rust's community managed package registry. Any Rust developer can publish their crates there for others to use in their projects. This is useful to make Substrate components accessible to developers and for developers to easily reuse existing modules in their projects. Programming paradigms Types, traits and generics . Reading: - https://doc.rust-lang.org/book/ch10-00-generics.html Rust has a sophisticated trait system that helps developers make use of Substrate\u2019s many layers of abstractions. The core features available to build abstractions are owed to Rust's system of traits and generics. Generics allow Substrate to exist as a sort of template for writing runtimes. They use traits to encapsulate the set of operations that can be performed on a generic type. For developers, this system makes it possible to extend domain specific logic by defining custom behavior using traits and type bounds. TODO: Make actual diagram illustrating that everything is generic and made concrete in the runtime. \u2502 Generic library | ---> made concrete ---> \u2502 Runtime \u2502 Having Substrate as generic as possible leaves maximum flexibility, where generics resolve into whatever the user defines them to resolve as. Refer to the UTXO implementation with Substrate for a demonstration of how these paradigms make Substrate flexible and modular. Configuration traits A common use of abstractions in Susbtrate is the use of the Config trait from frame_system when developing pallets . This is the trait responsible for declaring the types that are commonly used in developing Substrate runtimes. With it there is no need to duplicate code that declares a type that's used in several places, such as AccountId . Instead, any pallet-which is coupled to frame_system::Config by definintion-can refer to an AccountId type by using the generic T : T::AccountId; Only where the types are made concrete will the generic AccountId resolve to a specific type. This happens in the runtime implementation of frame_system::Config where AccountId is specified as: // In the `runtime/src/lib.rs` file of the Substrate node template. pub type AccountId = <<Signature as Verify>::Signer as IdentifyAccount>::AccountId; A trait such as frame_system::Config is constrained by its associated types. Further, each type is constrained by specific traits. This makes it possible to use AccountId generically so long as it satifies those contraints. For example, the associated type for AccountId is bound by a number of traits: /// The user account identifier type for the runtime. type AccountId: Parameter + Member + MaybeSerializeDeserialize + Debug + MaybeDisplay + Ord + Default + MaxEncodedLen; Every pallet also has its own Config or \"configuration\" trait which enables defining additional associated types that are specific to that pallet. In the same way that frame_system::Config associated types are made concrete in the runtime implementation, a pallet's associated types are configured in the runtime as well. Generic types Any type can be passed into a generic so long as the type implements the traits associated with that generic. With this paradigm, we can define a struct or enum and its associated traits and types and pass it as a parameter. For example, the enum Runtime is passed as a parameter to SubstrateWeight : SubstrateWeight<T> --> SubstrateWeight<Runtime> This exemplifies that so long as the constraints of that trait are satisfied, the generic T will resolve to fit the functionality it's targeting. In this case, Runtime implements all the required traits required to satisfy SubstrateWeight<T> . Common traits In many cases there is a need to use traits and types which are shared between multiple pallets. One example is a runtime's understanding of account balance and how multiple pallets need to share the same notion of it. Instead of defining the same implementation of balances in each pallet that requires it, we can pass in any pallet that implements some Currency trait to turn generic types into concrete ones in the runtime implementation. When building with FRAME, so long as this associated type adheres to the trait bounds of a some Currency trait , it can simply pass in the runtime's instance of pallet_balances across all pallets that rely on the same notion for currency. For example, pallet_staking has an associated type Currency whose trait bound is LockableCurrency . Given that pallet_balances implements this trait, any runtime that includes the balances pallet can make the generic associated type concrete assigning it the balances pallets' runtime instance. Metaprogramming . Substrate uses \"metaprogramming\" in how macros are used throughout its libraries. This allows developers building with Substrate to write code that writes code, avoiding the need to write duplicate code. For example, FRAME uses macros to alleviate the need to write the heavy lifting code that is required for a pallet to integrate into a runtime. Similarly, ink! uses macros to handle common type creations and functions. Webassembly Webassembly . Rust compiles to executable Wasm (Webassembly) byte code, enabling Substrate runtimes to also compile to Wasm. Beyond being a powerful \"next-generation web\" technology, for Substrate, having Wasm at the core of its design means a few very specific things: Upgradability . First and foremost, Wasm is a key piece of technology for forkless runtime upgrades . Portability . Relay chain validators use Wasm to execute any new parachain block to verify that they can actually execute it and get the same results. Smart contract compatibility . Any Smart Contract that compiles to Wasm can be executed by a compatible Substrate node. See a list of key advantages of having Wasm smart contracts . Light-client ready . Wasm is also a key piece in how all Substrate chains are light-client ready out of the box . Build environments Rust is an embedded programming language. This means it is designed for writing programs that don't need to rely on the standards of existing operating systems to run. There are two classes of embedded programming environemnts: hosted environments and bare metal environments. Hosted environments assume basic system integration primitives such as a file and memory management system (e.g. POSIX ) and rely on the Rust standard library . In bare metal environments, the compiled program makes no assumption about its target environment. This requires exclusively using the Rust core library for such programs and telling the compiler to ignore the standard library entirely. For Substrate, having a bare metal environment option is a major contribution to enabling platform agnostic runtimes. Compiling to no_std vs. std Since a Substrate runtime is designed to be platform-agnostic, all runtime specific code is required to build with no_std . This is done by including a default crate feature, std and using the cfg_attr and cfg attributes as a switch to disable std in favor of no_std where needed. Notice that in the Substrate node template, any file that's part of the node's runtime logic (such as runtime/src/lib.rs and pallets/template/src/lib.rs ) will include: #![cfg_attr(not(feature = \"std\"), no_std)] This means that the code that follows this line will be treated as no_std except for code that is identified as feature = \"std\" . This prevents the std crate from being automatically added into scope. For code that requires the std crate, we simply trigger the conditional switch: // in runtime/src/lib.rs #[cfg(feature = \"std\")] use sp_version::NativeVersion; Wasm target By design, a Substrate node is cross-compiled to embed the Wasm runtime in the client at genesis. To achieve this we need to specifiy a Wasm target for the compiler. A target is simply information for the compiler to know what platform the code should be generated for. Rust can support a multitude of target platforms . Each target is identified as a triple which informs the compiler what kind of output a program expects. A target triple takes the form of: <architecture-type>-<vendor>-<os-type> When setting up your Rust environment , the compiler will default to using the host toolchain's platform as the target. For example: x86_64-unknown-linux-gnu In order to compile to Wasm, you need to add the wasm32-unknown-unknown target . This triple translates to: \" compile to a Wasm target of 32-bit address space and make no assumptions about the host and target environments \". The result is that it can run on any type of 32-bit CPU. Other Wasm targets for Rust do exist. However, the \"unknown\" parts of this Wasm target enforces the notion of making zero assumptions about the target environment, which is a key design decision in Substrate. It is also worth mentioning that there is std support for Substrate's Wasm target. But this is not something that Wasm runtimes in Substrate support as it could open up unwanted errors. In addition, the wasm32-unknown-unknown target architecture and no_std have the same fundamental assumptions, making no_std a natural fit. Rust std features are generally not compatible with the intended constraints of a Wasm runtime. For example, developers who attempt operations that are not allowed in the runtime, such as printing some text using std , could at worst cause the runtime to panic and terminate immediately. In general, relying only the no_std implementation of wasm32-unknown-unknown ensures that: A Substrate runtime is deterministic. A Substrate runtime is platform agnostic. A Substrate runtime is safe from unhandled errors. Toolchains Wasm runtime compilation uses Wasm builder which requires having a nightly toolchain installed. This is because the wasm32-unknown-unknown relies on experimental features of Rust . Over time, features will likely be promoted to stable. Subscribe to this tracking issue for updates and read more about the build process to understand how a Substrate node is cross-compiled. Resources Cargo and crates.io Rust blog post Why Rust for smart contracts?","title":"Substrates Rust"},{"location":"main-docs/02-fundamentals/rust-basics/#cargo-and-cratesio","text":"Cargo is Rust's package management tool. It comes with a number of different types of commands for running tests, building documentation, benchmarks and more. Some common patterns for using cargo when developing with Substrate include: Generating source code documentation using cargo doc for any pallet or runtime. Running unit tests using cargo test for any runtime logic. Managing project dependencies using cargo update and cargo edit . Using cargo tree for resolving dependency issues. Using cargo remote to speed up compile times by using a remote machine. The complete list of cargo plugins can be found here . Crates.io is Rust's community managed package registry. Any Rust developer can publish their crates there for others to use in their projects. This is useful to make Substrate components accessible to developers and for developers to easily reuse existing modules in their projects.","title":"Cargo and crates.io"},{"location":"main-docs/02-fundamentals/rust-basics/#programming-paradigms","text":"Types, traits and generics . Reading: - https://doc.rust-lang.org/book/ch10-00-generics.html Rust has a sophisticated trait system that helps developers make use of Substrate\u2019s many layers of abstractions. The core features available to build abstractions are owed to Rust's system of traits and generics. Generics allow Substrate to exist as a sort of template for writing runtimes. They use traits to encapsulate the set of operations that can be performed on a generic type. For developers, this system makes it possible to extend domain specific logic by defining custom behavior using traits and type bounds. TODO: Make actual diagram illustrating that everything is generic and made concrete in the runtime. \u2502 Generic library | ---> made concrete ---> \u2502 Runtime \u2502 Having Substrate as generic as possible leaves maximum flexibility, where generics resolve into whatever the user defines them to resolve as. Refer to the UTXO implementation with Substrate for a demonstration of how these paradigms make Substrate flexible and modular.","title":"Programming paradigms"},{"location":"main-docs/02-fundamentals/rust-basics/#configuration-traits","text":"A common use of abstractions in Susbtrate is the use of the Config trait from frame_system when developing pallets . This is the trait responsible for declaring the types that are commonly used in developing Substrate runtimes. With it there is no need to duplicate code that declares a type that's used in several places, such as AccountId . Instead, any pallet-which is coupled to frame_system::Config by definintion-can refer to an AccountId type by using the generic T : T::AccountId; Only where the types are made concrete will the generic AccountId resolve to a specific type. This happens in the runtime implementation of frame_system::Config where AccountId is specified as: // In the `runtime/src/lib.rs` file of the Substrate node template. pub type AccountId = <<Signature as Verify>::Signer as IdentifyAccount>::AccountId; A trait such as frame_system::Config is constrained by its associated types. Further, each type is constrained by specific traits. This makes it possible to use AccountId generically so long as it satifies those contraints. For example, the associated type for AccountId is bound by a number of traits: /// The user account identifier type for the runtime. type AccountId: Parameter + Member + MaybeSerializeDeserialize + Debug + MaybeDisplay + Ord + Default + MaxEncodedLen; Every pallet also has its own Config or \"configuration\" trait which enables defining additional associated types that are specific to that pallet. In the same way that frame_system::Config associated types are made concrete in the runtime implementation, a pallet's associated types are configured in the runtime as well.","title":"Configuration traits"},{"location":"main-docs/02-fundamentals/rust-basics/#generic-types","text":"Any type can be passed into a generic so long as the type implements the traits associated with that generic. With this paradigm, we can define a struct or enum and its associated traits and types and pass it as a parameter. For example, the enum Runtime is passed as a parameter to SubstrateWeight : SubstrateWeight<T> --> SubstrateWeight<Runtime> This exemplifies that so long as the constraints of that trait are satisfied, the generic T will resolve to fit the functionality it's targeting. In this case, Runtime implements all the required traits required to satisfy SubstrateWeight<T> .","title":"Generic types"},{"location":"main-docs/02-fundamentals/rust-basics/#common-traits","text":"In many cases there is a need to use traits and types which are shared between multiple pallets. One example is a runtime's understanding of account balance and how multiple pallets need to share the same notion of it. Instead of defining the same implementation of balances in each pallet that requires it, we can pass in any pallet that implements some Currency trait to turn generic types into concrete ones in the runtime implementation. When building with FRAME, so long as this associated type adheres to the trait bounds of a some Currency trait , it can simply pass in the runtime's instance of pallet_balances across all pallets that rely on the same notion for currency. For example, pallet_staking has an associated type Currency whose trait bound is LockableCurrency . Given that pallet_balances implements this trait, any runtime that includes the balances pallet can make the generic associated type concrete assigning it the balances pallets' runtime instance. Metaprogramming . Substrate uses \"metaprogramming\" in how macros are used throughout its libraries. This allows developers building with Substrate to write code that writes code, avoiding the need to write duplicate code. For example, FRAME uses macros to alleviate the need to write the heavy lifting code that is required for a pallet to integrate into a runtime. Similarly, ink! uses macros to handle common type creations and functions.","title":"Common traits"},{"location":"main-docs/02-fundamentals/rust-basics/#webassembly","text":"Webassembly . Rust compiles to executable Wasm (Webassembly) byte code, enabling Substrate runtimes to also compile to Wasm. Beyond being a powerful \"next-generation web\" technology, for Substrate, having Wasm at the core of its design means a few very specific things: Upgradability . First and foremost, Wasm is a key piece of technology for forkless runtime upgrades . Portability . Relay chain validators use Wasm to execute any new parachain block to verify that they can actually execute it and get the same results. Smart contract compatibility . Any Smart Contract that compiles to Wasm can be executed by a compatible Substrate node. See a list of key advantages of having Wasm smart contracts . Light-client ready . Wasm is also a key piece in how all Substrate chains are light-client ready out of the box .","title":"Webassembly"},{"location":"main-docs/02-fundamentals/rust-basics/#build-environments","text":"Rust is an embedded programming language. This means it is designed for writing programs that don't need to rely on the standards of existing operating systems to run. There are two classes of embedded programming environemnts: hosted environments and bare metal environments. Hosted environments assume basic system integration primitives such as a file and memory management system (e.g. POSIX ) and rely on the Rust standard library . In bare metal environments, the compiled program makes no assumption about its target environment. This requires exclusively using the Rust core library for such programs and telling the compiler to ignore the standard library entirely. For Substrate, having a bare metal environment option is a major contribution to enabling platform agnostic runtimes.","title":"Build environments"},{"location":"main-docs/02-fundamentals/rust-basics/#compiling-to-no_std-vs-std","text":"Since a Substrate runtime is designed to be platform-agnostic, all runtime specific code is required to build with no_std . This is done by including a default crate feature, std and using the cfg_attr and cfg attributes as a switch to disable std in favor of no_std where needed. Notice that in the Substrate node template, any file that's part of the node's runtime logic (such as runtime/src/lib.rs and pallets/template/src/lib.rs ) will include: #![cfg_attr(not(feature = \"std\"), no_std)] This means that the code that follows this line will be treated as no_std except for code that is identified as feature = \"std\" . This prevents the std crate from being automatically added into scope. For code that requires the std crate, we simply trigger the conditional switch: // in runtime/src/lib.rs #[cfg(feature = \"std\")] use sp_version::NativeVersion;","title":"Compiling to no_std vs. std"},{"location":"main-docs/02-fundamentals/rust-basics/#wasm-target","text":"By design, a Substrate node is cross-compiled to embed the Wasm runtime in the client at genesis. To achieve this we need to specifiy a Wasm target for the compiler. A target is simply information for the compiler to know what platform the code should be generated for. Rust can support a multitude of target platforms . Each target is identified as a triple which informs the compiler what kind of output a program expects. A target triple takes the form of: <architecture-type>-<vendor>-<os-type> When setting up your Rust environment , the compiler will default to using the host toolchain's platform as the target. For example: x86_64-unknown-linux-gnu In order to compile to Wasm, you need to add the wasm32-unknown-unknown target . This triple translates to: \" compile to a Wasm target of 32-bit address space and make no assumptions about the host and target environments \". The result is that it can run on any type of 32-bit CPU. Other Wasm targets for Rust do exist. However, the \"unknown\" parts of this Wasm target enforces the notion of making zero assumptions about the target environment, which is a key design decision in Substrate. It is also worth mentioning that there is std support for Substrate's Wasm target. But this is not something that Wasm runtimes in Substrate support as it could open up unwanted errors. In addition, the wasm32-unknown-unknown target architecture and no_std have the same fundamental assumptions, making no_std a natural fit. Rust std features are generally not compatible with the intended constraints of a Wasm runtime. For example, developers who attempt operations that are not allowed in the runtime, such as printing some text using std , could at worst cause the runtime to panic and terminate immediately. In general, relying only the no_std implementation of wasm32-unknown-unknown ensures that: A Substrate runtime is deterministic. A Substrate runtime is platform agnostic. A Substrate runtime is safe from unhandled errors.","title":"Wasm target"},{"location":"main-docs/02-fundamentals/rust-basics/#toolchains","text":"Wasm runtime compilation uses Wasm builder which requires having a nightly toolchain installed. This is because the wasm32-unknown-unknown relies on experimental features of Rust . Over time, features will likely be promoted to stable. Subscribe to this tracking issue for updates and read more about the build process to understand how a Substrate node is cross-compiled.","title":"Toolchains"},{"location":"main-docs/02-fundamentals/rust-basics/#resources","text":"Cargo and crates.io Rust blog post Why Rust for smart contracts?","title":"Resources"},{"location":"main-docs/02-fundamentals/state-transitions-and-storage/","text":"TODO","title":"State transitions and storage"},{"location":"main-docs/02-fundamentals/transaction-lifecycle/","text":"","title":"Transaction lifecycle"},{"location":"main-docs/02-fundamentals/transaction-lifecyle/","text":"TODO","title":"Transaction lifecycle"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/","text":"When transactions are executed or data is stored on-chain, the activity changes the state of the chain and consumes blockchain resources. Because the resources available to a blockchain are limited, it\u2019s important to manage how operations on-chain consume them. In addition to being limited in practical terms\u2014such as storage capacity\u2014blockchain resources represent a potential attack vector for malicious users. For example, a malicious user might attempt to overload the network with messages to stop the network from producing new blocks. To protect blockchain resources from being drained or overloaded, you need to manage how they are made available and how they are consumed. The resources to be aware of include: Memory usage Storage input and output Computation Transaction and block size State database size Substrate provides block authors with several ways to manage access to resources and to prevent individual components of the chain from consuming too much of any single resource. Two of the most important mechanisms available to block authors are weights and transaction fees . Weights are used to manage the time it takes to validate a block. In general, weights are used to characterize the time it takes to execute the extrinsic calls in the body of a block. By controlling the execution time that a block can consume, weights set limits on storage input and output and computation. Some of the weight allowed for a block is consumed as part of the block's initialization and finalization. The weight might also be used to execute mandatory inherent extrinsic calls. To help ensure blocks don\u2019t consume too much execution time\u2014and prevent malicious users from overloading the system with unnecessary calls\u2014weights are used in combination with transaction fees . Transaction fees provide an economic incentive to limit execution time, computation, and the number of calls required to perform operations. Transaction fees are also used to make the blockchain economically sustainable because they are typically applied to transactions initiated by users and deducted before a transaction request is executed. How fees are calculated The final fee for a transaction is calculated using the following parameters: base fee : This is the minimum amount a user pays for a transaction. It is declared as a base weight in the runtime and converted to a fee using WeightToFee . weight fee : A fee proportional to the execution time (input and output and computation) that a transaction consumes. length fee : A fee proportional to the encoded length of the transaction. tip : An optional tip to increase the priority of the transaction, giving it a higher chance to be included by the transaction queue. The base fee and proportional weight and length fees constitute the inclusion fee . The inclusion fee is the minimum fee that must be available for a transaction to be included in a block. Using the transaction payment pallet The Transaction Payment pallet provides the basic logic for calculating the inclusion fee. You can also use the Transaction Payment pallet to: Convert a weight value into a deductible fee based on a currency type using Config::WeightToFee . Update the fee for the next block by defining a multiplier, based on the final state of the chain at the end of the previous block using Config::FeeMultiplierUpdate . Manage the withdrawal, refund, and deposit of transaction fees using Config::OnChargeTransaction . You can learn more about these configuration traits in the Transaction Payment documentation. You should note that transaction fees are withdrawn before the transaction is executed. After the transaction is executed, the transaction weight can be adjusted to reflect the actual resources the transaction used. If a transaction uses fewer resources than expected, the transaction fee is corrected and the adjusted transaction fee is deposited. A closer look at the inclusion fee The formula for calculating the final fee looks like this: inclusion_fee = base_fee + length_fee + [targeted_fee_adjustment * weight_fee]; final_fee = inclusion_fee + tip; In this formula, the targeted_fee_adjustment is a multiplier that can tune the final fee based on the congestion of the network. The base_fee derived from the base weight covers inclusion overhead like signature verification. The length_fee is a per-byte fee that is multiplied by the length of the encoded extrinsic. The weight_fee fee is calculated using two parameters: The ExtrinsicBaseWeight that is declared in the runtime and applies to all extrinsics. The #[pallet::weight] annotation that accounts for an extrinsic's complexity. To convert the weight to Currency, the runtime must define a WeightToFee struct that implements a conversion function, Convert<Weight,Balance> . Note that the extrinsic sender is charged the inclusion fee before the extrinsic is invoked. The fee is deducted from the sender's balance even if the transaction fails upon execution. Accounts with an insufficient balance If an account does not have a sufficient balance to pay the inclusion fee and remain alive\u2014that is, enough to pay the inclusion fee and maintain the minimum existential deposit \u2014then you should ensure the transaction is cancelled so that no fee is deducted and the transaction does not begin execution. Substrate does not enforce this rollback behavior. However, this scenario would be a rare occurrence because the transaction queue and block-making logic perform checks to prevent it before adding an extrinsic to a block. Fee multiplier The inclusion fee formula always results in the same fee for the same input. However, weight can be dynamic and\u2014based on how WeightToFee is defined\u2014the final fee can include some degree of variability. To account for this variability, the Transaction Payment pallet provides the FeeMultiplierUpdate configurable parameter. The default update function is inspired by the Polkadot network and implements a targeted adjustment in which a target saturation level of block weight is defined. If the previous block is more saturated, then the fees are slightly increased. Similarly, if the previous block has fewer transactions than the target, fees are decreased by a small amount. For more information about fee multiplier adjustments, see the Web3 research page . Transactions with special requirements Inclusion fees must be computable prior to execution, and therefore can only represent fixed logic. Some transactions warrant limiting resources with other strategies. For example: Bonds are a type of fee that might be returned or slashed after some on-chain event. For example, you might want to require users to place a bond to participate in a vote. The bond might then be returned at the end of the referendum or slashed if the voter attempted malicious behavior. Deposits are fees that might be returned later. For example, you might require users to pay a deposit to execute an operation that uses storage. If a subsequent operation frees up storage, the user's deposit could be returned. Burn operations are used to pay for a transaction based on its internal logic. For example, a transaction might burn funds from the sender if the transaction creates new storage items to pay for the increased the state size. Limits enable you to enforce constant or configurable limits on certain operations. For example, the default Staking pallet only allows nominators to nominate 16 validators to limit the complexity of the validator election process. It is important to note that if you query the chain for a transaction fee, it only returns the inclusion fee. Default weight annotations All dispatchable functions in Substrate must specify a weight. The way of doing that is using the annotation-based system that lets you combine fixed values for database read/write weight and/or fixed values based on benchmarks. The most basic example would look like this: #[pallet::weight(100_000)] fn my_dispatchable() { // ... } Note that the ExtrinsicBaseWeight is automatically added to the declared weight to account for the costs of simply including an empty extrinsic into a block. Weights and database read/write operations To make weight annotations independent of the deployed database backend, they are defined as a constant and then used in the annotations when expressing database accesses performed by the dispatchable: #[pallet::weight(T::DbWeight::get().reads_writes(1, 2) + 20_000)] fn my_dispatchable() { // ... } This dispatchable does one database read and two database writes in addition to other things that add the additional 20,000. A database access is generally every time a value that is declared inside the #[pallet::storage] block is accessed. However, only unique accesses are counted because after a value is accessed it is cached and accessing it again does not result in a database operation. That is: Multiple reads of the same value count as one read. Multiple writes of the same value count as one write. Multiple reads of the same value, followed by a write to that value, count as one read and one write. A write followed by a read only counts as one write. Dispatch classes Dispatches are broken into three classes: Normal Operational Mandatory If a dispatch is not defined as Operational or Mandatory in the weight annotation, the dispatch is identified as Normal by default. You can specify that the dispatchable uses another class like this: #[pallet::weight(100_000, DispatchClass::Operational)] fn my_dispatchable() { // ... } This tuple notation also allows you to specify a final argument that determines whether or not the user is charged based on the annotated weight. If you don't specify otherwise, Pays::Yes is assumed: #[pallet::weight(100_000, DispatchClass::Normal, Pays::No)] fn my_dispatchable() { // ... } Normal dispatches Dispatches in this class represent normal user-triggered transactions. These types of dispatches only consume a portion of a block's total weight limit. For information about the maximum portion of a block that can be consumed for normal dispatches, see AvailableBlockRatio . Normal dispatches are sent to the transaction pool . Operational dispatches Unlike normal dispatches, which represent usage of network capabilities, operational dispatches are those that provide network capabilities. Operational dispatches can consume the entire weight limit of a block. They are not bound by the AvailableBlockRatio . Dispatches in this class are given maximum priority and are exempt from paying the length_fee . Mandatory dispatches Mandatory dispatches are included in a block even if they cause the block to surpass its weight limit. You can only use the mandatory dispatch class for inherents . This dispatch class is intended to represent functions that are part of the block validation process. Because these dispatches are always included in a block regardless of the function weight, it is critical that the validation process prevents malicious nodes from abusing the function to craft blocks that are valid but impossibly heavy. You can typically accomplish this by ensuring that: The operation performed is always light. The operation can only be included in a block once. To make it more difficult for malicious nodes to abuse mandatory dispatches, they cannot be included in blocks that return errors. This dispatch class exists to serve the assumption that it is better to allow an overweight block to be created than to not allow any block to be created at all. Dynamic weights In addition to purely fixed weights and constants, the weight calculation can consider the input arguments of a dispatchable. The weight should be trivially computable from the input arguments with some basic arithmetic: #[pallet::weight(FunctionOf( |args: (&Vec<User>,)| args.0.len().saturating_mul(10_000), DispatchClass::Normal, Pays::Yes, ))] fn handle_users(origin, calls: Vec<User>) { // Do something per user } Post dispatch weight correction Depending on the execution logic, a dispatchable might consume less weight than was prescribed pre-dispatch. Why this is useful is explained in the weights article . To correct weight, the dispatchable declares a different return type and returns its actual weight: #[pallet::weight(10_000 + 500_000_000)] fn expensive_or_cheap(input: u64) -> DispatchResultWithPostInfo { let was_heavy = do_calculation(input); if (was_heavy) { // None means \"no correction\" from the weight annotation. Ok(None.into()) } else { // Return the actual weight consumed. Ok(Some(10_000).into()) } } Custom fees You can also define custom fee systems through custom weight functions or inclusion fee functions. Custom weights Instead of using the default weight annotations, you can create a custom weight calculation type. The custom weight calculation type must implement the follow traits: [ WeighData<T> ] to determine the weight of the dispatch. [ ClassifyDispatch<T> ] to determine the class of the dispatch. [ PaysFee<T> ] to determine whether the dispatchable's sender pays fees. Substrate then bundles the output information of the two traits into the [ DispatchInfo ] struct and provides it by implementing the [ GetDispatchInfo ] for all Call variants and opaque extrinsic types. This is used internally by the System and Executive modules. ClassifyDispatch , WeighData , and PaysFee are generic over T , which gets resolved into the tuple of all dispatch arguments except for the origin. The following example illustrates a struct that calculates the weight as m * len(args) where m is a given multiplier and args is the concatenated tuple of all dispatch arguments. In this example, the dispatch class is Operational if the transaction has more than 100 bytes of length in arguments and will pay fees if the encoded length is greater than 10 bytes. struct LenWeight(u32); impl<T> WeighData<T> for LenWeight { fn weigh_data(&self, target: T) -> Weight { let multiplier = self.0; let encoded_len = target.encode().len() as u32; multiplier * encoded_len } } impl<T> ClassifyDispatch<T> for LenWeight { fn classify_dispatch(&self, target: T) -> DispatchClass { let encoded_len = target.encode().len() as u32; if encoded_len > 100 { DispatchClass::Operational } else { DispatchClass::Normal } } } impl<T> PaysFee<T> { fn pays_fee(&self, target: T) -> Pays { let encoded_len = target.encode().len() as u32; if encoded_len > 10 { Pays::Yes } else { Pays::No } } } A weight calculator function can also be coerced to the final type of the argument, instead of defining it as a vague type that can be encoded. The code would roughly look like this: struct CustomWeight; impl WeighData<(&u32, &u64)> for CustomWeight { fn weigh_data(&self, target: (&u32, &u64)) -> Weight { ... } } // given a dispatch: #[pallet::call] impl<T: Config<I>, I: 'static> Pallet<T, I> { #[pallet::weight(CustomWeight)] fn foo(a: u32, b: u64) { ... } } In this example, the CustomWeight can only be used in conjunction with a dispatch with a particular signature (u32, u64) , as opposed to LenWeight , which can be used with anything because there aren't any assumptions about <T> . Custom inclusion fee The following example illustrates how to customize your inclusion fee. You must configure the appropriate associated types in the respective module. // Assume this is the balance type type Balance = u64; // Assume we want all the weights to have a `100 + 2 * w` conversion to fees struct CustomWeightToFee; impl Convert<Weight, Balance> for CustomWeightToFee { fn convert(w: Weight) -> Balance { let a = Balance::from(100); let b = Balance::from(2); let w = Balance::from(w); a + b * w } } parameter_types! { pub const ExtrinsicBaseWeight: Weight = 10_000_000; } impl frame_system::Config for Runtime { type ExtrinsicBaseWeight = ExtrinsicBaseWeight; } parameter_types! { pub const TransactionByteFee: Balance = 10; } impl transaction_payment::Config { type TransactionByteFee = TransactionByteFee; type WeightToFee = CustomWeightToFee; type FeeMultiplierUpdate = TargetedFeeAdjustment<TargetBlockFullness>; } struct TargetedFeeAdjustment<T>(sp_std::marker::PhantomData<T>); impl<T: Get<Perquintill>> Convert<Fixed128, Fixed128> for TargetedFeeAdjustment<T> { fn convert(multiplier: Fixed128) -> Fixed128 { // Don't change anything. Put any fee update info here. multiplier } } Next steps The entire logic of fees is encapsulated in pallet-transaction-payment using a SignedExtension . This pallet provides flexibility for implementing transaction payments. Alternatively, you can refer to the transaction payment pallet for inspiration and build a completely custom payment module. You now know what the weight system is, how it affects transaction fee computation, and how to specify weights for your dispatchable calls. The next step is determining the correct weight to account for the operations your dispatchable performs. You can use Substrate benchmarking functions and frame-benchmarking calls to test your functions with different parameters and empirically determine the correct weight in their worst case scenarios. For more information, see Benchmarking . Dedicated weight documentation Example pallet SignedExtension Examples You can find examples of custom weights and fees in the following repositories: Custom weights for the Example pallet Custom WeightToFee how-to guide References Web3 Foundation Research","title":"Transactions, weights, and fees"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#how-fees-are-calculated","text":"The final fee for a transaction is calculated using the following parameters: base fee : This is the minimum amount a user pays for a transaction. It is declared as a base weight in the runtime and converted to a fee using WeightToFee . weight fee : A fee proportional to the execution time (input and output and computation) that a transaction consumes. length fee : A fee proportional to the encoded length of the transaction. tip : An optional tip to increase the priority of the transaction, giving it a higher chance to be included by the transaction queue. The base fee and proportional weight and length fees constitute the inclusion fee . The inclusion fee is the minimum fee that must be available for a transaction to be included in a block.","title":"How fees are calculated"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#using-the-transaction-payment-pallet","text":"The Transaction Payment pallet provides the basic logic for calculating the inclusion fee. You can also use the Transaction Payment pallet to: Convert a weight value into a deductible fee based on a currency type using Config::WeightToFee . Update the fee for the next block by defining a multiplier, based on the final state of the chain at the end of the previous block using Config::FeeMultiplierUpdate . Manage the withdrawal, refund, and deposit of transaction fees using Config::OnChargeTransaction . You can learn more about these configuration traits in the Transaction Payment documentation. You should note that transaction fees are withdrawn before the transaction is executed. After the transaction is executed, the transaction weight can be adjusted to reflect the actual resources the transaction used. If a transaction uses fewer resources than expected, the transaction fee is corrected and the adjusted transaction fee is deposited.","title":"Using the transaction payment pallet"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#a-closer-look-at-the-inclusion-fee","text":"The formula for calculating the final fee looks like this: inclusion_fee = base_fee + length_fee + [targeted_fee_adjustment * weight_fee]; final_fee = inclusion_fee + tip; In this formula, the targeted_fee_adjustment is a multiplier that can tune the final fee based on the congestion of the network. The base_fee derived from the base weight covers inclusion overhead like signature verification. The length_fee is a per-byte fee that is multiplied by the length of the encoded extrinsic. The weight_fee fee is calculated using two parameters: The ExtrinsicBaseWeight that is declared in the runtime and applies to all extrinsics. The #[pallet::weight] annotation that accounts for an extrinsic's complexity. To convert the weight to Currency, the runtime must define a WeightToFee struct that implements a conversion function, Convert<Weight,Balance> . Note that the extrinsic sender is charged the inclusion fee before the extrinsic is invoked. The fee is deducted from the sender's balance even if the transaction fails upon execution.","title":"A closer look at the inclusion fee"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#accounts-with-an-insufficient-balance","text":"If an account does not have a sufficient balance to pay the inclusion fee and remain alive\u2014that is, enough to pay the inclusion fee and maintain the minimum existential deposit \u2014then you should ensure the transaction is cancelled so that no fee is deducted and the transaction does not begin execution. Substrate does not enforce this rollback behavior. However, this scenario would be a rare occurrence because the transaction queue and block-making logic perform checks to prevent it before adding an extrinsic to a block.","title":"Accounts with an insufficient balance"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#fee-multiplier","text":"The inclusion fee formula always results in the same fee for the same input. However, weight can be dynamic and\u2014based on how WeightToFee is defined\u2014the final fee can include some degree of variability. To account for this variability, the Transaction Payment pallet provides the FeeMultiplierUpdate configurable parameter. The default update function is inspired by the Polkadot network and implements a targeted adjustment in which a target saturation level of block weight is defined. If the previous block is more saturated, then the fees are slightly increased. Similarly, if the previous block has fewer transactions than the target, fees are decreased by a small amount. For more information about fee multiplier adjustments, see the Web3 research page .","title":"Fee multiplier"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#transactions-with-special-requirements","text":"Inclusion fees must be computable prior to execution, and therefore can only represent fixed logic. Some transactions warrant limiting resources with other strategies. For example: Bonds are a type of fee that might be returned or slashed after some on-chain event. For example, you might want to require users to place a bond to participate in a vote. The bond might then be returned at the end of the referendum or slashed if the voter attempted malicious behavior. Deposits are fees that might be returned later. For example, you might require users to pay a deposit to execute an operation that uses storage. If a subsequent operation frees up storage, the user's deposit could be returned. Burn operations are used to pay for a transaction based on its internal logic. For example, a transaction might burn funds from the sender if the transaction creates new storage items to pay for the increased the state size. Limits enable you to enforce constant or configurable limits on certain operations. For example, the default Staking pallet only allows nominators to nominate 16 validators to limit the complexity of the validator election process. It is important to note that if you query the chain for a transaction fee, it only returns the inclusion fee.","title":"Transactions with special requirements"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#default-weight-annotations","text":"All dispatchable functions in Substrate must specify a weight. The way of doing that is using the annotation-based system that lets you combine fixed values for database read/write weight and/or fixed values based on benchmarks. The most basic example would look like this: #[pallet::weight(100_000)] fn my_dispatchable() { // ... } Note that the ExtrinsicBaseWeight is automatically added to the declared weight to account for the costs of simply including an empty extrinsic into a block.","title":"Default weight annotations"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#weights-and-database-readwrite-operations","text":"To make weight annotations independent of the deployed database backend, they are defined as a constant and then used in the annotations when expressing database accesses performed by the dispatchable: #[pallet::weight(T::DbWeight::get().reads_writes(1, 2) + 20_000)] fn my_dispatchable() { // ... } This dispatchable does one database read and two database writes in addition to other things that add the additional 20,000. A database access is generally every time a value that is declared inside the #[pallet::storage] block is accessed. However, only unique accesses are counted because after a value is accessed it is cached and accessing it again does not result in a database operation. That is: Multiple reads of the same value count as one read. Multiple writes of the same value count as one write. Multiple reads of the same value, followed by a write to that value, count as one read and one write. A write followed by a read only counts as one write.","title":"Weights and database read/write operations"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#dispatch-classes","text":"Dispatches are broken into three classes: Normal Operational Mandatory If a dispatch is not defined as Operational or Mandatory in the weight annotation, the dispatch is identified as Normal by default. You can specify that the dispatchable uses another class like this: #[pallet::weight(100_000, DispatchClass::Operational)] fn my_dispatchable() { // ... } This tuple notation also allows you to specify a final argument that determines whether or not the user is charged based on the annotated weight. If you don't specify otherwise, Pays::Yes is assumed: #[pallet::weight(100_000, DispatchClass::Normal, Pays::No)] fn my_dispatchable() { // ... }","title":"Dispatch classes"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#normal-dispatches","text":"Dispatches in this class represent normal user-triggered transactions. These types of dispatches only consume a portion of a block's total weight limit. For information about the maximum portion of a block that can be consumed for normal dispatches, see AvailableBlockRatio . Normal dispatches are sent to the transaction pool .","title":"Normal dispatches"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#operational-dispatches","text":"Unlike normal dispatches, which represent usage of network capabilities, operational dispatches are those that provide network capabilities. Operational dispatches can consume the entire weight limit of a block. They are not bound by the AvailableBlockRatio . Dispatches in this class are given maximum priority and are exempt from paying the length_fee .","title":"Operational dispatches"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#mandatory-dispatches","text":"Mandatory dispatches are included in a block even if they cause the block to surpass its weight limit. You can only use the mandatory dispatch class for inherents . This dispatch class is intended to represent functions that are part of the block validation process. Because these dispatches are always included in a block regardless of the function weight, it is critical that the validation process prevents malicious nodes from abusing the function to craft blocks that are valid but impossibly heavy. You can typically accomplish this by ensuring that: The operation performed is always light. The operation can only be included in a block once. To make it more difficult for malicious nodes to abuse mandatory dispatches, they cannot be included in blocks that return errors. This dispatch class exists to serve the assumption that it is better to allow an overweight block to be created than to not allow any block to be created at all.","title":"Mandatory dispatches"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#dynamic-weights","text":"In addition to purely fixed weights and constants, the weight calculation can consider the input arguments of a dispatchable. The weight should be trivially computable from the input arguments with some basic arithmetic: #[pallet::weight(FunctionOf( |args: (&Vec<User>,)| args.0.len().saturating_mul(10_000), DispatchClass::Normal, Pays::Yes, ))] fn handle_users(origin, calls: Vec<User>) { // Do something per user }","title":"Dynamic weights"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#post-dispatch-weight-correction","text":"Depending on the execution logic, a dispatchable might consume less weight than was prescribed pre-dispatch. Why this is useful is explained in the weights article . To correct weight, the dispatchable declares a different return type and returns its actual weight: #[pallet::weight(10_000 + 500_000_000)] fn expensive_or_cheap(input: u64) -> DispatchResultWithPostInfo { let was_heavy = do_calculation(input); if (was_heavy) { // None means \"no correction\" from the weight annotation. Ok(None.into()) } else { // Return the actual weight consumed. Ok(Some(10_000).into()) } }","title":"Post dispatch weight correction"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#custom-fees","text":"You can also define custom fee systems through custom weight functions or inclusion fee functions.","title":"Custom fees"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#custom-weights","text":"Instead of using the default weight annotations, you can create a custom weight calculation type. The custom weight calculation type must implement the follow traits: [ WeighData<T> ] to determine the weight of the dispatch. [ ClassifyDispatch<T> ] to determine the class of the dispatch. [ PaysFee<T> ] to determine whether the dispatchable's sender pays fees. Substrate then bundles the output information of the two traits into the [ DispatchInfo ] struct and provides it by implementing the [ GetDispatchInfo ] for all Call variants and opaque extrinsic types. This is used internally by the System and Executive modules. ClassifyDispatch , WeighData , and PaysFee are generic over T , which gets resolved into the tuple of all dispatch arguments except for the origin. The following example illustrates a struct that calculates the weight as m * len(args) where m is a given multiplier and args is the concatenated tuple of all dispatch arguments. In this example, the dispatch class is Operational if the transaction has more than 100 bytes of length in arguments and will pay fees if the encoded length is greater than 10 bytes. struct LenWeight(u32); impl<T> WeighData<T> for LenWeight { fn weigh_data(&self, target: T) -> Weight { let multiplier = self.0; let encoded_len = target.encode().len() as u32; multiplier * encoded_len } } impl<T> ClassifyDispatch<T> for LenWeight { fn classify_dispatch(&self, target: T) -> DispatchClass { let encoded_len = target.encode().len() as u32; if encoded_len > 100 { DispatchClass::Operational } else { DispatchClass::Normal } } } impl<T> PaysFee<T> { fn pays_fee(&self, target: T) -> Pays { let encoded_len = target.encode().len() as u32; if encoded_len > 10 { Pays::Yes } else { Pays::No } } } A weight calculator function can also be coerced to the final type of the argument, instead of defining it as a vague type that can be encoded. The code would roughly look like this: struct CustomWeight; impl WeighData<(&u32, &u64)> for CustomWeight { fn weigh_data(&self, target: (&u32, &u64)) -> Weight { ... } } // given a dispatch: #[pallet::call] impl<T: Config<I>, I: 'static> Pallet<T, I> { #[pallet::weight(CustomWeight)] fn foo(a: u32, b: u64) { ... } } In this example, the CustomWeight can only be used in conjunction with a dispatch with a particular signature (u32, u64) , as opposed to LenWeight , which can be used with anything because there aren't any assumptions about <T> .","title":"Custom weights"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#custom-inclusion-fee","text":"The following example illustrates how to customize your inclusion fee. You must configure the appropriate associated types in the respective module. // Assume this is the balance type type Balance = u64; // Assume we want all the weights to have a `100 + 2 * w` conversion to fees struct CustomWeightToFee; impl Convert<Weight, Balance> for CustomWeightToFee { fn convert(w: Weight) -> Balance { let a = Balance::from(100); let b = Balance::from(2); let w = Balance::from(w); a + b * w } } parameter_types! { pub const ExtrinsicBaseWeight: Weight = 10_000_000; } impl frame_system::Config for Runtime { type ExtrinsicBaseWeight = ExtrinsicBaseWeight; } parameter_types! { pub const TransactionByteFee: Balance = 10; } impl transaction_payment::Config { type TransactionByteFee = TransactionByteFee; type WeightToFee = CustomWeightToFee; type FeeMultiplierUpdate = TargetedFeeAdjustment<TargetBlockFullness>; } struct TargetedFeeAdjustment<T>(sp_std::marker::PhantomData<T>); impl<T: Get<Perquintill>> Convert<Fixed128, Fixed128> for TargetedFeeAdjustment<T> { fn convert(multiplier: Fixed128) -> Fixed128 { // Don't change anything. Put any fee update info here. multiplier } }","title":"Custom inclusion fee"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#next-steps","text":"The entire logic of fees is encapsulated in pallet-transaction-payment using a SignedExtension . This pallet provides flexibility for implementing transaction payments. Alternatively, you can refer to the transaction payment pallet for inspiration and build a completely custom payment module. You now know what the weight system is, how it affects transaction fee computation, and how to specify weights for your dispatchable calls. The next step is determining the correct weight to account for the operations your dispatchable performs. You can use Substrate benchmarking functions and frame-benchmarking calls to test your functions with different parameters and empirically determine the correct weight in their worst case scenarios. For more information, see Benchmarking . Dedicated weight documentation Example pallet SignedExtension","title":"Next steps"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#examples","text":"You can find examples of custom weights and fees in the following repositories: Custom weights for the Example pallet Custom WeightToFee how-to guide","title":"Examples"},{"location":"main-docs/02-fundamentals/tx-weights-and-fees/#references","text":"Web3 Foundation Research","title":"References"},{"location":"main-docs/03-install/","text":"Install Rust builds Linux macOS Windows Full node Versioning and upgrades Other tools Troubleshoot common issues","title":"Install"},{"location":"main-docs/03-install/#install","text":"Rust builds Linux macOS Windows Full node Versioning and upgrades Other tools Troubleshoot common issues","title":"Install"},{"location":"main-docs/03-install/linux/","text":"Linux development environment Supported distributions Installation instructions Verifying your installation Troubleshooting","title":"Linux"},{"location":"main-docs/03-install/linux/#linux-development-environment","text":"Supported distributions Installation instructions Verifying your installation Troubleshooting","title":"Linux development environment"},{"location":"main-docs/03-install/macos/","text":"macOS development environment Supported architecture and versions Installation instructions Verifying your installation Troubleshooting","title":"macOS"},{"location":"main-docs/03-install/macos/#macos-development-environment","text":"Supported architecture and versions Installation instructions Verifying your installation Troubleshooting","title":"macOS development environment"},{"location":"main-docs/03-install/other-tools/","text":"Substrate and runtime tools Other tools available and how to install them.","title":"Developer tools"},{"location":"main-docs/03-install/other-tools/#substrate-and-runtime-tools","text":"Other tools available and how to install them.","title":"Substrate and runtime tools"},{"location":"main-docs/03-install/rust-builds/","text":"Rust compiler and toolchain Some stuff about Rust.","title":"Rust compiler and toolchain"},{"location":"main-docs/03-install/rust-builds/#rust-compiler-and-toolchain","text":"Some stuff about Rust.","title":"Rust compiler and toolchain"},{"location":"main-docs/03-install/troubleshoot/","text":"TODO","title":"Troubleshoot common issues"},{"location":"main-docs/03-install/versioning-and-upgrades/","text":"TODO","title":"Versioning and upgrades"},{"location":"main-docs/03-install/windows/","text":"Windows development environment Supported architecture and versions Installation instructions Verifying your installation Troubleshooting","title":"Windows"},{"location":"main-docs/03-install/windows/#windows-development-environment","text":"Supported architecture and versions Installation instructions Verifying your installation Troubleshooting","title":"Windows development environment"},{"location":"main-docs/04-explore/explore/","text":"Explore Substrate sampler Road map of resources available, where to go for what. Developer Playground Build a local blockchain Curated projects on the awesome list Where to find examples Where to find reference docs Where to find videos Developer Playground TODO: All of the info in this page is mainly reference for navigation purposes. Copy page from: https://docs.substrate.io/playground/ Build a local blockchain TODO: What resources are at my disposal? Awesome list TODO: Copy page from https://substrate.io/ecosystem/resources/awesome-substrate/ Trying for a less fragmented expereince of finding what's available where. Curated projects on the awesome list Example projects TODO Videos TODO: Where to find videos (seminar, sub0 and other events).","title":"Explore"},{"location":"main-docs/04-explore/explore/#explore","text":"Substrate sampler Road map of resources available, where to go for what. Developer Playground Build a local blockchain Curated projects on the awesome list Where to find examples Where to find reference docs Where to find videos","title":"Explore"},{"location":"main-docs/04-explore/explore/#developer-playground","text":"TODO: All of the info in this page is mainly reference for navigation purposes. Copy page from: https://docs.substrate.io/playground/","title":"Developer Playground"},{"location":"main-docs/04-explore/explore/#build-a-local-blockchain","text":"TODO: What resources are at my disposal?","title":"Build a local blockchain"},{"location":"main-docs/04-explore/explore/#awesome-list","text":"TODO: Copy page from https://substrate.io/ecosystem/resources/awesome-substrate/ Trying for a less fragmented expereince of finding what's available where. Curated projects on the awesome list","title":"Awesome list"},{"location":"main-docs/04-explore/explore/#example-projects","text":"TODO","title":"Example projects"},{"location":"main-docs/04-explore/explore/#videos","text":"TODO: Where to find videos (seminar, sub0 and other events).","title":"Videos"},{"location":"main-docs/05-design/","text":"Designing your runtime Application logic in Substrate-based blockchains can be expressed in the form of: Specialized pallets : each pallet performs a special task, serving the business logic needs of the blockchain. Smart contracts: application logic is specified in smart contracts that target a specific execution environment. A combination of both pallets and smart contracts: application logic is executed by both smart contracts and task-specific pallets. Note that designing a Substrate-based blockchain network (or \"core runtime features\" ) and designing the application logic of a Substrate-based blockchain are separate things. While the network type may have an influence on how a runtime is designed and/or how smart contracts are used, the chosen network architecture can evolve over time throughout early phases of development. For chains already in production, evolving on network type or architecture is possible only with chains with forkless upgradability built in, which the Substrate framework provides out of the box. Refer to this page to explore the types of networks that can be built with Substrate. Substrate runtime application development using specialized pallets or smart contracts each provide solutions designed to solve different problems. There is likely some amount of overlap in the kinds of problems each one can solve, but there is also a clear set of problems suited for only one of the two. To give just one example in each category: Runtime development: Building a privacy layer on top of transactions in your blockchain. Smart contract development: Introducing multi-signature wallets over the currency of your blockchain. Use case specific: Building a gaming dApp which may need to build up a community of users (smart contract), or may need to scale to millions of transactions a day (runtime pallet development). Runtime development Runtime development has the intention of producing lean, performant, and fast nodes. You have full control of the underlying logic that each node on your network will run. You have full access to each and every storage item across all of your pallets, which you can modify and control. This level of control comes with greater responsibility. Runtime engineers have much more responsibility for writing robust and correct code, than those deploying Smart Contracts. Incorrect logic or poor error handling could brick your chain. As a runtime engineer, you must provide the protections for the overhead of transactions reverting and implicitly introduce any fee system to the computation of the nodes your chain runs on. This means while you are developing runtime functions, you must correctly assess and apply fees to different parts of your runtime logic so that it will not be abused by malicious actors. Substrate Runtime Development: Provides low level access to your entire blockchain. Removes the overhead of built-in safety for performance, giving developers increased flexibility at the cost of increased responsibility. Raises the entry bar for developers, where developers are not only responsible for writing working code but must constantly check to avoid writing broken code. Has no inherent economic incentives to repel bad actors. Smart contracts in Substrate In order to use smart contracts in a Substrate node, the runtime must be specially configured. Smart contract compatible runtimes use specialized pallets that define the types of execution environment an application requires. This could be the EVM pallet , for example, used in Ethereum compatible Substrate-based chains. Another example is the Contracts pallet which provides a way to execute Wasm contracts written in a specialized language called ink!. See some examples on how to write a smart contract in ink!. Other community projects aiming to provide easy ways to integrate smart contract capabilities also exist. Refer to this section of the awesome Subtrate repository to learn about them. In all cases, the architecture of a Substrate node with smart contract capabilities will look like this: (TODO: Diagramify with points below) Any node will have some pallet (or collection of pallets) that will implement the smart contract execution environment. This could be any VM, for example the EVM or a Wasm execution environment, or both. The contract code and programming language used depends on the target environment of the pallet. For example ink! for the Contracts pallet, or anything that can compile to Wasm and exposes the interface required by the Contracts pallet . Any single type of virtual machine or execution environment, such as EVM or Wasm, can support different programming languages to write smart contracts. For example, Solidity can be used for both EVM and Wasm environments using purpose built compilers. With the contracts pallet as the execution environment, it is possible to use any language that can compile to Wasm. A traditional smart contract platform allows users to publish additional logic on top of some core blockchain logic. Because smart contract logic can be published by anyone, including malicious actors and inexperienced developers, there are a number of intentional safe guards built around these public smart contract platform. Some examples are: Fees : Ensuring that contract execution incurs fees for the computation and storage it forces on the computers running it, so it can't abuse block creators. Sandbox : A contract is not able to modify core blockchain storage or the storage of other contracts directly. It's power is limited to only modifying it's own state, and the ability to make outside calls to other contracts or runtime functions. Storage Deposit : A contract takes up space on the blockchain, and should be charged for taking up space on the hard drives of the nodes. This ensures that people don't take advantage of \"free, unlimited storage.\" Reversion : A contract can be prone to logical errors. The expectations of a contract developer are low, so extra overhead is added to support reverting transactions when they fail, so no state is updated when things go wrong. These different overheads makes running contracts slower and more costly, but attractive to certain developers. Contracts allow your community to extend and develop on top of your runtime logic without needing to go through the process of on-chain runtime upgrades. It can even be used as a testing ground for future runtime changes, but done in a way that isolates your network from any of the growing pains or errors which might occur. Substrate Smart Contracts: Are inherently safer to the network. Have built in economic incentives against abuse. Have computational overhead to support graceful failures in logic. Have a lower bar to entry for development. Enable fast-pace community interaction through a playground to write new logic. Prototyping with smart contracts Todo Considerations and comparisions There are a few considerations to be made when composing runtimes with pallets, smart contracts or both. A main one is the cost associated with building using each approach. Deploying a contract is a relatively simple and easy process because you take advantage of the existing network. The only costs to you are the fees which you pay to deploy and maintain your contract. Setting up your own blockchain, on the other hand, incurs the cost of building a community who find value in the service you provide, or the additional costs associated with establishing a private network with the overhead of a Cloud computing-based architecture and general network maintenance. While it's hard to address every scenario, in general, runtime development is most favorable for applications that require higher degrees of flexibility and adaptability. For example, applications that require the accommodation of different types of users or multiple layers of governance. The table below is meant to help inform your decisions on which approach to use based on different situations. Runtime Development Smart Contract Use Case Specific Privacy Layer Feeless Token Light-Client Bridge Decentralized Exchange Oracles Stable Coin Multi-signature Wallet Data services Simple fundraiser Small scale gaming dApp (contract) Large scale gaming dApp (runtime) Community driven Decentralized Autonomous Organizations (DAO)(contract) Protocol driven Decentralized Autonomous Organizations (DAO)(runtime) Community driven treasury(contract) Protocol driven treasury (runtime) NOTE: If you are building on Polkadot, you can also deploy smart contracts on its parachain . See The Polkadot Wiki for a comparison between developing on a parachain, parathread, and smart contracts. Where to go next Explore the following resources to learn more. Tell me Pallet design Smart contract pallets Storage design Economic models Guide me Build a proof of existence blockchain ink! tutorial","title":"Designing your runtime logic"},{"location":"main-docs/05-design/#designing-your-runtime","text":"Application logic in Substrate-based blockchains can be expressed in the form of: Specialized pallets : each pallet performs a special task, serving the business logic needs of the blockchain. Smart contracts: application logic is specified in smart contracts that target a specific execution environment. A combination of both pallets and smart contracts: application logic is executed by both smart contracts and task-specific pallets. Note that designing a Substrate-based blockchain network (or \"core runtime features\" ) and designing the application logic of a Substrate-based blockchain are separate things. While the network type may have an influence on how a runtime is designed and/or how smart contracts are used, the chosen network architecture can evolve over time throughout early phases of development. For chains already in production, evolving on network type or architecture is possible only with chains with forkless upgradability built in, which the Substrate framework provides out of the box. Refer to this page to explore the types of networks that can be built with Substrate. Substrate runtime application development using specialized pallets or smart contracts each provide solutions designed to solve different problems. There is likely some amount of overlap in the kinds of problems each one can solve, but there is also a clear set of problems suited for only one of the two. To give just one example in each category: Runtime development: Building a privacy layer on top of transactions in your blockchain. Smart contract development: Introducing multi-signature wallets over the currency of your blockchain. Use case specific: Building a gaming dApp which may need to build up a community of users (smart contract), or may need to scale to millions of transactions a day (runtime pallet development).","title":"Designing your runtime"},{"location":"main-docs/05-design/#runtime-development","text":"Runtime development has the intention of producing lean, performant, and fast nodes. You have full control of the underlying logic that each node on your network will run. You have full access to each and every storage item across all of your pallets, which you can modify and control. This level of control comes with greater responsibility. Runtime engineers have much more responsibility for writing robust and correct code, than those deploying Smart Contracts. Incorrect logic or poor error handling could brick your chain. As a runtime engineer, you must provide the protections for the overhead of transactions reverting and implicitly introduce any fee system to the computation of the nodes your chain runs on. This means while you are developing runtime functions, you must correctly assess and apply fees to different parts of your runtime logic so that it will not be abused by malicious actors. Substrate Runtime Development: Provides low level access to your entire blockchain. Removes the overhead of built-in safety for performance, giving developers increased flexibility at the cost of increased responsibility. Raises the entry bar for developers, where developers are not only responsible for writing working code but must constantly check to avoid writing broken code. Has no inherent economic incentives to repel bad actors.","title":"Runtime development"},{"location":"main-docs/05-design/#smart-contracts-in-substrate","text":"In order to use smart contracts in a Substrate node, the runtime must be specially configured. Smart contract compatible runtimes use specialized pallets that define the types of execution environment an application requires. This could be the EVM pallet , for example, used in Ethereum compatible Substrate-based chains. Another example is the Contracts pallet which provides a way to execute Wasm contracts written in a specialized language called ink!. See some examples on how to write a smart contract in ink!. Other community projects aiming to provide easy ways to integrate smart contract capabilities also exist. Refer to this section of the awesome Subtrate repository to learn about them. In all cases, the architecture of a Substrate node with smart contract capabilities will look like this: (TODO: Diagramify with points below) Any node will have some pallet (or collection of pallets) that will implement the smart contract execution environment. This could be any VM, for example the EVM or a Wasm execution environment, or both. The contract code and programming language used depends on the target environment of the pallet. For example ink! for the Contracts pallet, or anything that can compile to Wasm and exposes the interface required by the Contracts pallet . Any single type of virtual machine or execution environment, such as EVM or Wasm, can support different programming languages to write smart contracts. For example, Solidity can be used for both EVM and Wasm environments using purpose built compilers. With the contracts pallet as the execution environment, it is possible to use any language that can compile to Wasm. A traditional smart contract platform allows users to publish additional logic on top of some core blockchain logic. Because smart contract logic can be published by anyone, including malicious actors and inexperienced developers, there are a number of intentional safe guards built around these public smart contract platform. Some examples are: Fees : Ensuring that contract execution incurs fees for the computation and storage it forces on the computers running it, so it can't abuse block creators. Sandbox : A contract is not able to modify core blockchain storage or the storage of other contracts directly. It's power is limited to only modifying it's own state, and the ability to make outside calls to other contracts or runtime functions. Storage Deposit : A contract takes up space on the blockchain, and should be charged for taking up space on the hard drives of the nodes. This ensures that people don't take advantage of \"free, unlimited storage.\" Reversion : A contract can be prone to logical errors. The expectations of a contract developer are low, so extra overhead is added to support reverting transactions when they fail, so no state is updated when things go wrong. These different overheads makes running contracts slower and more costly, but attractive to certain developers. Contracts allow your community to extend and develop on top of your runtime logic without needing to go through the process of on-chain runtime upgrades. It can even be used as a testing ground for future runtime changes, but done in a way that isolates your network from any of the growing pains or errors which might occur. Substrate Smart Contracts: Are inherently safer to the network. Have built in economic incentives against abuse. Have computational overhead to support graceful failures in logic. Have a lower bar to entry for development. Enable fast-pace community interaction through a playground to write new logic.","title":"Smart contracts in Substrate"},{"location":"main-docs/05-design/#prototyping-with-smart-contracts","text":"Todo","title":"Prototyping with smart contracts"},{"location":"main-docs/05-design/#considerations-and-comparisions","text":"There are a few considerations to be made when composing runtimes with pallets, smart contracts or both. A main one is the cost associated with building using each approach. Deploying a contract is a relatively simple and easy process because you take advantage of the existing network. The only costs to you are the fees which you pay to deploy and maintain your contract. Setting up your own blockchain, on the other hand, incurs the cost of building a community who find value in the service you provide, or the additional costs associated with establishing a private network with the overhead of a Cloud computing-based architecture and general network maintenance. While it's hard to address every scenario, in general, runtime development is most favorable for applications that require higher degrees of flexibility and adaptability. For example, applications that require the accommodation of different types of users or multiple layers of governance. The table below is meant to help inform your decisions on which approach to use based on different situations. Runtime Development Smart Contract Use Case Specific Privacy Layer Feeless Token Light-Client Bridge Decentralized Exchange Oracles Stable Coin Multi-signature Wallet Data services Simple fundraiser Small scale gaming dApp (contract) Large scale gaming dApp (runtime) Community driven Decentralized Autonomous Organizations (DAO)(contract) Protocol driven Decentralized Autonomous Organizations (DAO)(runtime) Community driven treasury(contract) Protocol driven treasury (runtime) NOTE: If you are building on Polkadot, you can also deploy smart contracts on its parachain . See The Polkadot Wiki for a comparison between developing on a parachain, parathread, and smart contracts.","title":"Considerations and comparisions"},{"location":"main-docs/05-design/#where-to-go-next","text":"Explore the following resources to learn more.","title":"Where to go next"},{"location":"main-docs/05-design/#tell-me","text":"Pallet design Smart contract pallets Storage design Economic models","title":"Tell me"},{"location":"main-docs/05-design/#guide-me","text":"Build a proof of existence blockchain ink! tutorial","title":"Guide me"},{"location":"main-docs/05-design/economic-models/","text":"[ WIP ] Hybrid consensus See: https://github.com/paritytech/substrate/issues/1304 Describes considerations for swappable consenus. A good starting point for designing hybrid consesnus systems. Note: block authoring engines must be made aware of blocks that are finalized so that they don't waste time building on top of blocks that will never be in the canonical chain.","title":"Economic models"},{"location":"main-docs/05-design/economic-models/#hybrid-consensus","text":"See: https://github.com/paritytech/substrate/issues/1304 Describes considerations for swappable consenus. A good starting point for designing hybrid consesnus systems. Note: block authoring engines must be made aware of blocks that are finalized so that they don't waste time building on top of blocks that will never be in the canonical chain.","title":"Hybrid consensus"},{"location":"main-docs/05-design/pallet-design/","text":"[WIP] FRAME primitives Substrate comes with an opinionated toolkit for building runtimes in Rust called FRAME. That said, the runtime can be built in any way, with any language, so long as it can communicate to the client. The core Substrate codebase ships with FRAME , Parity's system for Substrate runtime development that is used for chains like Kusama and Polkadot . FRAME defines additional runtime primitives and provides a framework that makes it easy to construct a runtime by composing modules, called pallets . Each pallet encapsulates domain-specific logic that is expressed as a set of a storage items , events , errors , and dispatchable functions . FRAME developers can create their own pallets and reuse existing pallets, including over 50 of those shipped with Substrate . There are an additional set of primitives that are assumed about a runtime built with the Substrate FRAME. These are: Call : The dispatch type that can be called via an extrinsic. Origin : Represents where a call came from. For example, a signed message (a transaction), an unsigned message (an inherent extrinsic), or a call from the runtime itself (a root call). Index : An account index (aka nonce) type. This stores the number of previous transactions associated with a sender account. Hashing : The hashing algorithm being used in the runtime (e.g. Blake2). AccountId : The type used to identify user accounts in the runtime. Event : The type used for events emitted by the runtime. Version : A type which represents the version of the runtime. Although a lot of core runtime development can be enabled with FRAME and its related primitives, FRAME is not the only system for developing Substrate based blockchains. Next steps Learn more Learn about the Substrate FRAME . Follow a tutorial to develop your first Substrate chain . Follow a tutorial to add a pallet to your Substrate runtime . References See the primitive types defined in node-primitives . See the traits defined in sp-runtime . Weights Gav: In general, pallets should be written such that it\u2019s impossible for a block to need more weight than the max. There are two occasions where we have historically relaxed this: upgrades and migrations. But in general (and especially for parachains) this won\u2019t work So it\u2019s best to structure code so that it cannot have unbounded weight. If it looks like code might need more weight than the block\u2019s max, then that code might need reworking so that it can reduce or split its functionality at a pinch. If a block\u2019s weight is too large then it basically just means that other validators will be unable/unwilling to import it. This is the desired outcome for a malicious block. Shawn: I think another point to mention about weights is that everything is relative. An overweight block represents a block that takes more than than the allocated time on a specified hardware. People running faster machines are going to be able to import \"overweight\" blocks no problem. People who are running very crappy computers are not going to be able to import underweight blocks in time. The whole thing we are trying to prevent is that good nodes should not miss their allocated block production slot because someone produced a block that is too big, and then takes them too long to import before they can go ahead and make their own block. Imagine an attack where we know all computers on the network are exactly on par with another. Then a malicious actor would run a bunch of powerful machines, and somehow construct a block which is weighed incorrectly, and is actually very expensive to execute. It would be possible they submit this block a lot, and then the only machines that would be able to keep up and continue to produce blocks would be those powerful nodes. Other nodes would just be constantly behind trying to import blocks. Finally, our weight calculations are known to be quite conservative. We test everything in worst case scenario, and have assumed quite a bit of overhead which does not actually exist in regular blocks. https://www.shawntabrizi.com/substrate-graph-benchmarks/docs/#/results So we have overestimated the weight of transfer_keep_alive by 50%. So weights are inherently a bit flexible, but our goal with benchmarking is to be as close to truth as possible about the time to execute some logic, and there is plenty of room to continue and improve that Order of pallets (pallet hooks). See: https://github.com/paritytech/substrate/blob/9689a131a595b99e60f134d7634f5f4d71969410/frame/support/procedural/src/lib.rs#L347-L351 /// The population of the genesis storage depends on the order of pallets. So, if one of your /// pallets depends on another pallet, the pallet that is depended upon needs to come before /// the pallet depending on it. \u2192 Explain how this relates to on_initialize \u2192 Linked PR: https://github.com/paritytech/substrate/pull/10043 to be more precise we should also say that frame_system is executed first, no matter its position. storage FRAME macros are used to hash storage items, encode and decode them. Commonly used hashers in Substrate are: Blake2_128 , Blake2_128 , Twox128 and Twox256 . Trie abstraction Substrate does not use reference counting for performance reasons. Tries allow efficient storing and sharing of the historical block state. The trie root is a representation of the data within the trie: two tries with different data will always have different roots. Thus, two blockchain nodes can easily verify that they have the same state by simply comparing their trie roots. One advantage of using a simple key-value store is that you are able to easily abstract storage structures on top of it. Accessing trie data is costly. Each read operation takes O(log N) time, where N is the number of elements stored in the trie. To mitigate this, we use a key-value cache. Child trie Child tries are identical to the main state trie, except that a child trie's root is stored and updated as a node in the main trie instead of the block header. Since their headers are a part of the main state trie, it is still easy to verify the complete node state when it includes child tries. Child tries are useful when you want your own independent trie with a separate root hash that you can use to verify the specific content in that trie. Subsections of a trie do not have a root-hash-like representation that satisfy these needs automatically; thus a child trie is used instead. Querying storage Blockchains that are built with Substrate expose a remote procedure call (RPC) server that can be used to query runtime storage. When you use the Substrate RPC to access a storage item, you only need to provide the key associated with that item. Substrate's runtime storage APIs expose a number of storage item types; keep reading to learn how to calculate storage keys for the different types of storage items. Storage value keys To calculate the key for a simple Storage Value , take the TwoX 128 hash of the name of the pallet that contains the Storage Value and append to it the TwoX 128 hash of the name of the Storage Value itself. For example, the Sudo pallet exposes a Storage Value item named Key : twox_128(\"Sudo\") = \"0x5c0d1176a568c1f92944340dbfed9e9c\" twox_128(\"Key\") = \"0x530ebca703c85910e7164cb7d1c9e47b\" twox_128(\"Sudo\") + twox_128(\"Key\") = \"0x5c0d1176a568c1f92944340dbfed9e9c530ebca703c85910e7164cb7d1c9e47b\" If the familiar Alice account is the sudo user, an RPC request and response to read the Sudo pallet's Key Storage Value could be represented as: state_getStorage(\"0x5c0d1176a568c1f92944340dbfed9e9c530ebca703c85910e7164cb7d1c9e47b\") = \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" In this case, the value that is returned ( \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" ) is Alice's SCALE -encoded account ID ( 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY ). You may have noticed that the non-cryptographic TwoX 128 hash algorithm is used to generate Storage Value keys. This is because it is not necessary to pay the performance costs associated with a cryptographic hash function since the input to the hash function (the names of the pallet and storage item) are determined by the runtime developer and not by potentially malicious users of your blockchain. Storage map keys Like Storage Values, the keys for Storage Maps are equal to the TwoX 128 hash of the name of the pallet that contains the map prepended to the TwoX 128 hash of the name of the Storage Map itself. To retrieve an element from a map, simply append the hash of the desired map key to the storage key of the Storage Map. For maps with two keys (Storage Double Maps), append the hash of the first map key followed by the hash of the second map key to the Storage Double Map's storage key. Like Storage Values, Substrate will use the TwoX 128 hashing algorithm for the pallet and Storage Map names, but you will need to make sure to use the correct hashing algorithm (the one that was declared in the #[pallet::storage] macro ) when determining the hashed keys for the elements in a map. Here is an example that illustrates querying a Storage Map named FreeBalance from a pallet named \"Balances\" for the balance of the familiar Alice account. In this example, the FreeBalance map is using the transparent Blake2 128 Concat hashing algorithm : twox_128(\"Balances\") = \"0xc2261276cc9d1f8598ea4b6a74b15c2f\" twox_128(\"FreeBalance\") = \"0x6482b9ade7bc6657aaca787ba1add3b4\" scale_encode(\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\") = \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" blake2_128_concat(\"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\") = \"0xde1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" state_getStorage(\"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4de1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\") = \"0x0000a0dec5adc9353600000000000000\" The value that is returned from the storage query ( \"0x0000a0dec5adc9353600000000000000\" in the example above) is the SCALE -encoded value of Alice's account balance ( \"1000000000000000000000\" in this example). Notice that before hashing Alice's account ID it has to be SCALE-encoded. Also notice that the output of the blake2_128_concat function consists of 32 hexadecimal characters followed by the function's input. This is because the Blake2 128 Concat is a transparent hashing algorithm . Although the above example may make this characteristic seem superfluous, its utility becomes more apparent when the goal is to iterate over the keys in a map (as opposed to retrieving the value associated with a single key). The ability to iterate over the keys in a map is a common requirement in order to allow people to use the map in a way that seems natural (such as UIs): first, a user is presented with a list of elements in the map, then, that user can select the element that they are interested in and query the map for more details about that particular element. Here is another example that uses the same example Storage Map (a map named FreeBalances that uses a Blake2 128 Concat hashing algorithm in a pallet named \"Balances\") that will demonstrate using the Substrate RPC to query a Storage Map for its list of keys via the state_getKeys RPC endpoint: twox_128(\"Balances\") = \"0xc2261276cc9d1f8598ea4b6a74b15c2f\" twox_128(\"FreeBalance\") = \"0x6482b9ade7bc6657aaca787ba1add3b4\" state_getKeys(\"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4\") = [ \"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4de1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\", \"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b432a5935f6edc617ae178fef9eb1e211fbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f\", ... ] Each element in the list that is returned by the Substrate RPC's state_getKeys endpoint can be directly used as input for the RPC's state_getStorage endpoint. In fact, the first element in the example list above is equal to the input used for the state_getStorage query in the previous example (the one used to find the balance for Alice ). Because the map that these keys belong to uses a transparent hashing algorithm to generate its keys, it is possible to determine the account associated with the second element in the list. Notice that each element in the list is a hexadecimal value that begins with the same 64 characters; this is because each list element represents a key in the same map, and that map is identified by concatenating two TwoX 128 hashes, each of which are 128-bits or 32 hexadecimal characters. After discarding this portion of the second element in the list, you are left with 0x32a5935f6edc617ae178fef9eb1e211fbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f . You saw in the previous example that this represents the Blake2 128 Concat hash of some SCALE -encoded account ID. The Blake 128 Concat hashing algorithm consists of appending (concatenating) the hashing algorithm's input to its Blake 128 hash. This means that the first 128 bits (or 32 hexadecimal characters) of a Blake2 128 Concat hash represents a Blake2 128 hash, and the remainder represents the value that was passed to the Blake 2 128 hashing algorithm. In this example, after you remove the first 32 hexadecimal characters that represent the Blake2 128 hash (i.e. 0x32a5935f6edc617ae178fef9eb1e211f ) what is left is the hexadecimal value 0xbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f , which is a SCALE -encoded account ID. Decoding this value yields the result 5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY , which is the account ID for the familiar Alice_Stash account. Runtime storage API Substrate's FRAME Support crate provides utilities for generating unique, deterministic keys for your runtime's storage items. These storage items are placed in the state trie and are accessible by querying the trie by key .","title":"Pallet design"},{"location":"main-docs/05-design/pallet-design/#frame-primitives","text":"Substrate comes with an opinionated toolkit for building runtimes in Rust called FRAME. That said, the runtime can be built in any way, with any language, so long as it can communicate to the client. The core Substrate codebase ships with FRAME , Parity's system for Substrate runtime development that is used for chains like Kusama and Polkadot . FRAME defines additional runtime primitives and provides a framework that makes it easy to construct a runtime by composing modules, called pallets . Each pallet encapsulates domain-specific logic that is expressed as a set of a storage items , events , errors , and dispatchable functions . FRAME developers can create their own pallets and reuse existing pallets, including over 50 of those shipped with Substrate . There are an additional set of primitives that are assumed about a runtime built with the Substrate FRAME. These are: Call : The dispatch type that can be called via an extrinsic. Origin : Represents where a call came from. For example, a signed message (a transaction), an unsigned message (an inherent extrinsic), or a call from the runtime itself (a root call). Index : An account index (aka nonce) type. This stores the number of previous transactions associated with a sender account. Hashing : The hashing algorithm being used in the runtime (e.g. Blake2). AccountId : The type used to identify user accounts in the runtime. Event : The type used for events emitted by the runtime. Version : A type which represents the version of the runtime. Although a lot of core runtime development can be enabled with FRAME and its related primitives, FRAME is not the only system for developing Substrate based blockchains.","title":"FRAME primitives"},{"location":"main-docs/05-design/pallet-design/#next-steps","text":"","title":"Next steps"},{"location":"main-docs/05-design/pallet-design/#learn-more","text":"Learn about the Substrate FRAME . Follow a tutorial to develop your first Substrate chain . Follow a tutorial to add a pallet to your Substrate runtime .","title":"Learn more"},{"location":"main-docs/05-design/pallet-design/#references","text":"See the primitive types defined in node-primitives . See the traits defined in sp-runtime . Weights Gav: In general, pallets should be written such that it\u2019s impossible for a block to need more weight than the max. There are two occasions where we have historically relaxed this: upgrades and migrations. But in general (and especially for parachains) this won\u2019t work So it\u2019s best to structure code so that it cannot have unbounded weight. If it looks like code might need more weight than the block\u2019s max, then that code might need reworking so that it can reduce or split its functionality at a pinch. If a block\u2019s weight is too large then it basically just means that other validators will be unable/unwilling to import it. This is the desired outcome for a malicious block. Shawn: I think another point to mention about weights is that everything is relative. An overweight block represents a block that takes more than than the allocated time on a specified hardware. People running faster machines are going to be able to import \"overweight\" blocks no problem. People who are running very crappy computers are not going to be able to import underweight blocks in time. The whole thing we are trying to prevent is that good nodes should not miss their allocated block production slot because someone produced a block that is too big, and then takes them too long to import before they can go ahead and make their own block. Imagine an attack where we know all computers on the network are exactly on par with another. Then a malicious actor would run a bunch of powerful machines, and somehow construct a block which is weighed incorrectly, and is actually very expensive to execute. It would be possible they submit this block a lot, and then the only machines that would be able to keep up and continue to produce blocks would be those powerful nodes. Other nodes would just be constantly behind trying to import blocks. Finally, our weight calculations are known to be quite conservative. We test everything in worst case scenario, and have assumed quite a bit of overhead which does not actually exist in regular blocks. https://www.shawntabrizi.com/substrate-graph-benchmarks/docs/#/results So we have overestimated the weight of transfer_keep_alive by 50%. So weights are inherently a bit flexible, but our goal with benchmarking is to be as close to truth as possible about the time to execute some logic, and there is plenty of room to continue and improve that Order of pallets (pallet hooks). See: https://github.com/paritytech/substrate/blob/9689a131a595b99e60f134d7634f5f4d71969410/frame/support/procedural/src/lib.rs#L347-L351 /// The population of the genesis storage depends on the order of pallets. So, if one of your /// pallets depends on another pallet, the pallet that is depended upon needs to come before /// the pallet depending on it. \u2192 Explain how this relates to on_initialize \u2192 Linked PR: https://github.com/paritytech/substrate/pull/10043 to be more precise we should also say that frame_system is executed first, no matter its position. storage FRAME macros are used to hash storage items, encode and decode them. Commonly used hashers in Substrate are: Blake2_128 , Blake2_128 , Twox128 and Twox256 .","title":"References"},{"location":"main-docs/05-design/pallet-design/#trie-abstraction","text":"Substrate does not use reference counting for performance reasons. Tries allow efficient storing and sharing of the historical block state. The trie root is a representation of the data within the trie: two tries with different data will always have different roots. Thus, two blockchain nodes can easily verify that they have the same state by simply comparing their trie roots. One advantage of using a simple key-value store is that you are able to easily abstract storage structures on top of it. Accessing trie data is costly. Each read operation takes O(log N) time, where N is the number of elements stored in the trie. To mitigate this, we use a key-value cache.","title":"Trie abstraction"},{"location":"main-docs/05-design/pallet-design/#child-trie","text":"Child tries are identical to the main state trie, except that a child trie's root is stored and updated as a node in the main trie instead of the block header. Since their headers are a part of the main state trie, it is still easy to verify the complete node state when it includes child tries. Child tries are useful when you want your own independent trie with a separate root hash that you can use to verify the specific content in that trie. Subsections of a trie do not have a root-hash-like representation that satisfy these needs automatically; thus a child trie is used instead.","title":"Child trie"},{"location":"main-docs/05-design/pallet-design/#querying-storage","text":"Blockchains that are built with Substrate expose a remote procedure call (RPC) server that can be used to query runtime storage. When you use the Substrate RPC to access a storage item, you only need to provide the key associated with that item. Substrate's runtime storage APIs expose a number of storage item types; keep reading to learn how to calculate storage keys for the different types of storage items.","title":"Querying storage"},{"location":"main-docs/05-design/pallet-design/#storage-value-keys","text":"To calculate the key for a simple Storage Value , take the TwoX 128 hash of the name of the pallet that contains the Storage Value and append to it the TwoX 128 hash of the name of the Storage Value itself. For example, the Sudo pallet exposes a Storage Value item named Key : twox_128(\"Sudo\") = \"0x5c0d1176a568c1f92944340dbfed9e9c\" twox_128(\"Key\") = \"0x530ebca703c85910e7164cb7d1c9e47b\" twox_128(\"Sudo\") + twox_128(\"Key\") = \"0x5c0d1176a568c1f92944340dbfed9e9c530ebca703c85910e7164cb7d1c9e47b\" If the familiar Alice account is the sudo user, an RPC request and response to read the Sudo pallet's Key Storage Value could be represented as: state_getStorage(\"0x5c0d1176a568c1f92944340dbfed9e9c530ebca703c85910e7164cb7d1c9e47b\") = \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" In this case, the value that is returned ( \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" ) is Alice's SCALE -encoded account ID ( 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY ). You may have noticed that the non-cryptographic TwoX 128 hash algorithm is used to generate Storage Value keys. This is because it is not necessary to pay the performance costs associated with a cryptographic hash function since the input to the hash function (the names of the pallet and storage item) are determined by the runtime developer and not by potentially malicious users of your blockchain.","title":"Storage value keys"},{"location":"main-docs/05-design/pallet-design/#storage-map-keys","text":"Like Storage Values, the keys for Storage Maps are equal to the TwoX 128 hash of the name of the pallet that contains the map prepended to the TwoX 128 hash of the name of the Storage Map itself. To retrieve an element from a map, simply append the hash of the desired map key to the storage key of the Storage Map. For maps with two keys (Storage Double Maps), append the hash of the first map key followed by the hash of the second map key to the Storage Double Map's storage key. Like Storage Values, Substrate will use the TwoX 128 hashing algorithm for the pallet and Storage Map names, but you will need to make sure to use the correct hashing algorithm (the one that was declared in the #[pallet::storage] macro ) when determining the hashed keys for the elements in a map. Here is an example that illustrates querying a Storage Map named FreeBalance from a pallet named \"Balances\" for the balance of the familiar Alice account. In this example, the FreeBalance map is using the transparent Blake2 128 Concat hashing algorithm : twox_128(\"Balances\") = \"0xc2261276cc9d1f8598ea4b6a74b15c2f\" twox_128(\"FreeBalance\") = \"0x6482b9ade7bc6657aaca787ba1add3b4\" scale_encode(\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\") = \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" blake2_128_concat(\"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\") = \"0xde1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\" state_getStorage(\"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4de1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\") = \"0x0000a0dec5adc9353600000000000000\" The value that is returned from the storage query ( \"0x0000a0dec5adc9353600000000000000\" in the example above) is the SCALE -encoded value of Alice's account balance ( \"1000000000000000000000\" in this example). Notice that before hashing Alice's account ID it has to be SCALE-encoded. Also notice that the output of the blake2_128_concat function consists of 32 hexadecimal characters followed by the function's input. This is because the Blake2 128 Concat is a transparent hashing algorithm . Although the above example may make this characteristic seem superfluous, its utility becomes more apparent when the goal is to iterate over the keys in a map (as opposed to retrieving the value associated with a single key). The ability to iterate over the keys in a map is a common requirement in order to allow people to use the map in a way that seems natural (such as UIs): first, a user is presented with a list of elements in the map, then, that user can select the element that they are interested in and query the map for more details about that particular element. Here is another example that uses the same example Storage Map (a map named FreeBalances that uses a Blake2 128 Concat hashing algorithm in a pallet named \"Balances\") that will demonstrate using the Substrate RPC to query a Storage Map for its list of keys via the state_getKeys RPC endpoint: twox_128(\"Balances\") = \"0xc2261276cc9d1f8598ea4b6a74b15c2f\" twox_128(\"FreeBalance\") = \"0x6482b9ade7bc6657aaca787ba1add3b4\" state_getKeys(\"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4\") = [ \"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b4de1e86a9a8c739864cf3cc5ec2bea59fd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\", \"0xc2261276cc9d1f8598ea4b6a74b15c2f6482b9ade7bc6657aaca787ba1add3b432a5935f6edc617ae178fef9eb1e211fbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f\", ... ] Each element in the list that is returned by the Substrate RPC's state_getKeys endpoint can be directly used as input for the RPC's state_getStorage endpoint. In fact, the first element in the example list above is equal to the input used for the state_getStorage query in the previous example (the one used to find the balance for Alice ). Because the map that these keys belong to uses a transparent hashing algorithm to generate its keys, it is possible to determine the account associated with the second element in the list. Notice that each element in the list is a hexadecimal value that begins with the same 64 characters; this is because each list element represents a key in the same map, and that map is identified by concatenating two TwoX 128 hashes, each of which are 128-bits or 32 hexadecimal characters. After discarding this portion of the second element in the list, you are left with 0x32a5935f6edc617ae178fef9eb1e211fbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f . You saw in the previous example that this represents the Blake2 128 Concat hash of some SCALE -encoded account ID. The Blake 128 Concat hashing algorithm consists of appending (concatenating) the hashing algorithm's input to its Blake 128 hash. This means that the first 128 bits (or 32 hexadecimal characters) of a Blake2 128 Concat hash represents a Blake2 128 hash, and the remainder represents the value that was passed to the Blake 2 128 hashing algorithm. In this example, after you remove the first 32 hexadecimal characters that represent the Blake2 128 hash (i.e. 0x32a5935f6edc617ae178fef9eb1e211f ) what is left is the hexadecimal value 0xbe5ddb1579b72e84524fc29e78609e3caf42e85aa118ebfe0b0ad404b5bdd25f , which is a SCALE -encoded account ID. Decoding this value yields the result 5GNJqTPyNqANBkUVMN1LPPrxXnFouWXoe2wNSmmEoLctxiZY , which is the account ID for the familiar Alice_Stash account.","title":"Storage map keys"},{"location":"main-docs/05-design/pallet-design/#runtime-storage-api","text":"Substrate's FRAME Support crate provides utilities for generating unique, deterministic keys for your runtime's storage items. These storage items are placed in the state trie and are accessible by querying the trie by key .","title":"Runtime storage API"},{"location":"main-docs/05-design/smart-contract-pallets/","text":"Substrate provides two smart contract virtual machines which can be added to your runtime: the Contracts pallet and the EVM pallet . Each come with additional tools to ease development depending on your use cases. Contracts pallet The Contracts pallet provides the ability for the runtime to deploy and execute WebAssembly (Wasm) smart contracts. It uses ink! , a Rust -based embedded domain specific language ( eDSL ) for writing WebAssembly smart contracts. Here are some of ink!'s key features: Designed for correctness, conciseness and efficiency, ink! carries familiar concepts from other modern smart contract languages. Learn more about how it compares to Solidity . ink! provides a built in test environment that can be used to perform off-chain unit testing with the Rust framework. This makes it simple and easy to ensure that your contract code functions as expected, without the need for third party testing platforms. Learn more here . Because ink! follows Rust standards, tools like rustfmt and rust-analyzer already work out of the box. Start the ink! workshop } link={ /tutorials/v3/ink-workshop/pt1 } /> Features The Contracts pallet has a number of familiar and new features for the deployment and execution of smart contracts. Wasm Engine The Contracts pallet depends on a Wasm sandboxing interface defining the Wasm execution engine available within the runtime. This is currently implemented with wasmi , a Wasm interpreter. Account based The Contracts pallet uses an account-based system similar to many existing smart contract platforms. To the Substrate runtime, contract accounts are just like normal user accounts; however, in addition to an AccountID and Balance that normal accounts have, a contract account also has associated contract code and some persistent contract storage. A notable behaviour that arises from this is that a contract's account can receive balances without having its code executed by a plain transfer transaction. Deploying and calling contracts Deploying a contract with the Contracts pallet takes two steps: Store the Wasm contract on the blockchain. Instantiate a new account, with new storage, associated with that Wasm contract. This means that multiple contract instances, with different constructor arguments, can be initialized using the same Wasm code, reducing the amount of storage space needed by the Contracts pallet on your blockchain. Calls to contracts can alter the storage of the contract, create new contracts, and call other contracts. Because Substrate provides you with the ability to write custom runtimes, the Contracts pallet also enables you to make synchronous calls directly to those runtime functions on behalf of the contract's account. The Contracts pallet is intended to be used by any user on a public network. This means that contracts only have the ability to directly modify their own storage. To provide safety to the underlying blockchain state, the Contracts pallet enables revertible transactions, which roll back any changes to the storage by contract calls that do not complete successfully. Gas Contract calls are charged a gas fee to limit the amount of computational resources a transaction can use. When forming a contract transaction, a gas limit is specified. As the contract executes, gas is incrementally used up depending on the complexity of the computation. If the gas limit is reached before the contract execution completes, the transaction fails, contract storage is reverted, and the gas fee is not returned to the user. If the contract execution completes with remaining gas, it is returned to the user at the end of the transaction. The concept of gas is tightly integrated with substrates weight system . In fact there is no difference between gas and weight. The specified gas_limit directly influences the weight of the submitted transaction. The contracts pallet uses post dispatch weight correction to change the pre dispatch weight derived from the gas_limit to the actual weight consumed. Thus, to execute a transaction, a user must have a free balance of at least weight price * gas limit which can be spent. The charged fee however, is based upon the actually consumed gas. The weight price is determined due do the usual transaction fee mechanism . The Contracts pallet determines the gas price, which is a conversion between the Substrate weight system and a single unit of gas. Thus, to execute a transaction, a user must have a free balance of at least gas price * gas limit which can be spent. Storage deposit Similar to how gas limits the amount of computational resources that can be used during a transaction, storage deposit limits the footprint that a contract can have on the blockchain's storage. Any caller of a contract is charged a deposit proportionally to the amount of storage that the call in question adds to the blockchain. If a call removes storage the caller that removes it gets a refund proportionally to the amount of storage that was removed. Please note that with caller we mean the origin of a contract execution and not any contract which calls into another contract during a transaction. Similar to the gas_limit argument there is also a storage_limit argument with which users can limit the amount of deposit that can be incurred. The argument is denominated in native chain balance and hence the user must have at least that amount of free balance. Contracts pallet The Contracts pallet attempts to repair this through storage deposit which ensures that any data that persists on the blockchain is appropriately charged for those resources. The Contracts pallet chooses to approach contract creation using a two-step process , which fundamentally changes how contracts are stored on chain. Contract addresses, their storage, and balances are now separated from the underlying contract logic. This could enable behavior like what create2 provided to Ethereum or even enable repairable or upgradeable contracts on a Substrate based blockchain. How do I add the Contracts pallet to my custom chain? You can follow our guide here for instructions on how to add the Contracts pallet and other FRAME pallets to your blockchain's runtime. EVM pallet The FRAME Ethereum Virtual Machine (EVM) provides an execution environment for Substrate's Ethereum compatibility layer, known as Frontier. Frontier allows unmodified EVM code to be executed in a Substrate-based blockchain, designed to closely emulate the functionality of executing contracts on the Ethereum mainnet within the Substrate runtime. For more information on the FRAME EVM, see FRAME EVM pallet reference . To use the Frontier node template, go to https://github.com/paritytech/frontier/tree/master/template. The Substrate runtime works alongside the Ethereum pallet and the Dynamic Fee pallet to enable the creation of runtimes capable of fully emulating Ethereum block production and transaction processing. Start the Frontier workshop } link={ /tutorials/v3/frontier } /> EVM engine The EVM pallet uses SputnikVM as the underlying EVM engine. The engine is overhauled to be modular. For more information see Core Paper Project of EVM . The EVM is a good theoretical execution environment, but it is not very practical to use with modern hardware. For example, manipulation of 256 bit integers on modern architectures is significantly more complex than standard types. The Ethereum team has investigated the use of Wasm for the next generation of the network. An alternative to using the EVM is adding the Contracts pallet. The Contracts pallet iterates on existing ideas in the smart contract ecosystem, particularly Ethereum and the EVM. The most obvious difference between the Contracts pallet and the EVM is the underlying execution engine used to run smart contracts. To learn more about the Contracts pallet, see link . Cost The EVM charges for storage fees only at the time of storage. This one-time cost results in some permanent amount of storage being used on the blockchain, forever, which is not economically sound. Execution lifecycle Substrate-based accounts can call the EVM pallet to deposit or withdraw a balance from the Substrate base-currency into a different balance managed and used by the EVM pallet. Once a user has populated their balance, they can create and call smart contracts using this pallet. There's one-to-one mapping from Substrate accounts and EVM external accounts defined by a conversion function. EVM pallet vs. Ethereum network The EVM pallet should be able to produce nearly identical results as the Ethereum mainnet, including gas cost and balance changes. Observable differences include: The available length of block hashes may not be 256 depending on the configuration of the Substrate System pallet in the Substrate runtime. For more information on the System pallet, see the System pallet rust documentation . Difficulty and coinbase, which do not make sense in this pallet and are currently hard-coded to zero. Unobservable behaviors, such as state root are not the same when using the EVM pallet. The transaction / receipt format is also different. However, given one Ethereum transaction and one Substrate account private key, you should be able to convert any Ethereum transaction into a transaction compatible with this pallet. The gas configurations are currently hard-coded to the Istanbul hard fork. It can later be expanded to support earlier hard fork configurations. Substrate is built to enable you to extend what's provided out of the box. We encourage further development of alternative smart contract platforms on top of the Substrate runtime. Use these pre-built pallets to inform how you might design your own system or how you could port over an existing system to work on a Substrate-based chain. FAQ What is the difference between memory and storage? In ink! memory is the computer memory that is commonly known to programmers, while storage is the contract instance memory. The storage is backed up by the runtime in a database. How do I run tests? When building a smart contract with ink!, you can define a set of tests. For example, in the flipper contract , you can find a small test at the bottom of the contract. To run this test, type the following command: cargo +nightly test Learn more about why Rust is an ideal smart contract language . Follow a tutorial to add a pallet to your FRAME runtime . Examples Follow a this guide to learn how to add the Contracts pallet to your FRAME runtime. References Visit the reference docs for the Contracts pallet . Take a look at the repository for wasmi . For more information on ink!, see https://paritytech.github.io/ink-docs/ . Learn how to start developing with the Contracts pallet and ink! see https://tutorials/v3/ink-workshop/pt1. To view the source code and documentation for the EVM pallet, see https://github.com/paritytech/frontier/tree/master/frame/evm. To view the ink! repository, see https://github.com/paritytech/ink. To view the reference documentation for the EVM pallet, see https://docs.rs/pallet_evm and https://docs.rs/fp-evm/. To view the reference documentation fir SputnikVM's evm crate, see https://docs.rs/evm/.","title":"Smart contract pallets"},{"location":"main-docs/05-design/smart-contract-pallets/#contracts-pallet","text":"The Contracts pallet provides the ability for the runtime to deploy and execute WebAssembly (Wasm) smart contracts. It uses ink! , a Rust -based embedded domain specific language ( eDSL ) for writing WebAssembly smart contracts. Here are some of ink!'s key features: Designed for correctness, conciseness and efficiency, ink! carries familiar concepts from other modern smart contract languages. Learn more about how it compares to Solidity . ink! provides a built in test environment that can be used to perform off-chain unit testing with the Rust framework. This makes it simple and easy to ensure that your contract code functions as expected, without the need for third party testing platforms. Learn more here . Because ink! follows Rust standards, tools like rustfmt and rust-analyzer already work out of the box. Start the ink! workshop } link={ /tutorials/v3/ink-workshop/pt1 } />","title":"Contracts pallet"},{"location":"main-docs/05-design/smart-contract-pallets/#features","text":"The Contracts pallet has a number of familiar and new features for the deployment and execution of smart contracts.","title":"Features"},{"location":"main-docs/05-design/smart-contract-pallets/#wasm-engine","text":"The Contracts pallet depends on a Wasm sandboxing interface defining the Wasm execution engine available within the runtime. This is currently implemented with wasmi , a Wasm interpreter.","title":"Wasm Engine"},{"location":"main-docs/05-design/smart-contract-pallets/#account-based","text":"The Contracts pallet uses an account-based system similar to many existing smart contract platforms. To the Substrate runtime, contract accounts are just like normal user accounts; however, in addition to an AccountID and Balance that normal accounts have, a contract account also has associated contract code and some persistent contract storage. A notable behaviour that arises from this is that a contract's account can receive balances without having its code executed by a plain transfer transaction.","title":"Account based"},{"location":"main-docs/05-design/smart-contract-pallets/#deploying-and-calling-contracts","text":"Deploying a contract with the Contracts pallet takes two steps: Store the Wasm contract on the blockchain. Instantiate a new account, with new storage, associated with that Wasm contract. This means that multiple contract instances, with different constructor arguments, can be initialized using the same Wasm code, reducing the amount of storage space needed by the Contracts pallet on your blockchain. Calls to contracts can alter the storage of the contract, create new contracts, and call other contracts. Because Substrate provides you with the ability to write custom runtimes, the Contracts pallet also enables you to make synchronous calls directly to those runtime functions on behalf of the contract's account. The Contracts pallet is intended to be used by any user on a public network. This means that contracts only have the ability to directly modify their own storage. To provide safety to the underlying blockchain state, the Contracts pallet enables revertible transactions, which roll back any changes to the storage by contract calls that do not complete successfully.","title":"Deploying and calling contracts"},{"location":"main-docs/05-design/smart-contract-pallets/#gas","text":"Contract calls are charged a gas fee to limit the amount of computational resources a transaction can use. When forming a contract transaction, a gas limit is specified. As the contract executes, gas is incrementally used up depending on the complexity of the computation. If the gas limit is reached before the contract execution completes, the transaction fails, contract storage is reverted, and the gas fee is not returned to the user. If the contract execution completes with remaining gas, it is returned to the user at the end of the transaction. The concept of gas is tightly integrated with substrates weight system . In fact there is no difference between gas and weight. The specified gas_limit directly influences the weight of the submitted transaction. The contracts pallet uses post dispatch weight correction to change the pre dispatch weight derived from the gas_limit to the actual weight consumed. Thus, to execute a transaction, a user must have a free balance of at least weight price * gas limit which can be spent. The charged fee however, is based upon the actually consumed gas. The weight price is determined due do the usual transaction fee mechanism . The Contracts pallet determines the gas price, which is a conversion between the Substrate weight system and a single unit of gas. Thus, to execute a transaction, a user must have a free balance of at least gas price * gas limit which can be spent.","title":"Gas"},{"location":"main-docs/05-design/smart-contract-pallets/#storage-deposit","text":"Similar to how gas limits the amount of computational resources that can be used during a transaction, storage deposit limits the footprint that a contract can have on the blockchain's storage. Any caller of a contract is charged a deposit proportionally to the amount of storage that the call in question adds to the blockchain. If a call removes storage the caller that removes it gets a refund proportionally to the amount of storage that was removed. Please note that with caller we mean the origin of a contract execution and not any contract which calls into another contract during a transaction. Similar to the gas_limit argument there is also a storage_limit argument with which users can limit the amount of deposit that can be incurred. The argument is denominated in native chain balance and hence the user must have at least that amount of free balance.","title":"Storage deposit"},{"location":"main-docs/05-design/smart-contract-pallets/#contracts-pallet_1","text":"The Contracts pallet attempts to repair this through storage deposit which ensures that any data that persists on the blockchain is appropriately charged for those resources. The Contracts pallet chooses to approach contract creation using a two-step process , which fundamentally changes how contracts are stored on chain. Contract addresses, their storage, and balances are now separated from the underlying contract logic. This could enable behavior like what create2 provided to Ethereum or even enable repairable or upgradeable contracts on a Substrate based blockchain.","title":"Contracts pallet"},{"location":"main-docs/05-design/smart-contract-pallets/#how-do-i-add-the-contracts-pallet-to-my-custom-chain","text":"You can follow our guide here for instructions on how to add the Contracts pallet and other FRAME pallets to your blockchain's runtime.","title":"How do I add the Contracts pallet to my custom chain?"},{"location":"main-docs/05-design/smart-contract-pallets/#evm-pallet","text":"The FRAME Ethereum Virtual Machine (EVM) provides an execution environment for Substrate's Ethereum compatibility layer, known as Frontier. Frontier allows unmodified EVM code to be executed in a Substrate-based blockchain, designed to closely emulate the functionality of executing contracts on the Ethereum mainnet within the Substrate runtime. For more information on the FRAME EVM, see FRAME EVM pallet reference . To use the Frontier node template, go to https://github.com/paritytech/frontier/tree/master/template. The Substrate runtime works alongside the Ethereum pallet and the Dynamic Fee pallet to enable the creation of runtimes capable of fully emulating Ethereum block production and transaction processing. Start the Frontier workshop } link={ /tutorials/v3/frontier } />","title":"EVM pallet"},{"location":"main-docs/05-design/smart-contract-pallets/#evm-engine","text":"The EVM pallet uses SputnikVM as the underlying EVM engine. The engine is overhauled to be modular. For more information see Core Paper Project of EVM . The EVM is a good theoretical execution environment, but it is not very practical to use with modern hardware. For example, manipulation of 256 bit integers on modern architectures is significantly more complex than standard types. The Ethereum team has investigated the use of Wasm for the next generation of the network. An alternative to using the EVM is adding the Contracts pallet. The Contracts pallet iterates on existing ideas in the smart contract ecosystem, particularly Ethereum and the EVM. The most obvious difference between the Contracts pallet and the EVM is the underlying execution engine used to run smart contracts. To learn more about the Contracts pallet, see link .","title":"EVM engine"},{"location":"main-docs/05-design/smart-contract-pallets/#cost","text":"The EVM charges for storage fees only at the time of storage. This one-time cost results in some permanent amount of storage being used on the blockchain, forever, which is not economically sound.","title":"Cost"},{"location":"main-docs/05-design/smart-contract-pallets/#execution-lifecycle","text":"Substrate-based accounts can call the EVM pallet to deposit or withdraw a balance from the Substrate base-currency into a different balance managed and used by the EVM pallet. Once a user has populated their balance, they can create and call smart contracts using this pallet. There's one-to-one mapping from Substrate accounts and EVM external accounts defined by a conversion function.","title":"Execution lifecycle"},{"location":"main-docs/05-design/smart-contract-pallets/#evm-pallet-vs-ethereum-network","text":"The EVM pallet should be able to produce nearly identical results as the Ethereum mainnet, including gas cost and balance changes. Observable differences include: The available length of block hashes may not be 256 depending on the configuration of the Substrate System pallet in the Substrate runtime. For more information on the System pallet, see the System pallet rust documentation . Difficulty and coinbase, which do not make sense in this pallet and are currently hard-coded to zero. Unobservable behaviors, such as state root are not the same when using the EVM pallet. The transaction / receipt format is also different. However, given one Ethereum transaction and one Substrate account private key, you should be able to convert any Ethereum transaction into a transaction compatible with this pallet. The gas configurations are currently hard-coded to the Istanbul hard fork. It can later be expanded to support earlier hard fork configurations. Substrate is built to enable you to extend what's provided out of the box. We encourage further development of alternative smart contract platforms on top of the Substrate runtime. Use these pre-built pallets to inform how you might design your own system or how you could port over an existing system to work on a Substrate-based chain.","title":"EVM pallet vs. Ethereum network"},{"location":"main-docs/05-design/smart-contract-pallets/#faq","text":"","title":"FAQ"},{"location":"main-docs/05-design/smart-contract-pallets/#what-is-the-difference-between-memory-and-storage","text":"In ink! memory is the computer memory that is commonly known to programmers, while storage is the contract instance memory. The storage is backed up by the runtime in a database.","title":"What is the difference between memory and storage?"},{"location":"main-docs/05-design/smart-contract-pallets/#how-do-i-run-tests","text":"When building a smart contract with ink!, you can define a set of tests. For example, in the flipper contract , you can find a small test at the bottom of the contract. To run this test, type the following command: cargo +nightly test Learn more about why Rust is an ideal smart contract language . Follow a tutorial to add a pallet to your FRAME runtime .","title":"How do I run tests?"},{"location":"main-docs/05-design/smart-contract-pallets/#examples","text":"Follow a this guide to learn how to add the Contracts pallet to your FRAME runtime.","title":"Examples"},{"location":"main-docs/05-design/smart-contract-pallets/#references","text":"Visit the reference docs for the Contracts pallet . Take a look at the repository for wasmi . For more information on ink!, see https://paritytech.github.io/ink-docs/ . Learn how to start developing with the Contracts pallet and ink! see https://tutorials/v3/ink-workshop/pt1. To view the source code and documentation for the EVM pallet, see https://github.com/paritytech/frontier/tree/master/frame/evm. To view the ink! repository, see https://github.com/paritytech/ink. To view the reference documentation for the EVM pallet, see https://docs.rs/pallet_evm and https://docs.rs/fp-evm/. To view the reference documentation fir SputnikVM's evm crate, see https://docs.rs/evm/.","title":"References"},{"location":"main-docs/05-design/storage-design/","text":"TODO","title":"Storage design decisions"},{"location":"main-docs/06-build/best-practices/","text":"Best practices [ Note: rough sketch for now.. ] Blockchain-specific best practices write efficient code simple or complex functions minimize database reads/writes be mindful of constraints (processing time for computation, network bandwidth, storage, memory) Rust and Substrate-specific syntax Examples of good APIs Examples of using extrinsics Examples of using storage using saturated_add or checked_add for arithmetic operations. error checking. writing tests. Have a favorite you want to share? Let us know !","title":"Best practices"},{"location":"main-docs/06-build/best-practices/#best-practices","text":"[ Note: rough sketch for now.. ]","title":"Best practices"},{"location":"main-docs/06-build/best-practices/#blockchain-specific-best-practices","text":"write efficient code simple or complex functions minimize database reads/writes be mindful of constraints (processing time for computation, network bandwidth, storage, memory)","title":"Blockchain-specific best practices"},{"location":"main-docs/06-build/best-practices/#rust-and-substrate-specific-syntax","text":"Examples of good APIs Examples of using extrinsics Examples of using storage using saturated_add or checked_add for arithmetic operations. error checking. writing tests. Have a favorite you want to share? Let us know !","title":"Rust and Substrate-specific syntax"},{"location":"main-docs/06-build/build-process/","text":"This article describes what happens under the hood when building a Substrate node. Relevant context: Substrate runtimes are compiled to both native and Wasm . Runtimes should be compressed Wasm binaries for on-chain upgrades and relay chain validation capabilities to function correctly. Read about the anatomy of a full Substrate node here in order to understand how the client interacts with the runtime. Build process The native runtime is used as a regular Rust crate dependency to the Substrate client. You can see this when running cargo tree -i node-template-runtime from a standard Substrate node template: # Displays all packages that depend on the node-template-runtime package. node-template-runtime devhub/latest (...) \u2514\u2500\u2500 node-template devhub/latest (...) So what happens when cargo build --release is executed in the directory of a Substrate node template? At a very high level, this command builds the project it is being called in with optimized artifacts . These artifacts then result in the final executable program that enables launching a chain with the following command: ./target/release/node-template --dev . During the build process, the runtime Wasm binary goes through 3 different stages, whereby each stage depicts the various steps in the build process. The initial Wasm runtime is built in the first stage of the build cycle and embedded into the client. Once the program is compiled and executed, the compressed Wasm binary is placed in on-chain storage at the :code storage key. When a chain is launched, its genesis state is initialized by using the embedded Wasm in the chainspec from the native runtime by default. [ NOTE / TODO: turn A-D below into diagram ] A. Create the initial runtime Wasm binary Cargo builds the entire graph of dependencies in all project TOML files. The runtime's build.rs module uses the substrate-wasm-builder crate. This build.rs module executes and compiles the runtime into a Wasm binary, creating wasm_binary.rs , i.e. the intial wasm (largest size). B. Post-processing Then the substrate-wasm-builder wasm linker invokes the optimizations to create a Compact wasm binary. It optimizes some instruction sequences and removes any unnecessary sections, such as the ones for debugging, using a tool called wasm-opt . The runtime crate is a dependency of the node. C. Compression A zstd lossless compression algorithm is applied to minimize the size of the final Wasm binary. All users should use this Wasm binary. D. Result The runtime crate requires the Wasm blob from the first step and embeds it into its compilation result. The final executable binary is node-template . The ./target/release/node-template --dev command initializes a new chain, i.e. generates a new chainspec. The Wasm runtime is put as an item in storage (with the magic key named \u201c:code\u201d) Chain spec has the genesis state and includes the Wasm binary, which was fetched from the node-runtime crate. See the sizes of each Wasm binary in Polkadot: .rw-r--r-- 1.2M pep 1 Dec 16:13 \u2502 \u251c\u2500\u2500 polkadot_runtime.compact.compressed.wasm .rw-r--r-- 5.1M pep 1 Dec 16:13 \u2502 \u251c\u2500\u2500 polkadot_runtime.compact.wasm .rwxr-xr-x 5.5M pep 1 Dec 16:13 \u2502 \u2514\u2500\u2500 polkadot_runtime.wasm It is important to always use the compressed version especially for maintaining a chain in production . There is no need for using any other of the Wasm artifacts. See the README for the Wasm builder . Build options It can make sense to compile the Wasm binary only, if for example you are just trying to provide an upgraded Wasm to perform a forkless upgrade. Usually when performing a runtime upgrade, you want to provide both a native and Wasm binary. Doing only one usually is an incomplete release process and not considered best practice . In any case, when starting a new chain the initial Wasm binary is a requirement. In production the Wasm runtime comes from the chain specification of a chain. However, when starting a chain in developer mode at block 0, it uses the embedded Wasm from the native runtime. There are several ways to configure a chain to meet the requirements of your needs: SKIP_WASM_BUILD - Skips building any Wasm binary. This is useful when only native should be recompiled. If this is the first run and there doesn't exist a Wasm binary, this will set both variables to None . Use this script to build the no_std Wasm binary only. Use the [wasm-runtime-overrides] CLI flag to load the Wasm from the filesystem.","title":"Build process"},{"location":"main-docs/06-build/build-process/#build-process","text":"The native runtime is used as a regular Rust crate dependency to the Substrate client. You can see this when running cargo tree -i node-template-runtime from a standard Substrate node template: # Displays all packages that depend on the node-template-runtime package. node-template-runtime devhub/latest (...) \u2514\u2500\u2500 node-template devhub/latest (...) So what happens when cargo build --release is executed in the directory of a Substrate node template? At a very high level, this command builds the project it is being called in with optimized artifacts . These artifacts then result in the final executable program that enables launching a chain with the following command: ./target/release/node-template --dev . During the build process, the runtime Wasm binary goes through 3 different stages, whereby each stage depicts the various steps in the build process. The initial Wasm runtime is built in the first stage of the build cycle and embedded into the client. Once the program is compiled and executed, the compressed Wasm binary is placed in on-chain storage at the :code storage key. When a chain is launched, its genesis state is initialized by using the embedded Wasm in the chainspec from the native runtime by default. [ NOTE / TODO: turn A-D below into diagram ] A. Create the initial runtime Wasm binary Cargo builds the entire graph of dependencies in all project TOML files. The runtime's build.rs module uses the substrate-wasm-builder crate. This build.rs module executes and compiles the runtime into a Wasm binary, creating wasm_binary.rs , i.e. the intial wasm (largest size). B. Post-processing Then the substrate-wasm-builder wasm linker invokes the optimizations to create a Compact wasm binary. It optimizes some instruction sequences and removes any unnecessary sections, such as the ones for debugging, using a tool called wasm-opt . The runtime crate is a dependency of the node. C. Compression A zstd lossless compression algorithm is applied to minimize the size of the final Wasm binary. All users should use this Wasm binary. D. Result The runtime crate requires the Wasm blob from the first step and embeds it into its compilation result. The final executable binary is node-template . The ./target/release/node-template --dev command initializes a new chain, i.e. generates a new chainspec. The Wasm runtime is put as an item in storage (with the magic key named \u201c:code\u201d) Chain spec has the genesis state and includes the Wasm binary, which was fetched from the node-runtime crate. See the sizes of each Wasm binary in Polkadot: .rw-r--r-- 1.2M pep 1 Dec 16:13 \u2502 \u251c\u2500\u2500 polkadot_runtime.compact.compressed.wasm .rw-r--r-- 5.1M pep 1 Dec 16:13 \u2502 \u251c\u2500\u2500 polkadot_runtime.compact.wasm .rwxr-xr-x 5.5M pep 1 Dec 16:13 \u2502 \u2514\u2500\u2500 polkadot_runtime.wasm It is important to always use the compressed version especially for maintaining a chain in production . There is no need for using any other of the Wasm artifacts. See the README for the Wasm builder .","title":"Build process"},{"location":"main-docs/06-build/build-process/#build-options","text":"It can make sense to compile the Wasm binary only, if for example you are just trying to provide an upgraded Wasm to perform a forkless upgrade. Usually when performing a runtime upgrade, you want to provide both a native and Wasm binary. Doing only one usually is an incomplete release process and not considered best practice . In any case, when starting a new chain the initial Wasm binary is a requirement. In production the Wasm runtime comes from the chain specification of a chain. However, when starting a chain in developer mode at block 0, it uses the embedded Wasm from the native runtime. There are several ways to configure a chain to meet the requirements of your needs: SKIP_WASM_BUILD - Skips building any Wasm binary. This is useful when only native should be recompiled. If this is the first run and there doesn't exist a Wasm binary, this will set both variables to None . Use this script to build the no_std Wasm binary only. Use the [wasm-runtime-overrides] CLI flag to load the Wasm from the filesystem.","title":"Build options"},{"location":"main-docs/06-build/cli/","text":"Different CLI use cases for building or running a chain. Execution strategy [ NOTE: taken from https://docs.substrate.io/v3/advanced/executor/ ] The default execution strategies for the different parts of the blockchain execution process are: Syncing: NativeElseWasm Block Import (for non-validator): NativeElseWasm Block Import (for validator): AlwaysWasm Block Construction: AlwaysWasm Off-Chain Worker: NativeWhenPossible Other: NativeWhenPossible Source: [1] , [2] They can be overridden via the command line argument --execution-{block-construction, import-block, offchain-worker, other, syncing} <strategy> , or --execution <strategy> to apply the specified strategy to all five aspects. Details can be seen at substrate --help . When specifying on cli, the following shorthand strategy names are used: Native mapping to the NativeWhenPossible strategy Wasm mapping to the AlwaysWasm strategy Both mapping to the Both strategy NativeElseWasm mapping to NativeElsmWasm strategy Footnotes Substrate codebase client/cli/src/params/import_params.rs Substrate codebase client/cli/src/arg_enums.rs References Check out the different Execution Strategies . Take a look at the different Execution Strategy Options Review the Runtime Version definition .","title":"Cli"},{"location":"main-docs/06-build/cli/#execution-strategy","text":"[ NOTE: taken from https://docs.substrate.io/v3/advanced/executor/ ] The default execution strategies for the different parts of the blockchain execution process are: Syncing: NativeElseWasm Block Import (for non-validator): NativeElseWasm Block Import (for validator): AlwaysWasm Block Construction: AlwaysWasm Off-Chain Worker: NativeWhenPossible Other: NativeWhenPossible Source: [1] , [2] They can be overridden via the command line argument --execution-{block-construction, import-block, offchain-worker, other, syncing} <strategy> , or --execution <strategy> to apply the specified strategy to all five aspects. Details can be seen at substrate --help . When specifying on cli, the following shorthand strategy names are used: Native mapping to the NativeWhenPossible strategy Wasm mapping to the AlwaysWasm strategy Both mapping to the Both strategy NativeElseWasm mapping to NativeElsmWasm strategy","title":"Execution strategy"},{"location":"main-docs/06-build/cli/#footnotes","text":"Substrate codebase client/cli/src/params/import_params.rs Substrate codebase client/cli/src/arg_enums.rs","title":"Footnotes"},{"location":"main-docs/06-build/cli/#references","text":"Check out the different Execution Strategies . Take a look at the different Execution Strategy Options Review the Runtime Version definition .","title":"References"},{"location":"main-docs/06-build/custom-pallets/","text":"TODO: WIP Create custom pallets Writing a pallet is the first step towards composing custom runtime logic. Building ontop of existing pallets is common when building a custom runtime. For example, one could build an application specific staking pallet that uses the already existing Collective and Balances pallets. Pallet architecture Building a custom pallet is made easy with FRAME. Each part of the pallet is declared using the pallet macro which contains a long list of attributes, a few of which are: #[pallet::pallet] : This mandatory pallet attribute helps define a struct for the pallet, to carry information such as pallet storage which can then easily be accessed. #[pallet::config] : This mandatory pallet attribute allows defining the configuration trait for the pallet. #[pallet::call] : This attribute allows implementing a pallet's dispatchables. #[pallet::error] : This attribute generates dispatchable errors. #[pallet::event] : This attribute generates dispatchable events. #[pallet::storage] : This attribute generates a storage instance in the runtime along with its metadata. Although these macros give developers more flexibility to write Rust code, some of these macros enforce particular requirements on function declarations. For instance, the Config trait must be bound by frame_system::Config and the #[pallet::pallet] struct must be declared as pub struct Pallet<T>(_); . [ insert / use excerpts from : https://docs.substrate.io/v3/runtime/macros/] There are several architectural considerations to be made when writing a pallet. Storage. What will your pallet need to store? Are these items to be stored on or off-chain? Dispatchables. What publicly callable functions does your pallet require? Transactionality. What dispatchables are designed to atomically modify storage? Hooks. Will your pallet be making calls to any runtime hooks? Weights. What considerations must be taken into account to generate the correct weights for your disptachables? Useful FRAME traits Pallet Origin Origins: EnsureOrigin, EnsureOneOf ... Runtime implementation Writing a pallet and implementing it for a runtime go hand in hand. Your pallet's Config trait is what get's implemented for Runtime which is a special struct used to compile all implemented pallets in the construct_runtime macro. parameter_types and ord_parameter_types macros are useful for passing in values to configurable pallet constants. [ other considerations like no_std ] Minimilistic runtime references Side chain architecture references Api endpoints: on_initialize, off_chain workers ? Write content that links to basic and intermediate how-to guides.","title":"Create custom pallets"},{"location":"main-docs/06-build/custom-pallets/#create-custom-pallets","text":"Writing a pallet is the first step towards composing custom runtime logic. Building ontop of existing pallets is common when building a custom runtime. For example, one could build an application specific staking pallet that uses the already existing Collective and Balances pallets.","title":"Create custom pallets"},{"location":"main-docs/06-build/custom-pallets/#pallet-architecture","text":"Building a custom pallet is made easy with FRAME. Each part of the pallet is declared using the pallet macro which contains a long list of attributes, a few of which are: #[pallet::pallet] : This mandatory pallet attribute helps define a struct for the pallet, to carry information such as pallet storage which can then easily be accessed. #[pallet::config] : This mandatory pallet attribute allows defining the configuration trait for the pallet. #[pallet::call] : This attribute allows implementing a pallet's dispatchables. #[pallet::error] : This attribute generates dispatchable errors. #[pallet::event] : This attribute generates dispatchable events. #[pallet::storage] : This attribute generates a storage instance in the runtime along with its metadata. Although these macros give developers more flexibility to write Rust code, some of these macros enforce particular requirements on function declarations. For instance, the Config trait must be bound by frame_system::Config and the #[pallet::pallet] struct must be declared as pub struct Pallet<T>(_); . [ insert / use excerpts from : https://docs.substrate.io/v3/runtime/macros/] There are several architectural considerations to be made when writing a pallet. Storage. What will your pallet need to store? Are these items to be stored on or off-chain? Dispatchables. What publicly callable functions does your pallet require? Transactionality. What dispatchables are designed to atomically modify storage? Hooks. Will your pallet be making calls to any runtime hooks? Weights. What considerations must be taken into account to generate the correct weights for your disptachables?","title":"Pallet architecture"},{"location":"main-docs/06-build/custom-pallets/#useful-frame-traits","text":"Pallet Origin Origins: EnsureOrigin, EnsureOneOf ...","title":"Useful FRAME traits"},{"location":"main-docs/06-build/custom-pallets/#runtime-implementation","text":"Writing a pallet and implementing it for a runtime go hand in hand. Your pallet's Config trait is what get's implemented for Runtime which is a special struct used to compile all implemented pallets in the construct_runtime macro. parameter_types and ord_parameter_types macros are useful for passing in values to configurable pallet constants. [ other considerations like no_std ] Minimilistic runtime references Side chain architecture references Api endpoints: on_initialize, off_chain workers ? Write content that links to basic and intermediate how-to guides.","title":"Runtime implementation"},{"location":"main-docs/06-build/frontend/","text":"Different libraries exist for building frontend interfaces of Substrate-based chains and interacting with Substrate runtimes. Polkadot-JS The Polkadot-JS project is a collection of tools, interfaces, and libraries around Polkadot and Substrate. While the project is named after \"Polkadot\", these tools, interfaces, and libraries are fully compatible with any Substrate based chain. The Polkadot JS API provides application developers the ability to query a node and interact with the Polkadot or Substrate chains using Javascript. Substrate connect Substrate Connect is a JavaScript library and browser extension that builds on the Polkadot JS API to enable developers to build application specific light clients for Substrate chains. By using light clients available to all Substrate built blockchains, application developers no longer need to rely on single RPC nodes to allow end-users to interact with their applications. This introduces a new paradigm for decentralization: instead of specifying a centralized RPC node, developers just need to specify the blockchain's chain specification for their application to synchronize with the chain. Substrate Connect provides application developers ways to run a Substrate light client in any NodeJS environment, from in-browser applications and extensions, to Electron apps, IOT devices, and mobile phones. For in-browser end-users, Substrate Connect is a browser extension designed to facilitate using applications with multiple blockchains, where all light clients can run in a single tab. This implies two key features: Ready-to-use light clients for Substrate chains. Light clients are part of the Substrate framework and with that, available for every Substrate based blockchain. This means that all you need in order to connect a Substrate chain to your application is provide the chain specification of the chain you want to connect to. Bundling light-clients of multiple chains. With the browser extension, end-users are able to interact with applications connected to multiple blockchains or connect their own blockchains to applications that support it. Motivation Interacting with a Substrate chain via an RPC server requires a layer of third party trust which can be avoided. Substrate Connect uses a Wasm light client which connects to a Substrate chain without any unecessary intermediary. In addition, due to browser limitations on websockets from HTTPS pages, establishing a good number of peers is difficult as nodes are reachable only if they provide a TLS (Transport Layer Security) certificate. Substrate Connect provides a browser extension to overcome this limitation and to keep the chains synced in the background, making applications on a Substrate chain faster. How it works The extension runs a single light client, Smoldot that manages connecting to different blockchains. Whenever a user opens an app in a new browser tab it asks the extension to connect to whatever blockchains the app is interested in. The light client is smart enough to share resources so that it only connects to a network once even if there are multiple apps talking to it. The @substrate/connect library has the following capabilities: It detects whether a user has the Substrate Connect browser extension installed. If it isn't installed, it falls back to instantiating a light client directly in the page. It handles receiving and listening for messages from the browser extension and provider. It manages an app's connection to multiple blockchains, creating an instance of Smoldot and connecting the app to it. Usage When used in individual projects, the Substrate Connect node module will first check for the installed extension. If available, it will try to connect to the light client running inside the extension. Only if the extension is not installed will it start a light client in the browser tab. Learn how to integrate Substrate Connect in your applications here . [ TODO : Add substrate connect note: https://github.com/substrate-developer-hub/substrate-docs/issues/573 ].","title":"Front-end development"},{"location":"main-docs/06-build/frontend/#polkadot-js","text":"The Polkadot-JS project is a collection of tools, interfaces, and libraries around Polkadot and Substrate. While the project is named after \"Polkadot\", these tools, interfaces, and libraries are fully compatible with any Substrate based chain. The Polkadot JS API provides application developers the ability to query a node and interact with the Polkadot or Substrate chains using Javascript.","title":"Polkadot-JS"},{"location":"main-docs/06-build/frontend/#substrate-connect","text":"Substrate Connect is a JavaScript library and browser extension that builds on the Polkadot JS API to enable developers to build application specific light clients for Substrate chains. By using light clients available to all Substrate built blockchains, application developers no longer need to rely on single RPC nodes to allow end-users to interact with their applications. This introduces a new paradigm for decentralization: instead of specifying a centralized RPC node, developers just need to specify the blockchain's chain specification for their application to synchronize with the chain. Substrate Connect provides application developers ways to run a Substrate light client in any NodeJS environment, from in-browser applications and extensions, to Electron apps, IOT devices, and mobile phones. For in-browser end-users, Substrate Connect is a browser extension designed to facilitate using applications with multiple blockchains, where all light clients can run in a single tab. This implies two key features: Ready-to-use light clients for Substrate chains. Light clients are part of the Substrate framework and with that, available for every Substrate based blockchain. This means that all you need in order to connect a Substrate chain to your application is provide the chain specification of the chain you want to connect to. Bundling light-clients of multiple chains. With the browser extension, end-users are able to interact with applications connected to multiple blockchains or connect their own blockchains to applications that support it. Motivation Interacting with a Substrate chain via an RPC server requires a layer of third party trust which can be avoided. Substrate Connect uses a Wasm light client which connects to a Substrate chain without any unecessary intermediary. In addition, due to browser limitations on websockets from HTTPS pages, establishing a good number of peers is difficult as nodes are reachable only if they provide a TLS (Transport Layer Security) certificate. Substrate Connect provides a browser extension to overcome this limitation and to keep the chains synced in the background, making applications on a Substrate chain faster. How it works The extension runs a single light client, Smoldot that manages connecting to different blockchains. Whenever a user opens an app in a new browser tab it asks the extension to connect to whatever blockchains the app is interested in. The light client is smart enough to share resources so that it only connects to a network once even if there are multiple apps talking to it. The @substrate/connect library has the following capabilities: It detects whether a user has the Substrate Connect browser extension installed. If it isn't installed, it falls back to instantiating a light client directly in the page. It handles receiving and listening for messages from the browser extension and provider. It manages an app's connection to multiple blockchains, creating an instance of Smoldot and connecting the app to it. Usage When used in individual projects, the Substrate Connect node module will first check for the installed extension. If available, it will try to connect to the light client running inside the extension. Only if the extension is not installed will it start a light client in the browser tab. Learn how to integrate Substrate Connect in your applications here . [ TODO : Add substrate connect note: https://github.com/substrate-developer-hub/substrate-docs/issues/573 ].","title":"Substrate connect"},{"location":"main-docs/06-build/libraries/","text":"This article goes over the different libraries available for building blockchains with Substrate. Core libraries At a high level, Substrate consists of libraries to build: a client, a runtime and the communication layer between the two. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 Primitives \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 Runtime \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 NOTE: Diagram is a rough sketch. Each part is not meant to be interpreted as nested, rather that \"primitives\" enable communication between the Clients and Runtimes. Need to annotate diagram with below: Client : Libraries that enable the client and networking layer, including consensus and block execution. Primitives : Libraries responsible for communicating between the client and the runtime, creating the transaction pool and building blocks for the block executor. FRAME : Libraries to facilitate building runtime logic and encoding and decoding information passing to and from the runtime. Each of these components are built from Rust libraries that fall under four categories: sc_* : Substrate client libraries encapsulate the numerous crates for node and client facing infrastructure, including consensus critical infrastructure, P2P networking, RPC APIs and block execution. For example, sc_service is responsible for building the networking layer for Substrate blockchains, managing the communication between the network, client and transaction pool. sp_* : Substrate primitives are libraries to facilitate communication between the client and the runtime. For example, sp_std takes useful primitives from Rust's standard library and makes them usable with any code that depends on the runtime. frame_* : runtime SDK libraries for building use case specific runtime logic and calling to and from a runtime. For example, frame_support enables developers to easily declare runtime storage items, errors and events and frame_system acts as the base layer for other pallets to interact with other Substrate components. pallet_* : a single FRAME module, of which exists an existing collection created for Polkadot and Kusama. Other pallet libraries exist such as the Open Runtime Module Library (ORML) . SCALE codec SCALE (Simple Concatenated Aggregate Little-Endian) Codec is a lightweight, efficient, binary serialization and deserialization codec . It is designed for high-performance, copy-free encoding and decoding of data in resource-constrained execution contexts, like the Substrate runtime . It is not self-describing in any way and assumes the decoding context has all type knowledge about the encoded data. Substrate uses the parity-scale-codec , a Rust implementation of the SCALE Codec. This library and the SCALE codec are advantageous for Substrate and blockchain systems because: It is lightweight relative to generic serialization frameworks like serde , which add significant boilerplate that can bloat the size of the binary. It does not use Rust libstd making it compatible with no_std environments that compile to Wasm, such as the Substrate runtime. It is built to have great support in Rust for deriving codec logic for new types using: #[derive(Encode, Decode)] . It's important to define the encoding scheme used in Substrate rather than reuse an existing Rust codec library because this codec needs to be re-implemented on other platforms and languages that want to support interoperability among Substrate blockchains. The table below shows how the Rust implementation of Parity's SCALE codec encodes different types. SCALE codec examples of different types Type Description Example SCALE encoded value SCALE decoded value Fixed-width integers Basic integers are encoded using a fixed-width little-endian (LE) format. signed 8-bit integer 69 0x45 unsigned 16-bit integer 42 0x2a00 unsigned 32-bit integer 16777215 0xffffff00 Compact/general integers[^1] A \"compact\" or general integer encoding is sufficient for encoding large integers (up to 2**536) and is more efficient at encoding most values than the fixed-width version. (Though for single-byte values, the fixed-width integer is never worse.) unsigned integer 0 0x00 unsigned integer 1 0x04 unsigned integer 42 0xa8 unsigned integer 69 0x1501 unsigned integer 65535 0xfeff0300 BigInt(100000000000000) 0x0b00407a10f35a Boolean Boolean values are encoded using the least significant bit of a single byte. false 0x00 true 0x01 Results [^2] Results are commonly used enumerations which indicate whether certain operations were successful or unsuccessful. Ok(42) 0x002a Err(false) 0x0100 Options [^3] One or zero values of a particular type. Some 0x01 followed by the encoded value. None 0x00 true 0x01 false 0x02 Vectors (lists, series, sets) A collection of same-typed values is encoded, prefixed with a compact encoding of the number of items, followed by each item's encoding concatenated in turn. Vector of unsigned 16-bit integers: [4, 8, 15, 16, 23, 42] 0x18040008000f00100017002a00 Strings Strings are Vectors of bytes ( Vec<u8> ) containing a valid UTF8 sequence. Tuples A fixed-size series of values, each with a possibly different but predetermined and fixed type. This is simply the concatenation of each encoded value. Tuple of compact unsigned integer and boolean: (3, false) 0x0c00 Structs For structures, the values are named, but that is irrelevant for the encoding (names are ignored - only order matters). All containers store elements consecutively. The order of the elements is not fixed, depends on the container, and cannot be relied on at decoding. This implicitly means that decoding some byte-array into a specified structure that enforces an order and then re-encoding it could result in a different byte array than the original that was decoded. A SortedVecAsc<u8> structure that always has byte-elements in ascending order: SortedVecAsc::from([3, 5, 2, 8]) [3, 2, 5, 8] Enumerations (tagged-unions) A fixed number of variants, each mutually exclusive and potentially implying a further value or series of values. Encoded as the first byte identifying the index of the variant that the value is. Any further bytes are used to encode any data that the variant implies. Thus, no more than 256 variants are supported. Int(42) and Bool(true) where enum IntOrBool { Int(u8), Bool(bool),} 0x002a and 0x0101 Footnotes: [^1]: Compact/general integers are encoded with the two least significant bits denoting the mode: - `0b00`: single-byte mode; upper six bits are the LE encoding of the value (valid only for values of 0-63). - `0b01`: two-byte mode: upper six bits and the following byte is the LE encoding of the value (valid only for values `64-(2**14-1)`). - `0b10`: four-byte mode: upper six bits and the following three bytes are the LE encoding of the value (valid only for values `(2**14)-(2**30-1)`). - `0b11`: Big-integer mode: The upper six bits are the number of bytes following, plus four. The value is contained, LE encoded, in the bytes following. The final (most significant) byte must be non-zero. Valid only for values `(2**30)-(2**536-1)`. [^2]: Results are encoded as: - `0x00` if the operation was successful, followed by the encoded value. - `0x01` if the operation was unsuccessful, followed by the encoded error. [^3]: Options are encoded as: - `0x00` if it is `None` (\"empty\" or \"null\"). - `0x01` followed by the encoded value if it is `Some`. As an exception, in the case that the type is a boolean, then it is always one byte. The Parity SCALE Codec has been implemented in many other languages, including: Python: polkascan/py-scale-codec Golang: itering/scale.go C: MatthewDarnell/cScale C++: soramitsu/scale-codec-cpp JavaScript: polkadot-js/api AssemblyScript: LimeChain/as-scale-codec Haskell: airalab/hs-web3 Java: emeraldpay/polkaj Ruby: itering/scale.rb Other libraries There are a number of language-specific client libraries that can be used to interact with the Substrate framework . In general, the capabilities that these libraries expose are implemented on top of the Substrate remote procedure call (RPC) API. Although it is possible to build an alternative to FRAME using Substrate primitives, there has not yet been any significant community efforts to do so yet. Rust Parity maintains subxt , which is a Rust library specifically designed for submitting extrinsics to Substrate blockchains. The the Substrate API Client is another Substrate client library written in Rust that is maintained by Supercomputing Systems; its API is more general-purpose than subxt . JavaScript The Polkadot JS team maintains a rich set of tools for interacting with Substrate-based blockchains. Refer to the main Polkadot JS page to learn more about that suite of tools. Parity also maintains txwrapper , which is a Javascript library for offline generation of Substrate transactions. Go The Go Substrate RPC Client (GSRPC), is maintained by Centrifuge . C Polkadot API DotNet is a Substrate RPC client library for .NET developers. It is maintained by Usetech . SubstrateNetApi is a .NET Standard API ( nuget ) allowing full Substrate integration in Unity3D for gaming development, starter template project . It is maintained by DOTMog Team . C++ Usetech also maintains Polkadot API CPP , which is a C++ library for interacting with the Substrate RPC. Python py-substrate-interface is a Python library for interacting with the Substrate RPC. It supports a wide range of capabilities and powers the Polkascan multi-chain block explorer . This library is maintained by Polkascan Foundation .","title":"Introduction to libraries"},{"location":"main-docs/06-build/libraries/#core-libraries","text":"At a high level, Substrate consists of libraries to build: a client, a runtime and the communication layer between the two. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Client \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 Primitives \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 Runtime \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 NOTE: Diagram is a rough sketch. Each part is not meant to be interpreted as nested, rather that \"primitives\" enable communication between the Clients and Runtimes. Need to annotate diagram with below: Client : Libraries that enable the client and networking layer, including consensus and block execution. Primitives : Libraries responsible for communicating between the client and the runtime, creating the transaction pool and building blocks for the block executor. FRAME : Libraries to facilitate building runtime logic and encoding and decoding information passing to and from the runtime. Each of these components are built from Rust libraries that fall under four categories: sc_* : Substrate client libraries encapsulate the numerous crates for node and client facing infrastructure, including consensus critical infrastructure, P2P networking, RPC APIs and block execution. For example, sc_service is responsible for building the networking layer for Substrate blockchains, managing the communication between the network, client and transaction pool. sp_* : Substrate primitives are libraries to facilitate communication between the client and the runtime. For example, sp_std takes useful primitives from Rust's standard library and makes them usable with any code that depends on the runtime. frame_* : runtime SDK libraries for building use case specific runtime logic and calling to and from a runtime. For example, frame_support enables developers to easily declare runtime storage items, errors and events and frame_system acts as the base layer for other pallets to interact with other Substrate components. pallet_* : a single FRAME module, of which exists an existing collection created for Polkadot and Kusama. Other pallet libraries exist such as the Open Runtime Module Library (ORML) .","title":"Core libraries"},{"location":"main-docs/06-build/libraries/#scale-codec","text":"SCALE (Simple Concatenated Aggregate Little-Endian) Codec is a lightweight, efficient, binary serialization and deserialization codec . It is designed for high-performance, copy-free encoding and decoding of data in resource-constrained execution contexts, like the Substrate runtime . It is not self-describing in any way and assumes the decoding context has all type knowledge about the encoded data. Substrate uses the parity-scale-codec , a Rust implementation of the SCALE Codec. This library and the SCALE codec are advantageous for Substrate and blockchain systems because: It is lightweight relative to generic serialization frameworks like serde , which add significant boilerplate that can bloat the size of the binary. It does not use Rust libstd making it compatible with no_std environments that compile to Wasm, such as the Substrate runtime. It is built to have great support in Rust for deriving codec logic for new types using: #[derive(Encode, Decode)] . It's important to define the encoding scheme used in Substrate rather than reuse an existing Rust codec library because this codec needs to be re-implemented on other platforms and languages that want to support interoperability among Substrate blockchains. The table below shows how the Rust implementation of Parity's SCALE codec encodes different types. SCALE codec examples of different types Type Description Example SCALE encoded value SCALE decoded value Fixed-width integers Basic integers are encoded using a fixed-width little-endian (LE) format. signed 8-bit integer 69 0x45 unsigned 16-bit integer 42 0x2a00 unsigned 32-bit integer 16777215 0xffffff00 Compact/general integers[^1] A \"compact\" or general integer encoding is sufficient for encoding large integers (up to 2**536) and is more efficient at encoding most values than the fixed-width version. (Though for single-byte values, the fixed-width integer is never worse.) unsigned integer 0 0x00 unsigned integer 1 0x04 unsigned integer 42 0xa8 unsigned integer 69 0x1501 unsigned integer 65535 0xfeff0300 BigInt(100000000000000) 0x0b00407a10f35a Boolean Boolean values are encoded using the least significant bit of a single byte. false 0x00 true 0x01 Results [^2] Results are commonly used enumerations which indicate whether certain operations were successful or unsuccessful. Ok(42) 0x002a Err(false) 0x0100 Options [^3] One or zero values of a particular type. Some 0x01 followed by the encoded value. None 0x00 true 0x01 false 0x02 Vectors (lists, series, sets) A collection of same-typed values is encoded, prefixed with a compact encoding of the number of items, followed by each item's encoding concatenated in turn. Vector of unsigned 16-bit integers: [4, 8, 15, 16, 23, 42] 0x18040008000f00100017002a00 Strings Strings are Vectors of bytes ( Vec<u8> ) containing a valid UTF8 sequence. Tuples A fixed-size series of values, each with a possibly different but predetermined and fixed type. This is simply the concatenation of each encoded value. Tuple of compact unsigned integer and boolean: (3, false) 0x0c00 Structs For structures, the values are named, but that is irrelevant for the encoding (names are ignored - only order matters). All containers store elements consecutively. The order of the elements is not fixed, depends on the container, and cannot be relied on at decoding. This implicitly means that decoding some byte-array into a specified structure that enforces an order and then re-encoding it could result in a different byte array than the original that was decoded. A SortedVecAsc<u8> structure that always has byte-elements in ascending order: SortedVecAsc::from([3, 5, 2, 8]) [3, 2, 5, 8] Enumerations (tagged-unions) A fixed number of variants, each mutually exclusive and potentially implying a further value or series of values. Encoded as the first byte identifying the index of the variant that the value is. Any further bytes are used to encode any data that the variant implies. Thus, no more than 256 variants are supported. Int(42) and Bool(true) where enum IntOrBool { Int(u8), Bool(bool),} 0x002a and 0x0101 Footnotes: [^1]: Compact/general integers are encoded with the two least significant bits denoting the mode: - `0b00`: single-byte mode; upper six bits are the LE encoding of the value (valid only for values of 0-63). - `0b01`: two-byte mode: upper six bits and the following byte is the LE encoding of the value (valid only for values `64-(2**14-1)`). - `0b10`: four-byte mode: upper six bits and the following three bytes are the LE encoding of the value (valid only for values `(2**14)-(2**30-1)`). - `0b11`: Big-integer mode: The upper six bits are the number of bytes following, plus four. The value is contained, LE encoded, in the bytes following. The final (most significant) byte must be non-zero. Valid only for values `(2**30)-(2**536-1)`. [^2]: Results are encoded as: - `0x00` if the operation was successful, followed by the encoded value. - `0x01` if the operation was unsuccessful, followed by the encoded error. [^3]: Options are encoded as: - `0x00` if it is `None` (\"empty\" or \"null\"). - `0x01` followed by the encoded value if it is `Some`. As an exception, in the case that the type is a boolean, then it is always one byte. The Parity SCALE Codec has been implemented in many other languages, including: Python: polkascan/py-scale-codec Golang: itering/scale.go C: MatthewDarnell/cScale C++: soramitsu/scale-codec-cpp JavaScript: polkadot-js/api AssemblyScript: LimeChain/as-scale-codec Haskell: airalab/hs-web3 Java: emeraldpay/polkaj Ruby: itering/scale.rb","title":"SCALE codec"},{"location":"main-docs/06-build/libraries/#other-libraries","text":"There are a number of language-specific client libraries that can be used to interact with the Substrate framework . In general, the capabilities that these libraries expose are implemented on top of the Substrate remote procedure call (RPC) API. Although it is possible to build an alternative to FRAME using Substrate primitives, there has not yet been any significant community efforts to do so yet.","title":"Other libraries"},{"location":"main-docs/06-build/libraries/#rust","text":"Parity maintains subxt , which is a Rust library specifically designed for submitting extrinsics to Substrate blockchains. The the Substrate API Client is another Substrate client library written in Rust that is maintained by Supercomputing Systems; its API is more general-purpose than subxt .","title":"Rust"},{"location":"main-docs/06-build/libraries/#javascript","text":"The Polkadot JS team maintains a rich set of tools for interacting with Substrate-based blockchains. Refer to the main Polkadot JS page to learn more about that suite of tools. Parity also maintains txwrapper , which is a Javascript library for offline generation of Substrate transactions.","title":"JavaScript"},{"location":"main-docs/06-build/libraries/#go","text":"The Go Substrate RPC Client (GSRPC), is maintained by Centrifuge .","title":"Go"},{"location":"main-docs/06-build/libraries/#c","text":"Polkadot API DotNet is a Substrate RPC client library for .NET developers. It is maintained by Usetech . SubstrateNetApi is a .NET Standard API ( nuget ) allowing full Substrate integration in Unity3D for gaming development, starter template project . It is maintained by DOTMog Team .","title":"C"},{"location":"main-docs/06-build/libraries/#c_1","text":"Usetech also maintains Polkadot API CPP , which is a C++ library for interacting with the Substrate RPC.","title":"C++"},{"location":"main-docs/06-build/libraries/#python","text":"py-substrate-interface is a Python library for interacting with the Substrate RPC. It supports a wide range of capabilities and powers the Polkascan multi-chain block explorer . This library is maintained by Polkascan Foundation .","title":"Python"},{"location":"main-docs/07-test/benchmark/","text":"","title":"Benchmark"},{"location":"main-docs/07-test/debug/","text":"","title":"Debug"},{"location":"main-docs/07-test/deploy-on-testnet/","text":"","title":"Deploy on a testnet"},{"location":"main-docs/07-test/test/","text":"Test Benchmark Unit (local) testing Debug Deploy on a testnet Validate","title":"Test"},{"location":"main-docs/07-test/test/#test","text":"Benchmark Unit (local) testing Debug Deploy on a testnet Validate","title":"Test"},{"location":"main-docs/07-test/unit-testing/","text":"","title":"Unit testing"},{"location":"main-docs/08-deploy/deploy/","text":"Deploy Launch a solo chain (public chain? private chain? permissioned chain?) Some of these topics might have been touched on in earlier phases, but it this section the focus is on what's relevant to deploying your customized blockchain. Validators / consensus Networking basics Finality Genesis construction Protecting the network from attacks Potentially, this bucket might cover DevOps material, maintenance, monitoring, and operations topics.","title":"Deploy"},{"location":"main-docs/08-deploy/deploy/#deploy","text":"Launch a solo chain (public chain? private chain? permissioned chain?) Some of these topics might have been touched on in earlier phases, but it this section the focus is on what's relevant to deploying your customized blockchain. Validators / consensus Networking basics Finality Genesis construction Protecting the network from attacks Potentially, this bucket might cover DevOps material, maintenance, monitoring, and operations topics.","title":"Deploy"},{"location":"main-docs/08-deploy/migrate/","text":"Migrate to Polkadot Construct Cumulus Launch Parachain PoV Limitations that apply to parachains Collators Maintain a parachain","title":"Migrate to Polkadot"},{"location":"main-docs/08-deploy/migrate/#migrate-to-polkadot","text":"Construct Cumulus Launch Parachain PoV Limitations that apply to parachains Collators Maintain a parachain","title":"Migrate to Polkadot"},{"location":"main-docs/08-deploy/monitor/","text":"Monitor Metrics and dashboards Alerting on bad behavior","title":"Monitor"},{"location":"main-docs/08-deploy/monitor/#monitor","text":"Metrics and dashboards Alerting on bad behavior","title":"Monitor"},{"location":"main-docs/08-deploy/operate/","text":"Operate Maintain the blockchain you have deployed Keeping up with Substrate metadata updates. Maintain runtime uptime","title":"Operate"},{"location":"main-docs/08-deploy/operate/#operate","text":"Maintain the blockchain you have deployed Keeping up with Substrate metadata updates. Maintain runtime uptime","title":"Operate"},{"location":"main-docs/09-maintain/","text":"Maintain This section cover upgrades and maintenance tasks.","title":"Maintain"},{"location":"main-docs/09-maintain/#maintain","text":"This section cover upgrades and maintenance tasks.","title":"Maintain"},{"location":"main-docs/09-maintain/upgrade/","text":"Upgrade Runtime upgrades Runtime migrations","title":"Upgrade"},{"location":"main-docs/09-maintain/upgrade/#upgrade","text":"Runtime upgrades Runtime migrations","title":"Upgrade"},{"location":"reference/","text":"Reference This section contains API documentation and links to reference material for tools and libraries.","title":"Reference"},{"location":"reference/#reference","text":"This section contains API documentation and links to reference material for tools and libraries.","title":"Reference"},{"location":"reference/client-lib/","text":"Client libraries There are language-specific client libraries that you can use to interact with Substrate-based blockchains. In general, these libraries expose functions that are implemented using the Substrate remote procedure call (RPC) API. JavaScript The Polkadot JS team maintains a rich set of tools for interacting with Substrate-based blockchains. Refer to the main Polkadot JS page to learn more about that suite of tools. Parity also maintains txwrapper , which is a Javascript library for offline generation of Substrate transactions. Go The Go Substrate RPC Client , AKA GSRPC, is maintained by Centrifuge . C Polkadot API DotNet is a Substrate RPC client library for .Net programmers. It is maintained by Usetech . SubstrateNetApi .NET Standard API ( nuget ) allowing full substrate integration in Unity3D for gaming development, starter template project . It is maintained by DOTMog Team . C++ Usetech also maintains Polkadot API CPP, which is a C++ library for interacting with the Substrate RPC. Rust Parity maintains substrate-subxt , which is a Rust library specifically designed for submitting extrinsics to Substrate blockchains. The the Substrate API Client is another Substrate client library for Rust that is maintained by Supercomputing Systems; its API is more general-purpose than substrate-subxt . Python py-substrate-interface is a Python library for interacting with the Substrate RPC. It supports a wide range of capabilities and powers the Polkascan multi-chain block explorer . This library is maintained by Polkascan Foundation .","title":"Client libraries"},{"location":"reference/client-lib/#client-libraries","text":"There are language-specific client libraries that you can use to interact with Substrate-based blockchains. In general, these libraries expose functions that are implemented using the Substrate remote procedure call (RPC) API.","title":"Client libraries"},{"location":"reference/client-lib/#javascript","text":"The Polkadot JS team maintains a rich set of tools for interacting with Substrate-based blockchains. Refer to the main Polkadot JS page to learn more about that suite of tools. Parity also maintains txwrapper , which is a Javascript library for offline generation of Substrate transactions.","title":"JavaScript"},{"location":"reference/client-lib/#go","text":"The Go Substrate RPC Client , AKA GSRPC, is maintained by Centrifuge .","title":"Go"},{"location":"reference/client-lib/#c","text":"Polkadot API DotNet is a Substrate RPC client library for .Net programmers. It is maintained by Usetech . SubstrateNetApi .NET Standard API ( nuget ) allowing full substrate integration in Unity3D for gaming development, starter template project . It is maintained by DOTMog Team .","title":"C"},{"location":"reference/client-lib/#c_1","text":"Usetech also maintains Polkadot API CPP, which is a C++ library for interacting with the Substrate RPC.","title":"C++"},{"location":"reference/client-lib/#rust","text":"Parity maintains substrate-subxt , which is a Rust library specifically designed for submitting extrinsics to Substrate blockchains. The the Substrate API Client is another Substrate client library for Rust that is maintained by Supercomputing Systems; its API is more general-purpose than substrate-subxt .","title":"Rust"},{"location":"reference/client-lib/#python","text":"py-substrate-interface is a Python library for interacting with the Substrate RPC. It supports a wide range of capabilities and powers the Polkascan multi-chain block explorer . This library is maintained by Polkascan Foundation .","title":"Python"},{"location":"reference/frame-pallets/","text":"The FRAME development environment provides modules\u2014called pallets\u2014and support libraries that you can use, modify, and extend to build the runtime logic to suite the needs of your blockchain. This section provides an overview of the predefined pallets and links to the Rust API reference documentation, where you can find details about each pallet's interfaces. System pallets The FRAME system pallets are integral to the Substrate runtime and provide core functionality that all other pallets depend on. System pallet name What it's for frame_executive Orchestrates incoming function calls by sending them to the appropriate pallets in the runtime. frame_support Provides Rust macros, types, traits, and modules that generate boilerplate code for the pallet structure when compiled. frame_system Defines low-level types for Substrate primitives, storage items, and core functions for the blockchain. All other pallets depend on the frame_system crate. Functional pallets The Substrate development framework includes many functional pallets that provide features you might find generally useful as composable components of your blockchain. These functional pallets are prebuilt and freely available to enable the community to share, reuse, and improve the interfaces to address common use cases. Prebuilt pallet name What it's for pallet_assets Provides simple and secure methods for dealing with fungible assets. pallet_atomic_swap Enables sending funds from an origin to a target. A proof is used to allow the target to claim the swap. If the swap is not claimed within a specified duration of time, the sender may cancel it. pallet_aura Extends the authority round (Aura) consensus model by managing offline reporting. pallet_authority_discovery Retrieves the current set of authorities, learns its own authority ID, and signs and verifies messages to and from other authorities. pallet_authorship Tracks the current author of the block and recent uncles. pallet_babe Extends BABE consensus by pallet_balances Provides functionality for handling accounts and balances. frame_benchmarking Contains common runtime patterns for benchmarking and testing purposes. pallet_collective Allows a set of account IDs to make their collective feelings known through dispatched calls from specialized origins. pallet_contracts Provides functionality for the runtime to deploy and execute WebAssembly smart contracts. pallet_democracy Provides a democratic system that handles administration of general stakeholder voting. pallet_elections_phragmen Provides an election module based on sequential Phragm\u00e9n . pallet_elections Provides an election module for stake-weighted membership in a collective. This pallet is no longer maintained. pallet_example Demonstrates concepts, APIs, and structures that are applicable for most pallets. pallet_example_offchain_worker Demonstrates concepts, APIs, and structures that are applicable for most offchain workers. pallet_grandpa Extends the GRANDPA consensus by managing the GRANDPA authority set ready for the native code. pallet_identity Enables a federated naming system that allows multiple registrars to be added from a specified origin. Registrars can set a fee to provide identity-verification service. pallet_im_online Allows validators to gossip a heartbeat transaction with each new session to signal that the node is online. pallet_indices Allocates indices for newly created accounts. An index is a short form of an address. pallet_membership Allows control of membership of a set of AccountId s, useful for managing the membership of a collective. pallet_multisig Enables multi-signature dispatches. pallet_nicks Demonstrates simplified account naming on-chain. It makes no effort to create a name hierarchy, be a DNS replacement, or provide reverse lookups. pallet_offences Tracks reported offences. pallet_proxy Allows accounts to give permission to other accounts to dispatch types of calls from their signed origin. pallet_randomness_collective_flip Provides a random function that can be used in tests and generates low-influence random values based on the block hashes from the previous 81 blocks. This pallet is not intended for use in production. pallet_recovery Provides a social recovery tool for users to gain access to their accounts if their private key or other authentication mechanism is lost. This pallet enables an account owner to identify trusted parties who can act on the owner's behalf to recover access to an account. pallet_scheduler Exposes capabilities for scheduling dispatches to occur at a specified block number or at a specified period. These scheduled dispatches can be named or anonymous and can be canceled. pallet_scored_pool Maintains a scored membership pool where the highest scoring entities are made members. pallet_session Allows validators to manage their session keys, provides a function for changing the session length, and handles session rotation. pallet_society Provides economic incentives for users to participate and maintain a membership society. pallet_staking Manages funds that have been staked by network maintainers. pallet_sudo Allows for a single account\u2014called the sudo key\u2014to execute dispatchable functions that require a Root origin or designate a new account to replace them as the sudo key. pallet_timestamp Provides functionality to get and set the on-chain time. pallet_transaction_payment Provides the basic logic to compute pre-dispatch transaction fees. pallet_treasury Provides a reserve of funds that can be managed by stakeholders in the system and a structure for making spending proposals from this reserve. pallet_utility Provides a stateless helper module for managing dispatches. pallet_vesting Places a linear curve on an account's locked balance. This module ensures that there is a lock in place to prevent the balance to drop below the unvested amount for any reason other than transaction fee payment. Additional information For detailed information about any pallet, refer to the Rust-generated API documentation or the source code for the individual pallet.","title":"FRAME pallets"},{"location":"reference/frame-pallets/#system-pallets","text":"The FRAME system pallets are integral to the Substrate runtime and provide core functionality that all other pallets depend on. System pallet name What it's for frame_executive Orchestrates incoming function calls by sending them to the appropriate pallets in the runtime. frame_support Provides Rust macros, types, traits, and modules that generate boilerplate code for the pallet structure when compiled. frame_system Defines low-level types for Substrate primitives, storage items, and core functions for the blockchain. All other pallets depend on the frame_system crate.","title":"System pallets"},{"location":"reference/frame-pallets/#functional-pallets","text":"The Substrate development framework includes many functional pallets that provide features you might find generally useful as composable components of your blockchain. These functional pallets are prebuilt and freely available to enable the community to share, reuse, and improve the interfaces to address common use cases. Prebuilt pallet name What it's for pallet_assets Provides simple and secure methods for dealing with fungible assets. pallet_atomic_swap Enables sending funds from an origin to a target. A proof is used to allow the target to claim the swap. If the swap is not claimed within a specified duration of time, the sender may cancel it. pallet_aura Extends the authority round (Aura) consensus model by managing offline reporting. pallet_authority_discovery Retrieves the current set of authorities, learns its own authority ID, and signs and verifies messages to and from other authorities. pallet_authorship Tracks the current author of the block and recent uncles. pallet_babe Extends BABE consensus by pallet_balances Provides functionality for handling accounts and balances. frame_benchmarking Contains common runtime patterns for benchmarking and testing purposes. pallet_collective Allows a set of account IDs to make their collective feelings known through dispatched calls from specialized origins. pallet_contracts Provides functionality for the runtime to deploy and execute WebAssembly smart contracts. pallet_democracy Provides a democratic system that handles administration of general stakeholder voting. pallet_elections_phragmen Provides an election module based on sequential Phragm\u00e9n . pallet_elections Provides an election module for stake-weighted membership in a collective. This pallet is no longer maintained. pallet_example Demonstrates concepts, APIs, and structures that are applicable for most pallets. pallet_example_offchain_worker Demonstrates concepts, APIs, and structures that are applicable for most offchain workers. pallet_grandpa Extends the GRANDPA consensus by managing the GRANDPA authority set ready for the native code. pallet_identity Enables a federated naming system that allows multiple registrars to be added from a specified origin. Registrars can set a fee to provide identity-verification service. pallet_im_online Allows validators to gossip a heartbeat transaction with each new session to signal that the node is online. pallet_indices Allocates indices for newly created accounts. An index is a short form of an address. pallet_membership Allows control of membership of a set of AccountId s, useful for managing the membership of a collective. pallet_multisig Enables multi-signature dispatches. pallet_nicks Demonstrates simplified account naming on-chain. It makes no effort to create a name hierarchy, be a DNS replacement, or provide reverse lookups. pallet_offences Tracks reported offences. pallet_proxy Allows accounts to give permission to other accounts to dispatch types of calls from their signed origin. pallet_randomness_collective_flip Provides a random function that can be used in tests and generates low-influence random values based on the block hashes from the previous 81 blocks. This pallet is not intended for use in production. pallet_recovery Provides a social recovery tool for users to gain access to their accounts if their private key or other authentication mechanism is lost. This pallet enables an account owner to identify trusted parties who can act on the owner's behalf to recover access to an account. pallet_scheduler Exposes capabilities for scheduling dispatches to occur at a specified block number or at a specified period. These scheduled dispatches can be named or anonymous and can be canceled. pallet_scored_pool Maintains a scored membership pool where the highest scoring entities are made members. pallet_session Allows validators to manage their session keys, provides a function for changing the session length, and handles session rotation. pallet_society Provides economic incentives for users to participate and maintain a membership society. pallet_staking Manages funds that have been staked by network maintainers. pallet_sudo Allows for a single account\u2014called the sudo key\u2014to execute dispatchable functions that require a Root origin or designate a new account to replace them as the sudo key. pallet_timestamp Provides functionality to get and set the on-chain time. pallet_transaction_payment Provides the basic logic to compute pre-dispatch transaction fees. pallet_treasury Provides a reserve of funds that can be managed by stakeholders in the system and a structure for making spending proposals from this reserve. pallet_utility Provides a stateless helper module for managing dispatches. pallet_vesting Places a linear curve on an account's locked balance. This module ensures that there is a lock in place to prevent the balance to drop below the unvested amount for any reason other than transaction fee payment.","title":"Functional pallets"},{"location":"reference/frame-pallets/#additional-information","text":"For detailed information about any pallet, refer to the Rust-generated API documentation or the source code for the individual pallet.","title":"Additional information"},{"location":"reference/glossary/","text":"This glossary defines and explains concepts and terminology that are specific to blockchain technology or the Substrate ecosystem. adaptive quorum biasing (AQB) Provides a mechanism for adjusting the passing threshold for a referendum based on voter turnout. Adaptive quorum biasing allows for more flexible governance by removing the requirement to have an arbitrary quorum for voting purposes, which create undesirable governance mechanics. Adaptive quorum biasing is implemented in the Democracy pallet . The Democracy pallet provides the interfaces for on-chain bodies such as a collective or individual token holder\u2014to call referenda with positive, negative, or neutral biases. With a positive turnout bias , the passing threshold decreases as more votes are cast, so that a higher turnout increases the likelihood of a referendum passing. With a negative turnout bias , the passing threshold increases as more votes are cast. Negative turnout bias is also sometimes called a \"default carries\" position because if there's an apathetic voting body, the referendum passes by default. A neutral turnout bias specifies a simple majority passing threshold. aggregation Used in the context of FRAME , aggregation or pallet aggregation is the process of combining analogous types from multiple runtime modules into a single type. Pallet aggregation allows each module's analogous types to be represented. The call containing the aggregated types is sometimes referred to as an outer call or a call to an outer object . Currently, there are six data types that can be aggregated: Call for published functions that can be called with a set of arguments. Error for messages that indicate why a function invocation ( Call ) failed. Event for pallet-emitted events that describe state changes. Log for extensible header items. Metadata for information that allows inspection of the above. Origin for the source of a function invocation ( Call ). approval voting Voting system where voters can vote for as many candidates as desired. The candidate with the highest overall number of votes wins. With approval voting, it is worth noting the following: Voting for all candidates is the same as voting for none. It is possible to vote against a single candidate by voting for all other candidates. Approval voting is used by the FRAME Elections Phragmen pallet as a governing Council on a number of Substrate-based chains. author Describes the node that is responsible for the creation of a block . Block authors are also referred to as block producers . In a proof-of-work blockchain, these nodes are called miners . authority The nodes that act as a collective to manage consensus on a blockchain network. In a proof-of-stake blockchain\u2014for example, a blockchain that us the Staking pallet from FRAME \u2014authorities are determined through a token-weighted nomination and voting system. The terms authorities and validators sometimes seem to refer the same thing. However, validators is a broader term that can include other aspects of chain maintenance such as parachain validation. In general, authorities are a (non-strict) subset of validators and many validators are authorities. authority round (Aura) Deterministic consensus protocol where block production is limited to a rotating list of authorities that take turns creating blocks. With authority round (Aura) consensus, the majority of online authorities are assumed to be honest. Learn more by reading the official wiki article for the Aura consensus algorithm. The Aura protocol is often used in combination with GRANDPA as a hybrid consensus protocol where Aura is used for block production and short-term probabilistic finality , with deterministic finality provided by GRANDPA . blind assignment of blockchain extension (BABE) A block authoring protocol similar to Aura . However, with the blind assignment of blockchain extension (BABE) protocol, authorities win slots based on a verifiable random function (VRF) as opposed to the round-robin selection method. The winning authority can select a chain and submit a new block for it. Learn more about BABE by referring to its official Web3 Foundation research document . block Describes a single element of a blockchain that cryptographically binds a set of extrinsic data\u2014the body\u2014to a header . Blocks are arranged into a tree through parent pointers. The pointer to a parent block is a hash of the parent and the tree is pruned into a list using a fork-choice rule and an optional finality mechanism. blockchain Describes a distributed network of computers that uses cryptography to allow a group of participants to trustlessly come to consensus on the state of a system as it evolves over time The computers that compose the blockchain network are called nodes . byzantine fault tolerance (BFT) Defines the ability of a distributed computer network to remain operational if a certain proportion of its nodes or authorities are defective or behaving maliciously. Typically, a distributed network is considered byzantine fault tolerant if it can remain functional with up to one-third of nodes assumed to defective, offline, actively malicious, and acting as part of a coordinated attack. byzantine failure The loss of a network service due to node failures that exceed the proprortion of nodes required to reach consensus. practical byzantine fault tolerance (pBFT) An early approach to byzantine fault tolerance. pBFT systems tolerate byzantine behavior from up to one-third of participants. The communication overhead for such systems is O(n\u00b2) , where n is the number of nodes (participants) in the system. consensus In the context of a blockchain , consensus is the process nodes use to agree on the canonical fork of a chain. Consensus is comprised of authorship , finality , and fork-choice rule . In the Substrate ecosystem, these three components are separated from one another, and the term consensus often refers specifically to authorship. In the context of a Substrate node , the term consensus engine describes the node subsystem that is responsible for consensus tasks. See also hybrid consensus . consensus algorithm An algorithm that ensures that a set of actors \u2014who don't necessarily trust each other\u2014can reach agreement about state as the result of some computation. Because most consensus algorithms assume that up to one-third of the actors or nodes can are byzantine fault tolerant . Consensus algorithms are generately concerned with ensuring two properties: safety indicating that all honest nodes eventually agreed on the state of the chain. liveness \" indicating the ability for the chain to keep making progress. For detailed information about the consensus strategies of the Polkadot network , see the Polkadot Consensus blog series. See also hybrid consensus . cryptographic primitives A general term used to describe fundamental cryptographic concepts such as signature schemes and hashing algorithms. Cryptographic primitives are essential to many aspects of the Substrate ecosystem. For example: Hashing algorithms produce blocks of hashed data and each block uses the hash generated by the hashing algorithm to reference its parent block. Hashing is used to encode state as a trie data structure to facilitate efficient verification. Digital signature schemes are used to secure different consensus models such as authorities . Cryptographic schemes identify and authenticate the accounts used to perform transactions in the Substrate runtime. council Most often used to refer to an instance of the Collective pallet on Substrate-based networks such as Kusama or Polkadot if the Collective pallet is part of the FRAME -based runtime for the network. A council primarily serves to optimize and balance the more inclusive referendum system. database backend The means by which the state of a blockchain network is persisted between invocations of the blockchain node application. For information about how the database backend is implemented and used by Substrate-based chains, see Advanced storage . dev phrase A mnemonic phrase that is intentionally made public. All of the well-known development accounts (Alice, Bob, Charlie, Dave, Eve, and Ferdie) are generated from the same dev phrase. The dev phrase is: bottom drive obey lake curtain smoke basket hold race lonely fit walk Many tools in the Substrate ecosystem, such as subkey , allow users to implicitly specify the dev phrase by only specifying a derivation path such as //Alice . digest An extensible field of the block header that encodes information needed by several actors in a blockchain network including: Light clients for chain synchronization. Consensus engines for block verification. The runtime itself in the case of pre-runtime digests. dispatch The execution of a function with a predefined set of arguments. In the context of runtime development with FRAME , a dispatch takes pure data\u2014the type is known as Call by convention\u2014and uses that data to call a published function in a runtime module ( pallet ) with predefined arguments. The published functions take one additional parameter, known as origin , that allows the function to securely determine the provenance of its execution. equivocating A type of erroneous or malicious behavior that involves backing multiple mutually-exclusive options within the consensus mechanism. ethash A function used by some proof-of-work consensus systems, such as the Ethereum blockchain. It was developed by a team led by Tim Hughes . events A means of recording, for the benefit of the off-chain world, that some particular state transition happened. In the context of FRAME , events are a composable data types that each pallet can individually define. Events in FRAME are implemented as a set of transient storage items that are inspected immediately after a block has executed and reset during block-initialization. executor A means of executing a function call in a given runtime with a set of dependencies. There are two executor implementations present in Substrate, WebAssembly and native . The native executor uses a natively compiled runtime embedded in the node to execute calls. This is a performance optimization that up-to-date nodes can take advantage of. The WebAssembly executor uses a Wasm binary and a Wasm interpreter to execute calls. The binary is guaranteed to be up-to-date regardless of the version of the blockchain node because it is persisted in the state of the Substrate-based chain. extrinsic Data that is external to the blockchain and included in a block . In general, there are two types of extrinsics: signed or unsigned transactions. inherents inserted by block authors . existential deposit The minimum balance an account is allowed to have in the Balances pallet . Accounts cannot be created with a balance less than the existential deposit amount. If an account balance drops below this amount, the Balances pallet uses a FRAME System API to drop its references to that account. If all of the references to an account are dropped, the account can be reaped . finality The part of consensus that makes the ongoing progress of the blockchain irreversible. After a block is finalized, all of the state changes it encapsulates are irreversible without a hard fork. The consensus algorithm must guarantee that finalized blocks never need reverting. However, different consensus algorithms can define different finalization methods. In a consensus protocol that uses deterministic finality , each block is guaranteed to be the canonical block for that chain when the block is included. Deterministic finality is desirable in situations where the full chain is not available, such as in the case of light clients . GRANDPA is the deterministic finality protocol that is used by the Polkadot Network . In a consensus protocol that uses probabilistic finality , finality is expressed in terms of a probability, denoted by p , that a proposed block, denoted by B , will remain in the canonical chain. As more blocks are produced on top of B , p approaches 1. In a consensus protocol that uses instant finality , finality is guaranteed immediately upon block production. This type of non-probabilistic consensus tends to use practical byzantine fault tolerance (pBFT) and have expensive communication requirements. fork Indicates that there are divergent paths a blockchain might take. If two or more blocks have the same parent but different state, the blockchain cannot continue to progress until the differences are resolved . An unresolved fork would split the blockchain into two separate chains. By resolving divergent forks, you can ensure that only one canonical chain exists. Flaming Fir A Substrate-based blockchain test network that exists for developing and testing the Substrate blockchain development framework. For more information about accessing Substrate networks and flaming fir, see the Polkadot wiki . FRAME An acronym for the Framework for Runtime Aggregation of Modularized Entities that enables developers to create blockchain runtime environments from a modular set of components called pallets . Runtime developers interact with FRAME using macros such as the following: #[pallet::event] , #[pallet::error] , #[pallet::storage] , #[frame_support::pallet] The macros make it easy to define custom pallets and compose pallets to create a working runtime using the construct_runtime! macro to deploy a Substrate-based blockchain. The convention used in the Substrate codebase is to preface core FRAME modules with frame_ and the optional pallets with pallet_* . For example, the preceding macros are all defined in the frame_support module and all FRAME-based runtimes must include the frame_system module. After the frame_support::construct_runtime macro has been used to create a runtime that includes the frame_system module, optional pallets such as the Balances pallet can be used to extend the core capabilities of the runtime. full client A node that is able to synchronize a blockchain in a secure manner through execution and verification of all logic. Full clients stand in contrast to light clients . genesis configuration A mechanism for specifying the initial state of a blockchain . By convention, this initial state or first block is commonly referred to as the genesis state or genesis block. The genesis configuration for Substrate-based chains is accomplished by way of a chain specification file. The chain specification file makes it easy to use a single Substrate codebase as the foundation for multiple independently-configured chains. GRANDPA A deterministic finality mechanism for blockchains that is implemented in the Rust programming language. The formal specification is maintained by the Web3 Foundation . header The structure that aggregates the information used to summarize a block . A header consists primarily of cryptographic information that is used by light-clients to get a minimally-secure but very efficient synchronization of the chain. hybrid consensus A blockchain consensus protocol that consists of independent or loosely-coupled mechanisms for block production and finality . Hybrid consensus allows the chain to grow as fast as probabilistic consensus protocols, such as Aura , while maintaining the same level of security as deterministic finality consensus protocols, such as GRANDPA . In general, block production algorithms tend to be faster than finality mechanisms. Making block production separate from block finalization gives Substrate developers greater control of their chain's performance. JSON-RPC A stateless, lightweight remote procedure call protocol that is encoded in JSON. JSON-RPC provides a standard way to call functions on a remote system by using JavaScript Object Notation. For Substrate, this protocol is implemented thrinough the Parity JSON-RPC crate. keystore A subsystem in Substrate for managing keys for the purpose of producing new blocks. Kusama Kusama is a Substrate-based blockchain that implements a design similar to the Polkadot network . Kusama is a canary network and is referred to as Polkadot's \"wild cousin\" . As a canary network, Kusama is expected to be more stable than a test network like Westend , but not as stable as a production network like Polkadot . As a canary network, Kusama is controlled by its network participants is intended to be stable enough to encourage meaningful experimentation. libp2p A peer-to-peer networking stack that allows use of many transport mechanisms, including WebSockets (usable in a web browser). Substrate uses the Rust implementation of the libp2p networking stack. light client A type of blockchain node that does not store the chain state or produce blocks. A light client is capable of verifying cryptographic primitives and exposes a remote procedure call (RPC) server that allows blockchain users to interact with the blockchain network. macro A programming language feature that enables developers to write a sequence of instructions that can be named and executed together. The FRAME development environment provides several macros for Rust that you can use to compose a runtime . metadata Data that provides information about one or more aspects of a system. The metadata that exposes information about a Substrate blockchain enables you to interact with that system. node A running instance of a blockchain client. Each node is part of the peer-to-peer network that allows blockchain participants to interact with one another. Substrate nodes can fill a number of roles in a blockchain network. For example, the nodes that produce blocks fulfill the validator role for the blockchain. Nodes that run light-clients facilitate scalable interactions in resource-constrained environments like user interfaces or embedded devices. nominated proof-of-stake (NPoS) A method for determining validators or authorities based on a willingness to commit their stake to the proper functioning of one or more block producing nodes. origin A FRAME primitive that identifies the source of a dispatched function call into the runtime . The FRAME system module defines three built-in origins . As a pallet developer, you can also define custom origins, such as those defined by the Collective pallet . pallet A module that can be used to extend the capabilities of a FRAME -based runtime . Pallets bundle domain-specific logic with runtime primitives like events , and storage items . parachain A parachain is a blockchain that derives shared infrastructure and security from a relay chain . You can learn more about parachains on the Polkadot Wiki . Polkadot network The Polkadot network is a blockchain that serves as the central hub of a heterogeneous blockchain network. It serves the role of the relay chain and supports other chains\u2014the parachains \u2014by providing shared infrastructure and security. proof-of-finality Data that can be used to prove that a particular block is finalized. proof-of-work A consensus mechanism that deters attacks by requiring work on the part of network participants. For example, some proof-of-work systems require participants to use the Ethash function to calculate a hash as a proof of completed work. relay chain The central hub in a heterogenous network of multiple blockchains. Relay chains are blockchains that provide shared infrastructure and security to the other blockchains\u2014the parachains \u2014in the network. In addition to providing consensus capabilities, relay chains also allow parachains to communicate and exchange digital assets without needing to trust one another. remote procedure call (RPC) A mechanism for interacting with a computer program. Remote procedure calls enable developers to query the remote computer programs or invoke program logic with parameters they supply. Substrate nodes expose an RPC server on HTTP and WebSocket endpoints. rhododendron An instant finality , byzantine fault tolerant (BFT) consensus algorithm. One of a number of adaptions of pBFT for blockchains. Refer to its implementation on GitHub . rococo A parachain test network for the Polkadot network. The Rococco network is a Substrate-based blockchain that is an evolving testbed for the capabilities of heterogeneous blockchain networks. runtime The block execution logic of a blockchain. The runtime provides the state transition function for a node. In Substrate, the runtime is stored as a WebAssembly binary in the chain state . slot A fixed, equal interval of time used by consensus engines such as Aura and BABE . In each slot, a subset of authorities is permitted\u2014or obliged\u2014to author a block . stake-weighted voting A democratic voting system that uses a one-vote-per-token method for tallying votes rather than a one-vote-per-head method. state Cryptographically-secure data that persists between blocks and can be used to create new blocks as part of the state transition function. In Substrate-based blockchains, state is stored in a trie data structure that supports the efficient creation of incremental digests. This trie is exposed to the runtime as a simple key/value map where both keys and values can be arbitrary byte arrays. state transition function (STF) The logic of a blockchain that determines how the state changes when a block is processed. In Substrate, the state transition function is effectively equivalent to the runtime . storage item FRAME primitives that provide type-safe data persistence capabilities to the runtime . Learn more about storage items in this article about runtime storage . Substrate A flexible framework for building modular, efficient, and upgradeable blockchains . Substrate is written in the Rust programming language and is maintained by Parity Technologies . transaction A type of extrinsic that can be safely gossiped between nodes on the network because it can be verified through signatures or signed extensions . transaction era A definable period\u2014expressed as a range of block numbers\u2014during which a transaction can be included in a block. Transaction eras are used to protect against transaction replay attacks in the event that an account is reaped and its replay-protecting nonce is reset to zero. transaction pool A collection of transactions that are not yet included in blocks but have been determined to be valid. A tagged transaction pool is a transaction pool implementation that allows the runtime to specify whether a given transaction is valid, how it should be prioritized, and how it relates to other transactions in the pool in terms of dependency and mutual-exclusivity. The tagged transaction pool implementation is designed to be extensible and general enough to express both unspent transaction output (UTXO) and account-based transaction models. trie (Patricia Merkle Tree) A data structure that is used to represent sets of key-value pairs. The Patricia Merkle trie data structure enables the items in the data set to be stores and retrieved using a cryptographic hash. Because incremental changes to the data set result in a new hash, retireving data is efficient even if the data set is very large. With this data structure, you can also prove whether the data set includes any particlar key-value pair without the access to the entire data set. validator A semi-trusted\u2014or untrusted but well-incentivized\u2014actor that helps maintain a blockchain network. In Substrate, validators broadly correspond to the authorities running the consensus system. In Polkadot , validators also manage other duties such as guaranteeing data availability and validating parachain candidate blocks . WebAssembly (Wasm) An execution architecture that allows for the efficient, platform-neutral expression of deterministic, machine-executable logic. WebAssembly can be compiled from many languages, including the Rust programming language. Substrate-based chains use a WebAssembly binary to provide portable runtimes that can be included as part of the chain's state . Westend Westend is a Parity -maintained, Substrate-based blockchain that serves as a test network for the Polkadot network .","title":"Glossary"},{"location":"reference/glossary/#adaptive-quorum-biasing-aqb","text":"Provides a mechanism for adjusting the passing threshold for a referendum based on voter turnout. Adaptive quorum biasing allows for more flexible governance by removing the requirement to have an arbitrary quorum for voting purposes, which create undesirable governance mechanics. Adaptive quorum biasing is implemented in the Democracy pallet . The Democracy pallet provides the interfaces for on-chain bodies such as a collective or individual token holder\u2014to call referenda with positive, negative, or neutral biases. With a positive turnout bias , the passing threshold decreases as more votes are cast, so that a higher turnout increases the likelihood of a referendum passing. With a negative turnout bias , the passing threshold increases as more votes are cast. Negative turnout bias is also sometimes called a \"default carries\" position because if there's an apathetic voting body, the referendum passes by default. A neutral turnout bias specifies a simple majority passing threshold.","title":"adaptive quorum biasing (AQB)"},{"location":"reference/glossary/#aggregation","text":"Used in the context of FRAME , aggregation or pallet aggregation is the process of combining analogous types from multiple runtime modules into a single type. Pallet aggregation allows each module's analogous types to be represented. The call containing the aggregated types is sometimes referred to as an outer call or a call to an outer object . Currently, there are six data types that can be aggregated: Call for published functions that can be called with a set of arguments. Error for messages that indicate why a function invocation ( Call ) failed. Event for pallet-emitted events that describe state changes. Log for extensible header items. Metadata for information that allows inspection of the above. Origin for the source of a function invocation ( Call ).","title":"aggregation"},{"location":"reference/glossary/#approval-voting","text":"Voting system where voters can vote for as many candidates as desired. The candidate with the highest overall number of votes wins. With approval voting, it is worth noting the following: Voting for all candidates is the same as voting for none. It is possible to vote against a single candidate by voting for all other candidates. Approval voting is used by the FRAME Elections Phragmen pallet as a governing Council on a number of Substrate-based chains.","title":"approval voting"},{"location":"reference/glossary/#author","text":"Describes the node that is responsible for the creation of a block . Block authors are also referred to as block producers . In a proof-of-work blockchain, these nodes are called miners .","title":"author"},{"location":"reference/glossary/#authority","text":"The nodes that act as a collective to manage consensus on a blockchain network. In a proof-of-stake blockchain\u2014for example, a blockchain that us the Staking pallet from FRAME \u2014authorities are determined through a token-weighted nomination and voting system. The terms authorities and validators sometimes seem to refer the same thing. However, validators is a broader term that can include other aspects of chain maintenance such as parachain validation. In general, authorities are a (non-strict) subset of validators and many validators are authorities.","title":"authority"},{"location":"reference/glossary/#authority-round-aura","text":"Deterministic consensus protocol where block production is limited to a rotating list of authorities that take turns creating blocks. With authority round (Aura) consensus, the majority of online authorities are assumed to be honest. Learn more by reading the official wiki article for the Aura consensus algorithm. The Aura protocol is often used in combination with GRANDPA as a hybrid consensus protocol where Aura is used for block production and short-term probabilistic finality , with deterministic finality provided by GRANDPA .","title":"authority round (Aura)"},{"location":"reference/glossary/#blind-assignment-of-blockchain-extension-babe","text":"A block authoring protocol similar to Aura . However, with the blind assignment of blockchain extension (BABE) protocol, authorities win slots based on a verifiable random function (VRF) as opposed to the round-robin selection method. The winning authority can select a chain and submit a new block for it. Learn more about BABE by referring to its official Web3 Foundation research document .","title":"blind assignment of blockchain extension (BABE)"},{"location":"reference/glossary/#block","text":"Describes a single element of a blockchain that cryptographically binds a set of extrinsic data\u2014the body\u2014to a header . Blocks are arranged into a tree through parent pointers. The pointer to a parent block is a hash of the parent and the tree is pruned into a list using a fork-choice rule and an optional finality mechanism.","title":"block"},{"location":"reference/glossary/#blockchain","text":"Describes a distributed network of computers that uses cryptography to allow a group of participants to trustlessly come to consensus on the state of a system as it evolves over time The computers that compose the blockchain network are called nodes .","title":"blockchain"},{"location":"reference/glossary/#byzantine-fault-tolerance-bft","text":"Defines the ability of a distributed computer network to remain operational if a certain proportion of its nodes or authorities are defective or behaving maliciously. Typically, a distributed network is considered byzantine fault tolerant if it can remain functional with up to one-third of nodes assumed to defective, offline, actively malicious, and acting as part of a coordinated attack.","title":"byzantine fault tolerance (BFT)"},{"location":"reference/glossary/#byzantine-failure","text":"The loss of a network service due to node failures that exceed the proprortion of nodes required to reach consensus.","title":"byzantine failure"},{"location":"reference/glossary/#practical-byzantine-fault-tolerance-pbft","text":"An early approach to byzantine fault tolerance. pBFT systems tolerate byzantine behavior from up to one-third of participants. The communication overhead for such systems is O(n\u00b2) , where n is the number of nodes (participants) in the system.","title":"practical byzantine fault tolerance (pBFT)"},{"location":"reference/glossary/#consensus","text":"In the context of a blockchain , consensus is the process nodes use to agree on the canonical fork of a chain. Consensus is comprised of authorship , finality , and fork-choice rule . In the Substrate ecosystem, these three components are separated from one another, and the term consensus often refers specifically to authorship. In the context of a Substrate node , the term consensus engine describes the node subsystem that is responsible for consensus tasks. See also hybrid consensus .","title":"consensus"},{"location":"reference/glossary/#consensus-algorithm","text":"An algorithm that ensures that a set of actors \u2014who don't necessarily trust each other\u2014can reach agreement about state as the result of some computation. Because most consensus algorithms assume that up to one-third of the actors or nodes can are byzantine fault tolerant . Consensus algorithms are generately concerned with ensuring two properties: safety indicating that all honest nodes eventually agreed on the state of the chain. liveness \" indicating the ability for the chain to keep making progress. For detailed information about the consensus strategies of the Polkadot network , see the Polkadot Consensus blog series. See also hybrid consensus .","title":"consensus algorithm"},{"location":"reference/glossary/#cryptographic-primitives","text":"A general term used to describe fundamental cryptographic concepts such as signature schemes and hashing algorithms. Cryptographic primitives are essential to many aspects of the Substrate ecosystem. For example: Hashing algorithms produce blocks of hashed data and each block uses the hash generated by the hashing algorithm to reference its parent block. Hashing is used to encode state as a trie data structure to facilitate efficient verification. Digital signature schemes are used to secure different consensus models such as authorities . Cryptographic schemes identify and authenticate the accounts used to perform transactions in the Substrate runtime.","title":"cryptographic primitives"},{"location":"reference/glossary/#council","text":"Most often used to refer to an instance of the Collective pallet on Substrate-based networks such as Kusama or Polkadot if the Collective pallet is part of the FRAME -based runtime for the network. A council primarily serves to optimize and balance the more inclusive referendum system.","title":"council"},{"location":"reference/glossary/#database-backend","text":"The means by which the state of a blockchain network is persisted between invocations of the blockchain node application. For information about how the database backend is implemented and used by Substrate-based chains, see Advanced storage .","title":"database backend"},{"location":"reference/glossary/#dev-phrase","text":"A mnemonic phrase that is intentionally made public. All of the well-known development accounts (Alice, Bob, Charlie, Dave, Eve, and Ferdie) are generated from the same dev phrase. The dev phrase is: bottom drive obey lake curtain smoke basket hold race lonely fit walk Many tools in the Substrate ecosystem, such as subkey , allow users to implicitly specify the dev phrase by only specifying a derivation path such as //Alice .","title":"dev phrase"},{"location":"reference/glossary/#digest","text":"An extensible field of the block header that encodes information needed by several actors in a blockchain network including: Light clients for chain synchronization. Consensus engines for block verification. The runtime itself in the case of pre-runtime digests.","title":"digest"},{"location":"reference/glossary/#dispatch","text":"The execution of a function with a predefined set of arguments. In the context of runtime development with FRAME , a dispatch takes pure data\u2014the type is known as Call by convention\u2014and uses that data to call a published function in a runtime module ( pallet ) with predefined arguments. The published functions take one additional parameter, known as origin , that allows the function to securely determine the provenance of its execution.","title":"dispatch"},{"location":"reference/glossary/#equivocating","text":"A type of erroneous or malicious behavior that involves backing multiple mutually-exclusive options within the consensus mechanism.","title":"equivocating"},{"location":"reference/glossary/#ethash","text":"A function used by some proof-of-work consensus systems, such as the Ethereum blockchain. It was developed by a team led by Tim Hughes .","title":"ethash"},{"location":"reference/glossary/#events","text":"A means of recording, for the benefit of the off-chain world, that some particular state transition happened. In the context of FRAME , events are a composable data types that each pallet can individually define. Events in FRAME are implemented as a set of transient storage items that are inspected immediately after a block has executed and reset during block-initialization.","title":"events"},{"location":"reference/glossary/#executor","text":"A means of executing a function call in a given runtime with a set of dependencies. There are two executor implementations present in Substrate, WebAssembly and native . The native executor uses a natively compiled runtime embedded in the node to execute calls. This is a performance optimization that up-to-date nodes can take advantage of. The WebAssembly executor uses a Wasm binary and a Wasm interpreter to execute calls. The binary is guaranteed to be up-to-date regardless of the version of the blockchain node because it is persisted in the state of the Substrate-based chain.","title":"executor"},{"location":"reference/glossary/#extrinsic","text":"Data that is external to the blockchain and included in a block . In general, there are two types of extrinsics: signed or unsigned transactions. inherents inserted by block authors .","title":"extrinsic"},{"location":"reference/glossary/#existential-deposit","text":"The minimum balance an account is allowed to have in the Balances pallet . Accounts cannot be created with a balance less than the existential deposit amount. If an account balance drops below this amount, the Balances pallet uses a FRAME System API to drop its references to that account. If all of the references to an account are dropped, the account can be reaped .","title":"existential deposit"},{"location":"reference/glossary/#finality","text":"The part of consensus that makes the ongoing progress of the blockchain irreversible. After a block is finalized, all of the state changes it encapsulates are irreversible without a hard fork. The consensus algorithm must guarantee that finalized blocks never need reverting. However, different consensus algorithms can define different finalization methods. In a consensus protocol that uses deterministic finality , each block is guaranteed to be the canonical block for that chain when the block is included. Deterministic finality is desirable in situations where the full chain is not available, such as in the case of light clients . GRANDPA is the deterministic finality protocol that is used by the Polkadot Network . In a consensus protocol that uses probabilistic finality , finality is expressed in terms of a probability, denoted by p , that a proposed block, denoted by B , will remain in the canonical chain. As more blocks are produced on top of B , p approaches 1. In a consensus protocol that uses instant finality , finality is guaranteed immediately upon block production. This type of non-probabilistic consensus tends to use practical byzantine fault tolerance (pBFT) and have expensive communication requirements.","title":"finality"},{"location":"reference/glossary/#fork","text":"Indicates that there are divergent paths a blockchain might take. If two or more blocks have the same parent but different state, the blockchain cannot continue to progress until the differences are resolved . An unresolved fork would split the blockchain into two separate chains. By resolving divergent forks, you can ensure that only one canonical chain exists.","title":"fork"},{"location":"reference/glossary/#flaming-fir","text":"A Substrate-based blockchain test network that exists for developing and testing the Substrate blockchain development framework. For more information about accessing Substrate networks and flaming fir, see the Polkadot wiki .","title":"Flaming Fir"},{"location":"reference/glossary/#frame","text":"An acronym for the Framework for Runtime Aggregation of Modularized Entities that enables developers to create blockchain runtime environments from a modular set of components called pallets . Runtime developers interact with FRAME using macros such as the following: #[pallet::event] , #[pallet::error] , #[pallet::storage] , #[frame_support::pallet] The macros make it easy to define custom pallets and compose pallets to create a working runtime using the construct_runtime! macro to deploy a Substrate-based blockchain. The convention used in the Substrate codebase is to preface core FRAME modules with frame_ and the optional pallets with pallet_* . For example, the preceding macros are all defined in the frame_support module and all FRAME-based runtimes must include the frame_system module. After the frame_support::construct_runtime macro has been used to create a runtime that includes the frame_system module, optional pallets such as the Balances pallet can be used to extend the core capabilities of the runtime.","title":"FRAME"},{"location":"reference/glossary/#full-client","text":"A node that is able to synchronize a blockchain in a secure manner through execution and verification of all logic. Full clients stand in contrast to light clients .","title":"full client"},{"location":"reference/glossary/#genesis-configuration","text":"A mechanism for specifying the initial state of a blockchain . By convention, this initial state or first block is commonly referred to as the genesis state or genesis block. The genesis configuration for Substrate-based chains is accomplished by way of a chain specification file. The chain specification file makes it easy to use a single Substrate codebase as the foundation for multiple independently-configured chains.","title":"genesis configuration"},{"location":"reference/glossary/#grandpa","text":"A deterministic finality mechanism for blockchains that is implemented in the Rust programming language. The formal specification is maintained by the Web3 Foundation .","title":"GRANDPA"},{"location":"reference/glossary/#header","text":"The structure that aggregates the information used to summarize a block . A header consists primarily of cryptographic information that is used by light-clients to get a minimally-secure but very efficient synchronization of the chain.","title":"header"},{"location":"reference/glossary/#hybrid-consensus","text":"A blockchain consensus protocol that consists of independent or loosely-coupled mechanisms for block production and finality . Hybrid consensus allows the chain to grow as fast as probabilistic consensus protocols, such as Aura , while maintaining the same level of security as deterministic finality consensus protocols, such as GRANDPA . In general, block production algorithms tend to be faster than finality mechanisms. Making block production separate from block finalization gives Substrate developers greater control of their chain's performance.","title":"hybrid consensus"},{"location":"reference/glossary/#json-rpc","text":"A stateless, lightweight remote procedure call protocol that is encoded in JSON. JSON-RPC provides a standard way to call functions on a remote system by using JavaScript Object Notation. For Substrate, this protocol is implemented thrinough the Parity JSON-RPC crate.","title":"JSON-RPC"},{"location":"reference/glossary/#keystore","text":"A subsystem in Substrate for managing keys for the purpose of producing new blocks.","title":"keystore"},{"location":"reference/glossary/#kusama","text":"Kusama is a Substrate-based blockchain that implements a design similar to the Polkadot network . Kusama is a canary network and is referred to as Polkadot's \"wild cousin\" . As a canary network, Kusama is expected to be more stable than a test network like Westend , but not as stable as a production network like Polkadot . As a canary network, Kusama is controlled by its network participants is intended to be stable enough to encourage meaningful experimentation.","title":"Kusama"},{"location":"reference/glossary/#libp2p","text":"A peer-to-peer networking stack that allows use of many transport mechanisms, including WebSockets (usable in a web browser). Substrate uses the Rust implementation of the libp2p networking stack.","title":"libp2p"},{"location":"reference/glossary/#light-client","text":"A type of blockchain node that does not store the chain state or produce blocks. A light client is capable of verifying cryptographic primitives and exposes a remote procedure call (RPC) server that allows blockchain users to interact with the blockchain network.","title":"light client"},{"location":"reference/glossary/#macro","text":"A programming language feature that enables developers to write a sequence of instructions that can be named and executed together. The FRAME development environment provides several macros for Rust that you can use to compose a runtime .","title":"macro"},{"location":"reference/glossary/#metadata","text":"Data that provides information about one or more aspects of a system. The metadata that exposes information about a Substrate blockchain enables you to interact with that system.","title":"metadata"},{"location":"reference/glossary/#node","text":"A running instance of a blockchain client. Each node is part of the peer-to-peer network that allows blockchain participants to interact with one another. Substrate nodes can fill a number of roles in a blockchain network. For example, the nodes that produce blocks fulfill the validator role for the blockchain. Nodes that run light-clients facilitate scalable interactions in resource-constrained environments like user interfaces or embedded devices.","title":"node"},{"location":"reference/glossary/#nominated-proof-of-stake-npos","text":"A method for determining validators or authorities based on a willingness to commit their stake to the proper functioning of one or more block producing nodes.","title":"nominated proof-of-stake (NPoS)"},{"location":"reference/glossary/#origin","text":"A FRAME primitive that identifies the source of a dispatched function call into the runtime . The FRAME system module defines three built-in origins . As a pallet developer, you can also define custom origins, such as those defined by the Collective pallet .","title":"origin"},{"location":"reference/glossary/#pallet","text":"A module that can be used to extend the capabilities of a FRAME -based runtime . Pallets bundle domain-specific logic with runtime primitives like events , and storage items .","title":"pallet"},{"location":"reference/glossary/#parachain","text":"A parachain is a blockchain that derives shared infrastructure and security from a relay chain . You can learn more about parachains on the Polkadot Wiki .","title":"parachain"},{"location":"reference/glossary/#polkadot-network","text":"The Polkadot network is a blockchain that serves as the central hub of a heterogeneous blockchain network. It serves the role of the relay chain and supports other chains\u2014the parachains \u2014by providing shared infrastructure and security.","title":"Polkadot network"},{"location":"reference/glossary/#proof-of-finality","text":"Data that can be used to prove that a particular block is finalized.","title":"proof-of-finality"},{"location":"reference/glossary/#proof-of-work","text":"A consensus mechanism that deters attacks by requiring work on the part of network participants. For example, some proof-of-work systems require participants to use the Ethash function to calculate a hash as a proof of completed work.","title":"proof-of-work"},{"location":"reference/glossary/#relay-chain","text":"The central hub in a heterogenous network of multiple blockchains. Relay chains are blockchains that provide shared infrastructure and security to the other blockchains\u2014the parachains \u2014in the network. In addition to providing consensus capabilities, relay chains also allow parachains to communicate and exchange digital assets without needing to trust one another.","title":"relay chain"},{"location":"reference/glossary/#remote-procedure-call-rpc","text":"A mechanism for interacting with a computer program. Remote procedure calls enable developers to query the remote computer programs or invoke program logic with parameters they supply. Substrate nodes expose an RPC server on HTTP and WebSocket endpoints.","title":"remote procedure call (RPC)"},{"location":"reference/glossary/#rhododendron","text":"An instant finality , byzantine fault tolerant (BFT) consensus algorithm. One of a number of adaptions of pBFT for blockchains. Refer to its implementation on GitHub .","title":"rhododendron"},{"location":"reference/glossary/#rococo","text":"A parachain test network for the Polkadot network. The Rococco network is a Substrate-based blockchain that is an evolving testbed for the capabilities of heterogeneous blockchain networks.","title":"rococo"},{"location":"reference/glossary/#runtime","text":"The block execution logic of a blockchain. The runtime provides the state transition function for a node. In Substrate, the runtime is stored as a WebAssembly binary in the chain state .","title":"runtime"},{"location":"reference/glossary/#slot","text":"A fixed, equal interval of time used by consensus engines such as Aura and BABE . In each slot, a subset of authorities is permitted\u2014or obliged\u2014to author a block .","title":"slot"},{"location":"reference/glossary/#stake-weighted-voting","text":"A democratic voting system that uses a one-vote-per-token method for tallying votes rather than a one-vote-per-head method.","title":"stake-weighted voting"},{"location":"reference/glossary/#state","text":"Cryptographically-secure data that persists between blocks and can be used to create new blocks as part of the state transition function. In Substrate-based blockchains, state is stored in a trie data structure that supports the efficient creation of incremental digests. This trie is exposed to the runtime as a simple key/value map where both keys and values can be arbitrary byte arrays.","title":"state"},{"location":"reference/glossary/#state-transition-function-stf","text":"The logic of a blockchain that determines how the state changes when a block is processed. In Substrate, the state transition function is effectively equivalent to the runtime .","title":"state transition function (STF)"},{"location":"reference/glossary/#storage-item","text":"FRAME primitives that provide type-safe data persistence capabilities to the runtime . Learn more about storage items in this article about runtime storage .","title":"storage item"},{"location":"reference/glossary/#substrate","text":"A flexible framework for building modular, efficient, and upgradeable blockchains . Substrate is written in the Rust programming language and is maintained by Parity Technologies .","title":"Substrate"},{"location":"reference/glossary/#transaction","text":"A type of extrinsic that can be safely gossiped between nodes on the network because it can be verified through signatures or signed extensions .","title":"transaction"},{"location":"reference/glossary/#transaction-era","text":"A definable period\u2014expressed as a range of block numbers\u2014during which a transaction can be included in a block. Transaction eras are used to protect against transaction replay attacks in the event that an account is reaped and its replay-protecting nonce is reset to zero.","title":"transaction era"},{"location":"reference/glossary/#transaction-pool","text":"A collection of transactions that are not yet included in blocks but have been determined to be valid. A tagged transaction pool is a transaction pool implementation that allows the runtime to specify whether a given transaction is valid, how it should be prioritized, and how it relates to other transactions in the pool in terms of dependency and mutual-exclusivity. The tagged transaction pool implementation is designed to be extensible and general enough to express both unspent transaction output (UTXO) and account-based transaction models.","title":"transaction pool"},{"location":"reference/glossary/#trie-patricia-merkle-tree","text":"A data structure that is used to represent sets of key-value pairs. The Patricia Merkle trie data structure enables the items in the data set to be stores and retrieved using a cryptographic hash. Because incremental changes to the data set result in a new hash, retireving data is efficient even if the data set is very large. With this data structure, you can also prove whether the data set includes any particlar key-value pair without the access to the entire data set.","title":"trie (Patricia Merkle Tree)"},{"location":"reference/glossary/#validator","text":"A semi-trusted\u2014or untrusted but well-incentivized\u2014actor that helps maintain a blockchain network. In Substrate, validators broadly correspond to the authorities running the consensus system. In Polkadot , validators also manage other duties such as guaranteeing data availability and validating parachain candidate blocks .","title":"validator"},{"location":"reference/glossary/#webassembly-wasm","text":"An execution architecture that allows for the efficient, platform-neutral expression of deterministic, machine-executable logic. WebAssembly can be compiled from many languages, including the Rust programming language. Substrate-based chains use a WebAssembly binary to provide portable runtimes that can be included as part of the chain's state .","title":"WebAssembly (Wasm)"},{"location":"reference/glossary/#westend","text":"Westend is a Parity -maintained, Substrate-based blockchain that serves as a test network for the Polkadot network .","title":"Westend"},{"location":"reference/macros/","text":"","title":"Macros"},{"location":"reference/polkadot-js/","text":"Polkadot-JS reference The Polkadot-JS project is a collection of tools, interfaces, and libraries that can be used with any Substrate-based blockchain. Polkadot-JS API `} text={ The API provides application developers the ability to query a node and interact with any Substrate-based blockchain using Javascript. } linkText={ Go to Documentation } link={ https://polkadot.js.org/docs/api`} /> `} text={ The Polkadot-JS API is a library of interfaces for communicating with Polkadot and Substrate nodes. } linkText={ GitHub } link={ https://github.com/polkadot-js/api`} /> Getting started Follow the Getting Started guide to learn how to install and start using the Polkadot-JS API right away. Polkadot-JS Apps `} text={ The Polkadot-JS Apps is a flexible UI for interacting with a Polkadot or Substrate based node.. } linkText={ Go to Documentation } link={ https://polkadot.js.org/apps`} /> `} text={ This is pre-built user-facing application, allowing access to all features available on Substrate chains. } linkText={ GitHub } link={ https://github.com/polkadot-js/apps`} /> Connecting to local node To connect the Polkadot-JS Apps to your local node, you must go into Settings and change the \"endpoint to connect to\" to Local Node (127.0.0.1:9944) . gray } title={ Note } text={ If you are connected to the Polkadot-JS Apps over a secure HTTPS connection, you will need to use a browser which also supports bridging to an insecure WebSocket endpoint. For example, Google Chrome supports this, but Mozilla Firefox does not. } /> Polkadot-JS extension The Polkadot-JS Extension is a simple proof-of-concept for managing accounts in a browser extension and allowing the signing of extrinsics using these accounts. It also provides a simple interface for interacting with extension-compliant dApps. Different ways to use the extension: On Chrome On Firefox Fork on GitHub Next steps Examples Clone the Substrate Front End Template to start building a custom ReactJS app for your blockchain using Polkadot-JS API. Complete part II of the Kitties tutorial to use PolkadotJS API in action References Visit the reference docs for the Polkadot-JS API Visit the reference docs for the Polkadot-JS Common Utilities","title":"Polkadot-JS API"},{"location":"reference/polkadot-js/#polkadot-js-reference","text":"The Polkadot-JS project is a collection of tools, interfaces, and libraries that can be used with any Substrate-based blockchain.","title":"Polkadot-JS reference"},{"location":"reference/polkadot-js/#polkadot-js-api","text":"`} text={ The API provides application developers the ability to query a node and interact with any Substrate-based blockchain using Javascript. } linkText={ Go to Documentation } link={ https://polkadot.js.org/docs/api`} /> `} text={ The Polkadot-JS API is a library of interfaces for communicating with Polkadot and Substrate nodes. } linkText={ GitHub } link={ https://github.com/polkadot-js/api`} />","title":"Polkadot-JS API"},{"location":"reference/polkadot-js/#getting-started","text":"Follow the Getting Started guide to learn how to install and start using the Polkadot-JS API right away.","title":"Getting started"},{"location":"reference/polkadot-js/#polkadot-js-apps","text":"`} text={ The Polkadot-JS Apps is a flexible UI for interacting with a Polkadot or Substrate based node.. } linkText={ Go to Documentation } link={ https://polkadot.js.org/apps`} /> `} text={ This is pre-built user-facing application, allowing access to all features available on Substrate chains. } linkText={ GitHub } link={ https://github.com/polkadot-js/apps`} />","title":"Polkadot-JS Apps"},{"location":"reference/polkadot-js/#connecting-to-local-node","text":"To connect the Polkadot-JS Apps to your local node, you must go into Settings and change the \"endpoint to connect to\" to Local Node (127.0.0.1:9944) . gray } title={ Note } text={ If you are connected to the Polkadot-JS Apps over a secure HTTPS connection, you will need to use a browser which also supports bridging to an insecure WebSocket endpoint. For example, Google Chrome supports this, but Mozilla Firefox does not. } />","title":"Connecting to local node"},{"location":"reference/polkadot-js/#polkadot-js-extension","text":"The Polkadot-JS Extension is a simple proof-of-concept for managing accounts in a browser extension and allowing the signing of extrinsics using these accounts. It also provides a simple interface for interacting with extension-compliant dApps. Different ways to use the extension: On Chrome On Firefox Fork on GitHub","title":"Polkadot-JS extension"},{"location":"reference/polkadot-js/#next-steps","text":"","title":"Next steps"},{"location":"reference/polkadot-js/#examples","text":"Clone the Substrate Front End Template to start building a custom ReactJS app for your blockchain using Polkadot-JS API. Complete part II of the Kitties tutorial to use PolkadotJS API in action","title":"Examples"},{"location":"reference/polkadot-js/#references","text":"Visit the reference docs for the Polkadot-JS API Visit the reference docs for the Polkadot-JS Common Utilities","title":"References"},{"location":"reference/command-line-tools/","text":"Command-line tools This section provides reference information for Substrate command-line tools. Command entry point Description subkey Generate and manage public and private key pairs for accounts. memory-profiler Collect information about memory allocation and the behavior of blockchain applications over time. try-runtime Query a snapshot of runtime storage to retrieve state. srtool Build WASM runtime in a deterministic way, allowing continuous integration pipelines and users to produce a strictly identical WASM runtime. subxt Submit extrinsics to a Substrate node using RPC. tx-wrapper Publish chain specific offline transaction generation libraries. sub-flood Flood a Substrate node with transactions. substrate-archive Index all blocks, state, and extrinsic data from a chain into PostgreSQL database. sidecar Use a REST service to interact with blockchain nodes built using FRAME. polkadot-launch Launch a local Polkadot test network.","title":"Command-line tools"},{"location":"reference/command-line-tools/#command-line-tools","text":"This section provides reference information for Substrate command-line tools. Command entry point Description subkey Generate and manage public and private key pairs for accounts. memory-profiler Collect information about memory allocation and the behavior of blockchain applications over time. try-runtime Query a snapshot of runtime storage to retrieve state. srtool Build WASM runtime in a deterministic way, allowing continuous integration pipelines and users to produce a strictly identical WASM runtime. subxt Submit extrinsics to a Substrate node using RPC. tx-wrapper Publish chain specific offline transaction generation libraries. sub-flood Flood a Substrate node with transactions. substrate-archive Index all blocks, state, and extrinsic data from a chain into PostgreSQL database. sidecar Use a REST service to interact with blockchain nodes built using FRAME. polkadot-launch Launch a local Polkadot test network.","title":"Command-line tools"},{"location":"reference/command-line-tools/archive/","text":"A tool Run alongside a Substrate-backed chain to index all Blocks, State, and Extrinsic data into PostgreSQL. Go to documentation","title":"Archive"},{"location":"reference/command-line-tools/memory-profiler/","text":"memory profiler Memory profiling enables you to understand the memory allocation and behavior of your blockchain applications over time in Substrate-based clients. It identifies method calls in the context of how memory was allocated, combining this information with the number of allocated objects. In addition, profiling can be used to analyze memory leaks, identify where memory consumption is happening, define temporary allocations, and investigate excessive memory fragmentation within applications. The profiler we recommend is koute's memory profiler . Installation From a binary release You can download a precompiled binary release of the profiler from here . The last version we've tested is 0.6.1, but any newer one will also most likely work. Here's how you can download and unpack it from the command-line: $ curl -L https://github.com/koute/memory-profiler/releases/download/0.6.1/memory-profiler-x86_64-unknown-linux-gnu.tgz -o memory-profiler-x86_64-unknown-linux-gnu.tgz $ tar -xf memory-profiler-x86_64-unknown-linux-gnu.tgz This will result in three files being unpacked. We're only interested in two of them: libmemory_profiler.so - this is the memory profiler itself that we will hook into Substrate memory-profiler-cli - this is the program we will later use to analyze the profiling data From source You can also compile the profiler from source yourself. First you need to make sure to have the following installed: GCC toolchain Rust nightly (we've tested version nightly-2021-06-08 ) Yarn package manager (for building the GUI) Then you should be able to build the profiler like this: $ git clone https://github.com/koute/memory-profiler $ cd memory-profiler $ cargo build --release -p memory-profiler $ cargo build --release -p memory-profiler-cli You'll find the binaries we need in target/release/libmemory_profiler.so and target/release/memory-profiler-cli . Hooking up the profiler to Substrate This part heavily depends on how exactly you're launching Substrate. Hooking to a manually launched Substrate If you're manually launching Substrate from the command-line then hooking the profiler up to it boils down to just setting up a few extra environment variables and then launching it normally as you'd usually do. First, we want to enable logging, tell the profiler where it's supposed to output its logs, where it should gather its profiling data, and optionally tell it to cull temporary allocations: $ export MEMORY_PROFILER_LOG=info $ export MEMORY_PROFILER_LOGFILE=profiling_%e_%t.log $ export MEMORY_PROFILER_OUTPUT=profiling_%e_%t.dat # Optional, depending on what exact aspect you'd like to profile # and how long you're going to be profiling. $ export MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS=1 Then we can launch Substrate with the profiler attached: $ LD_PRELOAD=/path/to/libmemory_profiler.so ./target/release/substrate Setting the LD_PRELOAD environment variable will instruct Linux's dynamic linker to inject the memory profiler into Substrate just before it's launched, which allows the profiler to hook into the system's memory allocation routines and track every memory allocation that Substrate's doing. Hooking to Substrate launched through systemd If you're running a Substrate-based node remotely you're probably using systemd to manage it. Here's how you could go about setting up profiling in such a situation. We assume you've already either downloaded a precompiled binary of the profiler or compiled it from source, and you have it in your current directory. First, we want to copy the memory profiler to a globally accessible location and set up a place where it can write its logs and gather the profiling data. $ sudo mkdir -p /opt/memory-profiler/bin $ sudo cp libmemory_profiler.so /opt/memory-profiler/bin/ $ sudo mkdir /opt/memory-profiler/logs $ sudo chmod 0777 /opt/memory-profiler/logs Then we want to set up a file with all of the environment variables to configure the profiler itself: $ echo \"MEMORY_PROFILER_OUTPUT=/opt/memory-profiler/logs/profiling_%e_%t_%p.dat\" | sudo tee /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_LOGFILE=/opt/memory-profiler/logs/profiling_%e_%t_%p.txt\" | sudo tee -a /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_LOG=info\" | sudo tee -a /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS=1\" | sudo tee -a /opt/memory-profiler/env $ echo \"LD_PRELOAD=/opt/memory-profiler/bin/libmemory_profiler.so\" | sudo tee -a /opt/memory-profiler/env Now you want to open your systemd unit file for your node and add the following in the [Service] section: [Service] EnvironmentFile=/opt/memory-profiler/env Do not add another [Service] section if one already exists; just add the EnvironmentFile key to it. If you already have one EnvironmentFile key do not replace it; just add a second one, systemd will apply both. Now you can reload your systemd daemon: $ sudo systemctl daemon-reload And then restart your service to start the profiling: $ sudo systemctl restart kusama The profiling data will be gathered at /opt/memory-profiler/logs . If you want to disable the memory profiler just delete the EnvironmentFile key you've added to your unit file, and restart the service again. Configuring the profiler There are also other environment variables you can set to configure the profiler , although besides the ones we've already shown changing them shouldn't be necessary in normal circumstances. One configuration knob that warrants extra consideration is MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS , which controls whenever the profiler will gather short lived allocations. By default the profiler will gather every allocation that's made by the profiled application. That is a lot of data, and can be on the order of megabytes per second. This is great if you want to only profile for a short period of time, or if you specifically care about diagnosing temporary allocations, but it becomes problematic when you want to leave the profiler running for longer. This is where the MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS option comes in. When you turn it on by setting it to 1 the profiler will omit all of the really short lived allocations and not write them out to disk. This significantly cuts down the amount of data that's generated, usually to the range of kilobytes per second, which makes it possible to leave the profiling running for days at a time. Analysis Now that you've gathered the profiling data you can now analyze it. Assuming you have both the memory-profiler-cli and the .dat file you've gathered in the same directory you can load the GUI for it: $ ./memory-profiler-cli server *.dat This might take a while, depending or your exact hardware and on the amount of data you're trying to load. Eventually you should see something like this being printed out: [2020-05-06T08:59:20Z INFO cli_core::loader] Loaded data in 315s 820 [2020-05-06T08:59:20Z INFO actix_server::builder] Starting 8 workers [2020-05-06T08:59:20Z INFO actix_server::builder] Starting server on 127.0.0.1:8080 Now you can open your web browser and access the GUI at http://localhost:8080/ . There's also a REST API that you can access you'd like to export the data into another format or inspect it programmatically. Miscellaneous tips It's a good idea to always check the logs generated by the profiler and see whenever there are any WRN or ERR logs present. You might see the the following error or warning in the profiler's logs depending on which Linux distribution you're running: The perf_event_open syscall failed for PID 0: Operation not permitted (os error 1)` This is generally harmless; at most this should only result in higher CPU usage when profiling. You can avoid it by doing something like this: bash $ echo \"-1\" | sudo tee /proc/sys/kernel/perf_event_paranoid Although please note that this might have some security implications. Take a look at man perf_event_open for more details. During analysis the whole data file has to be loaded into memory. If you don't have enough RAM and you'll try to load up a big file the analyzer might run out of memory and crash.","title":"memory-profiler"},{"location":"reference/command-line-tools/memory-profiler/#memory-profiler","text":"Memory profiling enables you to understand the memory allocation and behavior of your blockchain applications over time in Substrate-based clients. It identifies method calls in the context of how memory was allocated, combining this information with the number of allocated objects. In addition, profiling can be used to analyze memory leaks, identify where memory consumption is happening, define temporary allocations, and investigate excessive memory fragmentation within applications. The profiler we recommend is koute's memory profiler .","title":"memory profiler"},{"location":"reference/command-line-tools/memory-profiler/#installation","text":"","title":"Installation"},{"location":"reference/command-line-tools/memory-profiler/#from-a-binary-release","text":"You can download a precompiled binary release of the profiler from here . The last version we've tested is 0.6.1, but any newer one will also most likely work. Here's how you can download and unpack it from the command-line: $ curl -L https://github.com/koute/memory-profiler/releases/download/0.6.1/memory-profiler-x86_64-unknown-linux-gnu.tgz -o memory-profiler-x86_64-unknown-linux-gnu.tgz $ tar -xf memory-profiler-x86_64-unknown-linux-gnu.tgz This will result in three files being unpacked. We're only interested in two of them: libmemory_profiler.so - this is the memory profiler itself that we will hook into Substrate memory-profiler-cli - this is the program we will later use to analyze the profiling data","title":"From a binary release"},{"location":"reference/command-line-tools/memory-profiler/#from-source","text":"You can also compile the profiler from source yourself. First you need to make sure to have the following installed: GCC toolchain Rust nightly (we've tested version nightly-2021-06-08 ) Yarn package manager (for building the GUI) Then you should be able to build the profiler like this: $ git clone https://github.com/koute/memory-profiler $ cd memory-profiler $ cargo build --release -p memory-profiler $ cargo build --release -p memory-profiler-cli You'll find the binaries we need in target/release/libmemory_profiler.so and target/release/memory-profiler-cli .","title":"From source"},{"location":"reference/command-line-tools/memory-profiler/#hooking-up-the-profiler-to-substrate","text":"This part heavily depends on how exactly you're launching Substrate.","title":"Hooking up the profiler to Substrate"},{"location":"reference/command-line-tools/memory-profiler/#hooking-to-a-manually-launched-substrate","text":"If you're manually launching Substrate from the command-line then hooking the profiler up to it boils down to just setting up a few extra environment variables and then launching it normally as you'd usually do. First, we want to enable logging, tell the profiler where it's supposed to output its logs, where it should gather its profiling data, and optionally tell it to cull temporary allocations: $ export MEMORY_PROFILER_LOG=info $ export MEMORY_PROFILER_LOGFILE=profiling_%e_%t.log $ export MEMORY_PROFILER_OUTPUT=profiling_%e_%t.dat # Optional, depending on what exact aspect you'd like to profile # and how long you're going to be profiling. $ export MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS=1 Then we can launch Substrate with the profiler attached: $ LD_PRELOAD=/path/to/libmemory_profiler.so ./target/release/substrate Setting the LD_PRELOAD environment variable will instruct Linux's dynamic linker to inject the memory profiler into Substrate just before it's launched, which allows the profiler to hook into the system's memory allocation routines and track every memory allocation that Substrate's doing.","title":"Hooking to a manually launched Substrate"},{"location":"reference/command-line-tools/memory-profiler/#hooking-to-substrate-launched-through-systemd","text":"If you're running a Substrate-based node remotely you're probably using systemd to manage it. Here's how you could go about setting up profiling in such a situation. We assume you've already either downloaded a precompiled binary of the profiler or compiled it from source, and you have it in your current directory. First, we want to copy the memory profiler to a globally accessible location and set up a place where it can write its logs and gather the profiling data. $ sudo mkdir -p /opt/memory-profiler/bin $ sudo cp libmemory_profiler.so /opt/memory-profiler/bin/ $ sudo mkdir /opt/memory-profiler/logs $ sudo chmod 0777 /opt/memory-profiler/logs Then we want to set up a file with all of the environment variables to configure the profiler itself: $ echo \"MEMORY_PROFILER_OUTPUT=/opt/memory-profiler/logs/profiling_%e_%t_%p.dat\" | sudo tee /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_LOGFILE=/opt/memory-profiler/logs/profiling_%e_%t_%p.txt\" | sudo tee -a /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_LOG=info\" | sudo tee -a /opt/memory-profiler/env $ echo \"MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS=1\" | sudo tee -a /opt/memory-profiler/env $ echo \"LD_PRELOAD=/opt/memory-profiler/bin/libmemory_profiler.so\" | sudo tee -a /opt/memory-profiler/env Now you want to open your systemd unit file for your node and add the following in the [Service] section: [Service] EnvironmentFile=/opt/memory-profiler/env Do not add another [Service] section if one already exists; just add the EnvironmentFile key to it. If you already have one EnvironmentFile key do not replace it; just add a second one, systemd will apply both. Now you can reload your systemd daemon: $ sudo systemctl daemon-reload And then restart your service to start the profiling: $ sudo systemctl restart kusama The profiling data will be gathered at /opt/memory-profiler/logs . If you want to disable the memory profiler just delete the EnvironmentFile key you've added to your unit file, and restart the service again.","title":"Hooking to Substrate launched through systemd"},{"location":"reference/command-line-tools/memory-profiler/#configuring-the-profiler","text":"There are also other environment variables you can set to configure the profiler , although besides the ones we've already shown changing them shouldn't be necessary in normal circumstances. One configuration knob that warrants extra consideration is MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS , which controls whenever the profiler will gather short lived allocations. By default the profiler will gather every allocation that's made by the profiled application. That is a lot of data, and can be on the order of megabytes per second. This is great if you want to only profile for a short period of time, or if you specifically care about diagnosing temporary allocations, but it becomes problematic when you want to leave the profiler running for longer. This is where the MEMORY_PROFILER_CULL_TEMPORARY_ALLOCATIONS option comes in. When you turn it on by setting it to 1 the profiler will omit all of the really short lived allocations and not write them out to disk. This significantly cuts down the amount of data that's generated, usually to the range of kilobytes per second, which makes it possible to leave the profiling running for days at a time.","title":"Configuring the profiler"},{"location":"reference/command-line-tools/memory-profiler/#analysis","text":"Now that you've gathered the profiling data you can now analyze it. Assuming you have both the memory-profiler-cli and the .dat file you've gathered in the same directory you can load the GUI for it: $ ./memory-profiler-cli server *.dat This might take a while, depending or your exact hardware and on the amount of data you're trying to load. Eventually you should see something like this being printed out: [2020-05-06T08:59:20Z INFO cli_core::loader] Loaded data in 315s 820 [2020-05-06T08:59:20Z INFO actix_server::builder] Starting 8 workers [2020-05-06T08:59:20Z INFO actix_server::builder] Starting server on 127.0.0.1:8080 Now you can open your web browser and access the GUI at http://localhost:8080/ . There's also a REST API that you can access you'd like to export the data into another format or inspect it programmatically.","title":"Analysis"},{"location":"reference/command-line-tools/memory-profiler/#miscellaneous-tips","text":"It's a good idea to always check the logs generated by the profiler and see whenever there are any WRN or ERR logs present. You might see the the following error or warning in the profiler's logs depending on which Linux distribution you're running: The perf_event_open syscall failed for PID 0: Operation not permitted (os error 1)` This is generally harmless; at most this should only result in higher CPU usage when profiling. You can avoid it by doing something like this: bash $ echo \"-1\" | sudo tee /proc/sys/kernel/perf_event_paranoid Although please note that this might have some security implications. Take a look at man perf_event_open for more details. During analysis the whole data file has to be loaded into memory. If you don't have enough RAM and you'll try to load up a big file the analyzer might run out of memory and crash.","title":"Miscellaneous tips"},{"location":"reference/command-line-tools/node-template/","text":"node-template","title":"node-template"},{"location":"reference/command-line-tools/node-template/#node-template","text":"","title":"node-template"},{"location":"reference/command-line-tools/polkadot-launch/","text":"A simple CLI tool to launch a local Polkadot test network. Go to Documentation .","title":"Polkadot launch"},{"location":"reference/command-line-tools/polkadotjs-apps/","text":"Polkadot-JS apps The Polkadot-JS Apps is a flexible UI for interacting with a Polkadot or Substrate based node. Go to documentation . This is pre-built user-facing application , allowing access to all features available on Substrate chains. To connect the Polkadot-JS Apps to your local node, you must go into Settings and change the \"endpoint to connect to\" to Local Node (127.0.0.1:9944) . If you are connected to the Polkadot-JS Apps over a secure HTTPS connection, you will need to use a browser which also supports bridging to an insecure WebSocket endpoint. For example, Google Chrome supports this, but Mozilla Firefox does not. Polkadot-JS extension The Polkadot-JS Extension is a simple proof-of-concept for managing accounts in a browser extension and allowing the signing of extrinsics using these accounts. It also provides a simple interface for interacting with extension-compliant dApps. Different ways to use the extension: On Chrome On Firefox Fork on GitHub","title":"Polkadotjs apps"},{"location":"reference/command-line-tools/polkadotjs-apps/#polkadot-js-apps","text":"The Polkadot-JS Apps is a flexible UI for interacting with a Polkadot or Substrate based node. Go to documentation . This is pre-built user-facing application , allowing access to all features available on Substrate chains. To connect the Polkadot-JS Apps to your local node, you must go into Settings and change the \"endpoint to connect to\" to Local Node (127.0.0.1:9944) . If you are connected to the Polkadot-JS Apps over a secure HTTPS connection, you will need to use a browser which also supports bridging to an insecure WebSocket endpoint. For example, Google Chrome supports this, but Mozilla Firefox does not.","title":"Polkadot-JS apps"},{"location":"reference/command-line-tools/polkadotjs-apps/#polkadot-js-extension","text":"The Polkadot-JS Extension is a simple proof-of-concept for managing accounts in a browser extension and allowing the signing of extrinsics using these accounts. It also provides a simple interface for interacting with extension-compliant dApps. Different ways to use the extension: On Chrome On Firefox Fork on GitHub","title":"Polkadot-JS extension"},{"location":"reference/command-line-tools/sidecar/","text":"A REST service that makes it easy to interact with blockchain nodes built using Substrate's FRAME framework. Go to documentation .","title":"Sidecar"},{"location":"reference/command-line-tools/srtool/","text":"srtool allows building WASM runtimes in a deterministic way, allowing CIs and users to produce a strictly identical WASM runtime. Go to documentation .","title":"Srtool"},{"location":"reference/command-line-tools/subflood/","text":"A tool that floods a Substrate node with transactions. Go to documentation .","title":"Subflood"},{"location":"reference/command-line-tools/subkey/","text":"subkey The subkey program is a key generation and management utility that is included in the Substrate repository. You can use the subkey program to perform the following tasks: Generate and inspect cryptographically-secure public and private key pairs. Restore keys from secret phrases and raw seeds. Sign and verify signatures on messages. Sign and verify signatures for encoded transactions. Derive hierarchical deterministic child key pairs. Signature schemes The subkey program currently supporting the following signature schemes: sr25519 : Schorr signatures on the Ristretto group. ed25519 : SHA-512 (SHA-2) on Curve25519. secp256k1 : ECDSA signatures on secp256k1. In Substrate-based networks, the sr25519 encoded keys are used to produce SS58 addresses as the public keys for interacting with the blockchain. Installation You can download, install, an compile subkey using cargo without cloning the full Substrate repository. However, you must add Substrate build dependencies to your environment before you can install subkey as a standalone binary. To ensure dependencies are available, you can build the subkey binary from a clone of the Substrate repository. To install and compile the subkey program: Open a terminal shell, if necessary. Verify that you have the Rust compiler and toolchain, if necessary. Clone the Substrate repository, if necessary, by running the following command: bash git clone https://github.com/paritytech/substrate.git Change to the root directory of the Substrate repository by running the following command: bash cd substrate Compile the subkey program using the nightly toolchain by running the following command: bash cargo +nightly build --package subkey --release Because of the number of packages involved, compiling the node can take several minutes. Verify that your node is ready to use and information about the options available by running the following command: bash ./target/release/subkey --help Hierarchical deterministic keys The subkey program supports hierarchical deterministic keys. Hierarchical deterministic (HD) keys enable you to use a parent seed to derive child key pairs in a hierarchical tree structure. In this hierarchical structure, each child derived from a parent has its own key pair. The derived keys can also be used to derive additional child key pairs, similar to how a file system can have nested directories in a hierarchical directory structure. For background information about how hierarchical deterministic keys are derived, see the BIP32 specification for hierarchical deterministic wallets. For information about deriving hierarchical deterministic keys using subkey commands, see Working with derived keys . Basic command usage The basic syntax for running subkey commands is: subkey [subcommand] [flag] Depending on the subcommand you specify, additional arguments, options, and flags might apply or be required. To view usage information for a specific subkey subcommand, specify the subcommand and the --help flag. For example, to see usage information for subkey inspect , you can run the following command: subkey inspect --help Flags You can use the following optional flags with the subkey command. Flag Description -h, --help Displays usage information. -V, --version Displays version information. Subcommands You can use the following subcommands with the subkey command. For reference information and examples that illustrate using subkey subcommands, select an appropriate command. Command Description generate Generates a random account key. generate-node-key Generates a random node libp2p secret key. You can save the secret key to a file or display it as standard output ( stdout ). help Displays usage message for subkey or for a specified subcommand. inspect Displays the public key and SS58 address for the secret URI you specify. inspect-node-key Displays the peer ID that corresponds with the secret node key in the file name you specify. sign Signs a message with the secret key you specify. vanity Generates a seed that provides a vanity address. verify Verifies the signature for a message is valid for the public or secret key you specify. Output Depending on the subcommand you specify, the output from the subkey program displays some or all of the following information: This field Contains Secret phrase A series of English words that encodes the secret key in a human-friendly way. This series of words\u2014also referred to as a mnemonic phrase or seed phrase\u2014can be used to recover a secret key if the correct set of words are provided in the correct order. Secret Seed The minimum information necessary to restore a key pair. The secret seed is also sometimes referred to as a private key or raw seed. All other information is calculated from this value. Public Key (hex) The public half of the cryptographic key pair in hexadecimal format. Public Key (SS58) The public half of the cryptographic key pair in SS58 encoding. Account ID An alias for the public key in hexadecimal format. SS58 Address An SS58-encoded public address based on the public key. Examples To display version information for the subkey program, run the following command: subkey --version To display usage information for the subkey verify command, run the following command: subkey verify --help subkey generate Use the subkey generate command to generate public and private keys and account addresses. You can use command-line options to generate keys with different signature schemes or mnemonic phrases with more or fewer words. Basic usage subkey generate [FLAGS] [OPTIONS] Flags You can use the following optional flags with the subkey generate command. Flag Description -h , --help Displays usage information. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. -V , --version Displays version information. Options You can use the following command-line options with the subkey generate command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services -n , --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic scheme for the key you are generating. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . -w , --words <words> Specifies the number of words in the secret phrase for the key you are generating. Valid values are 12, 15, 18, 21, 24. By default, the secret phrase consists of 12 words. Examples To generate a new key pair that uses the sr25519 signature scheme, run the following command: subkey generate The command displays output similar to the following with a 12-word secret phrase: Secret phrase: bread tongue spell stadium clean grief coin rent spend total practice document Secret seed: 0xd5836897dc77e6c87e5cc268abaaa9c661bcf19aea9f0f50a1e149d21ce31eb7 Public key (hex): 0xb6a8b4b6bf796991065035093d3265e314c3fe89e75ccb623985e57b0c2e0c30 Account ID: 0xb6a8b4b6bf796991065035093d3265e314c3fe89e75ccb623985e57b0c2e0c30 Public key (SS58): 5GCCgshTQCfGkXy6kAkFDW1TZXAdsbCNZJ9Uz2c7ViBnwcVg SS58 Address: 5GCCgshTQCfGkXy6kAkFDW1TZXAdsbCNZJ9Uz2c7ViBnwcVg The subkey program encodes the address associated with a public/private key pair differently depending on the format required for the network where it is used. If you want to use the same private key on the Kusama and Polkadot networks, you can use the --network option to generate the separate address formats for the Kusama and Polkadot networks. The public key is the same, but the address formats are network-specific. To generate a key pair for a specific network, run a command similar to the following: subkey generate --network picasso The command displays the same fields as output, but uses the address format for the network you specify. To generate a more secure key pair that uses the ed25519 signature scheme and an 24-word secret phrase for the moonriver network, you would run the following command: subkey generate --scheme ed25519 --words 24 --network moonriver The command displays the same fields as output, but uses the Ed25519 signature scheme, a 24-word secret phrase, and the address format for the moonriver network. Secret phrase: cloth elevator sadness twice arctic adjust axis vendor grant angle face section key safe under fee fine garage pupil hotel museum valve popular motor Secret seed: 0x5fa5923c1d6753fa30f268ffd363efb730ca0db906f55bc17efe65cd24f92097 Public key (hex): 0x3f1da4d35489e3d84739de1490f51b567ad2a62793cca1357e624fbfa534fc85 Account ID: 0x3f1da4d35489e3d84739de1490f51b567ad2a62793cca1357e624fbfa534fc85 Public key (SS58): VkFLVqcighJnssSbL4LDSGy5ShJQZvYhm7G8K8W1ZXt96Z5VG SS58 Address: VkFLVqcighJnssSbL4LDSGy5ShJQZvYhm7G8K8W1ZXt96Z5VG To generate a key that is password-protected, run the subkey generate command using the --password <password> option. For example: subkey generate --password \"pencil laptop kitchen cutter\" After you generate a key that requires a password, you can retrieve it by including the --password option and password string in the command line or by adding three slashes ( /// ) at the end of the secret phrase. Remember that it is important to keep passwords, secret phrases, and secret seeds secure and to back them up in a secure location. subkey generate-node-key Use the subkey generate-node-key command to generate random public and private keys for peer-to-peer ( libp2p ) communication between Substrate nodes. The public key is the peer identifier that is used in chain specification files or as a command-line argument to identify a node participating in the blockchain network. In most cases, you use run this command with a command-line option to save the private key to a file. Basic usage subkey generate-node-key [FLAGS] [OPTIONS] Flags You can use the following optional flags with the subkey generate-node-key command. Flag Description -h , --help Displays usage information. -V , --version Displays version information. Options You can use the following command-line option with the subkey generate-node-key command. Option Description --file <file-name> Specifies the file location you want to use to save the secret key generated for the local node. If you don't specify this option, the generated keys are displayed as standard output ( stdout ). Examples To generate a random key pair for peer-to-peer communication and save the secret key in a file, run a command similar to the following: subkey generate-node-key --file ../generated-node-key This command displays the peer identifier for the node key in the terminal and the private key is saved in the generated-node-key file. In this example, the saved key in the parent directory instead of the current working directory. 12D3KooWHALHfL7dDBiGTt4JTEAvCbDWts8zHwvcPvJXDF9fxue7 subkey help Use the subkey help command to displays usage message for subkey or for a specified subcommand. Basic usage subkey help [SUBCOMMAND] Examples To display usage information for the verify subcommand, run the following command: subkey help verify subkey inspect Use the subkey inspect command to recalculate the public key and public address for specified secret key or mnemonic phrase. Basic usage subkey inspect [FLAGS] [OPTIONS] uri Flags You can use the following optional flags with the subkey inspect command. Flag Description -h , --help Displays usage information. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. --public Indicates that the uri you specify to inspect is a hex-encoded public key. -V , --version Displays version information. Options You can use the following command-line options with the subkey inspect command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services. -n , --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic scheme for the key you are inspecting. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . Arguments You must specify the following required argument with the subkey inspect command. Argument Description uri Specifies the key URI you want to inspect. You can specify the key using its secret phrase, secret seed (with derivation paths and password), SS58 address, public key, or hex-encoded public key. If you specify the uri using a hex-encoded public key, you must also include the --public flag on the command line. If you specify a file name for the uri , the file content is used as the URI. Examples To inspect the public keys derived from a mnemonic phrase, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\" The command displays output similar to the following: Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account: Secret seed: 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR To inspect the public keys derived from a secret seed, you can run a command similar to the following: subkey inspect 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 If you store a secret phrase or secret seed in a text file\u2014for example, my-secret-key \u2014you can specify the file name on the command-line to pass the contents of the file and display the public keys associated with that secret phrase or secret seed. For example, you can run a command similar to the following: subkey inspect my-secret-key To inspect the public keys using a hex-encoded public key, you can run a command similar to the following: subkey inspect --public 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 In this case, the command only displays public information similar to the following: Network ID/version: substrate Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR The subkey program encodes the address associated with a public/private key pair differently depending on the format required for the network where it is used. If you use the same private key on the Kusama and Polkadot networks, you can use the --network option to inspect the address used for a specific network. The public key is the same, but the address format is network-specific. To inspect a key pair for a specific network, run a command similar to the following: subkey inspect --network kusama \"caution juice atom organ advance problem want pledge someone senior holiday very\" In the command output, the secret phrase, secret seed, and public keys are the same, but the address for the Kusama network is: SS58 Address: HRkCrbmke2XeabJ5fxJdgXWpBRPkXWfWHY8eTeCKwDdf4k6 To inspect the address for the same private key on the Polkadot network, you would run a command similar to the following: subkey inspect --network polkadot \"caution juice atom organ advance problem want pledge someone senior holiday very\" In the command output, the secret phrase, secret seed, and public keys are the same as the Kusama network, but the address for the Polkadot network is: SS58 Address: 15rRgsWxz4H5LTnNGcCFsszfXD8oeAFd8QRsR6MbQE2f6XFF To inspect password-protected keys by specifying the --password option and password, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\" --password \"pencil laptop kitchen cutter\" If you specify the --password option and password in the command line, the command output does not display the password used. Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account: Secret seed: 0xdfc5d5d5235a37fdc907ee1cb720299f96aeb02f9c7c2fcad7ee8c7bfbd2a4db Public key (hex): 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 Public key (SS58): 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK Account ID: 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 SS58 Address: 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK You can also inspect password-protected keys by adding /// and the password to the secret phrase. For example, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very///pencil laptop kitchen cutter\" In this case, the command output displays the password used. For example: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very///pencil laptop kitchen cutter` is account: Secret seed: 0xdfc5d5d5235a37fdc907ee1cb720299f96aeb02f9c7c2fcad7ee8c7bfbd2a4db Public key (hex): 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 Public key (SS58): 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK Account ID: 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 SS58 Address: 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK subkey inspect-node-key Use the subkey inspect-node-key command to display the peer identifier for the node that corresponds with the node key in the specified file name. Before using this command, you should have previously used the subkey generate-node-key command and saved the key to a file. Basic usage subkey inspect-node-key [FLAGS] [OPTIONS] --file <file-name> Flags You can use the following optional flags with the subkey inspect-node-key command. Flag Description -h , --help Displays usage information. -V , --version Displays version information. Options You can use the following command-line option with the subkey inspect-node-key command. Option Description -n, --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. Arguments You must specify the following required argument with the subkey inspect-node-key command. Argument Description --file <file-name> Specifies the file that contains the secret key generated for the peer-to-peer communication with a node. subkey sign Use the subkey sign command to sign a message by passing the message as standard input ( stdin ). You can sign messages using your secret seed or secret phrase. Basic usage subkey sign [FLAGS] [OPTIONS] Flags You can use the following optional flags with the subkey sign command. Flag Description -h , --help Displays usage information. --hex Indicates that the message you specify as standard input is a hex-encoded message. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. -V , --version Displays version information. Options You can use the following command-line options with the subkey sign command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services. --message <network> Specifies the message string to sign. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . --suri <secret-seed> Specifies the secret key URI you want to use to sign the message. You can specify the key using its secret phrase, secret seed (with derivation paths and password). If you specify a file name for the --suri option, the file content is used as the URI. If you omit this option, you are prompted for the URI. Examples The following example uses the echo command to pipe a test message as input to the subkey sign command. To sign a text message in a terminal, you can run a command similar to the following: echo \"test message\" | subkey sign --suri 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 The command output displays the signature for the message. For example: f052504de653a5617c46eeb1daa73e2dbbf625b6bf8f16d9d8de6767bc40d91dfbd38c13207f8a03594221c9f68c00a158eb3120311b80ab2da563b82a995b86 To sign a hex-encoded message, run a command similar to the following: subkey sign --hex --message 68656c6c6f2c20776f726c64 --suri 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 The command output displays the signature for the message. For example: 9ae07defc0ddb752651836c25ac643fbdf9d45ba180ec6d09e4423ff6446487a52b609d69c06bd1c3ec09b3d06a43f019bacba12dc5a5697291c5e9faab13288 subkey vanity Use the subkey vanity command to create an address that contains a specified string patter. This command does not generate a secret phrase for the custom address. Basic usage subkey vanity [FLAGS] [OPTIONS] --pattern <pattern> Flags You can use the following optional flags with the subkey vanity command. Flag Description -h , --help Displays usage information. -V , --version Displays version information. Options You can use the following command-line options with the subkey vanity command. Option Description -n, --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . Arguments You must specify the following required argument with the subkey vanity command. Argument Description --pattern <pattern> Specifies the string you want to include in the generated address. Examples Depending on the pattern you specify, the subkey vanity command can take some time to search keystores and generate an address that contains the custom string. In general, you should use as few characters as possible for the --pattern and use the --network option to specify the network where you want to use the custom address, To generate an address that contains a specific string, you can run a command similar to the following: subkey vanity --network kusama --pattern DUNE The command displays output similar to the following: Generating key containing pattern 'DUNE' 100000 keys searched; best is 187/237 complete 200000 keys searched; best is 189/237 complete 300000 keys searched; best is 221/237 complete 400000 keys searched; best is 221/237 complete 500000 keys searched; best is 221/237 complete 600000 keys searched; best is 221/237 complete best: 237 == top: 237 Secret Key URI `0x82737756075d15409053afd19a6b29ae2abeed96a3487d71d2af9b3eff19cbfa` is account: Secret seed: 0x82737756075d15409053afd19a6b29ae2abeed96a3487d71d2af9b3eff19cbfa Public key (hex): 0xe025cc93383436f61f067ff918ec632d0933c2d81da3bc1fbc27c9d33579bc40 Account ID: 0xe025cc93383436f61f067ff918ec632d0933c2d81da3bc1fbc27c9d33579bc40 Public key (SS58): HeDUNE7vd4cYtwHadXBWTgYrsKGQXZ5xFLVbgPVo71X1ccF SS58 Address: HeDUNE7vd4cYtwHadXBWTgYrsKGQXZ5xFLVbgPVo71X1ccF After the key pair is generated, the SS58 address and public key both contain the custom string DUNE . subkey verify Use the subkey verify command to verify the signature for a message using a public or secret key. Basic syntax subkey verify [FLAGS] [OPTIONS] <signature> <uri> Flags You can use the following optional flags with the subkey verify command. Flag Description -h , --help Displays usage information. --hex Indicates that the message you specify as standard input is a hex-encoded message. -V , --version Displays version information. Options You can use the following command-line options with the subkey verify command. Option Description --message <message> Specifies the message to verify. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . Arguments You must specify the following required argument with the subkey verify command. Argument Description <signature> Specifies the hex-encoded signature to verify. <uri> Specifies the public or secret key URI that you want to use to verify the message. If you specify a file name for the uri , the file content is used as the URI. If you omit this option, you are prompted for the URI. Examples The following example uses the echo command to pipe a test message as input to the subkey verify command. echo \"test message\" | subkey verify f052504de653a5617c46eeb1daa73e2dbbf625b6bf8f16d9d8de6767bc40d91dfbd38c13207f8a03594221c9f68c00a158eb3120311b80ab2da563b82a995b86 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR If the message signature is verified, the command output confirms the signature, For example: Signature verifies correctly. To verify the signature for a hex-encoded message, run a command similar to the following: subkey verify --hex --message 68656c6c6f2c20776f726c64 4e9d84c9d67241f916272c3f39cd145d847cfeed322b3a4fcba67e1113f8b21440396cb7624113c14af2cd76850fc8445ec538005d7d39ce664e5fb0d926a48f 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR If the message signature is verified, the command output confirms the signature, For example: Signature verifies correctly. Working with derived keys In Substrate, hierarchical deterministic derived keys are classified as hard keys or as soft keys based on how they are derived. For example, hard keys can only be derived using the parent private key and a derivation path. The parent public key cannot be used to derive a hard key. Soft keys can be derived using either the parent private key or the parent public key and a derivation path. Because soft keys can be derived using the parent public key, they can be used to identify the parent key without exposing the parent seed. You can derive either hard keys or soft keys by using different syntax in subkey commands. You can then use the addresses associated with derived keys to sign messages with the same security as messages signed by their root key. Derive a hard key To derive a hard child key pair, you add two slashes ( // ), a derivation path, and an index after the secret phrase associated with its parent key. Because you derive child key pairs and addresses from keys that have been previously generated, you use the subkey inspect command. For example: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key//0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key//0` is account: Secret seed: 0x667fe31c1d1d8f00811aa0163001b5b3055b26f11e82ae17e28668d0e08ced51 Public key (hex): 0xd61bbc562fc43d43d80a3372a25c52e4aa862bbfdbb4aa1a5ec86f042f787f24 Account ID: 0xd61bbc562fc43d43d80a3372a25c52e4aa862bbfdbb4aa1a5ec86f042f787f24 Public key (SS58): 5GuSLtVEbYgYT9Q78CX99RSSPuHjsAyAadwC1GmweDvTvFTZ SS58 Address: 5GuSLtVEbYgYT9Q78CX99RSSPuHjsAyAadwC1GmweDvTvFTZ Derive a soft key To derive a soft child key pair from a parent private key, you add one slash ( / ), a derivation path, and an index after the secret phrase associated with the parent key. Because you are deriving a new key pair and address from a key that ahs been previously generated, you use the subkey inspect command. For example: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very/derived-soft-key/0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very/derived-soft-key/0` is account: Secret seed: n/a Public key (hex): 0x8826cc3730441dc4b67ea118997780db878ce7848c1548a9d36624ca39cf7c2c Account ID: 0x8826cc3730441dc4b67ea118997780db878ce7848c1548a9d36624ca39cf7c2c Public key (SS58): 5F9DtrPk3SaFs6U6S8HxnuJcoQ2jF8Wdt3ygwbbBnbVcsdiC SS58 Address: 5F9DtrPk3SaFs6U6S8HxnuJcoQ2jF8Wdt3ygwbbBnbVcsdiC To derive a soft child key pair from a parent public key, you can use the public SS58 address instead of the secret phrase. Because you are deriving a soft key, you use a single slash ( / ) to delimit the derivation path and index fields. For example: subkey inspect \"5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-public/0\" The command displays output similar to the following: Public Key URI `5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-public/0` is account: Network ID/version: substrate Public key (hex): 0xee3792a82ba43fc503bcbdabd7d090df71496a43928e25f87843f1d9d40e8a14 Account ID: 0xee3792a82ba43fc503bcbdabd7d090df71496a43928e25f87843f1d9d40e8a14 Public key (SS58): 5HT3mAg8NnpgeZFUsM9aUYVdS5iq6ZWVUoNcTDiuqVvjkgKR SS58 Address: 5HT3mAg8NnpgeZFUsM9aUYVdS5iq6ZWVUoNcTDiuqVvjkgKR If you use the same derivation path and index, the soft child key is the same whether you use the parent private key or parent public address. If you change either the derivation path\u2014for example, from derived-soft-key to derived-public \u2014or the index\u2014from 0 to 1 \u2014you derive different child keys with different addresses. For example: subkey inspect \"5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-soft-key/1\" The command displays output similar to the following: Public Key URI `5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-soft-key/1` is account: Network ID/version: substrate Public key (hex): 0x688d5a9761bc2705efd3ff0171a535e97de12aab59659177efae453873b18673 Account ID: 0x688d5a9761bc2705efd3ff0171a535e97de12aab59659177efae453873b18673 Public key (SS58): 5ERnpynLaQweDhrBQLe3vz8aWYodKYEeJ92xsbnpgG7GhHvo SS58 Address: 5ERnpynLaQweDhrBQLe3vz8aWYodKYEeJ92xsbnpgG7GhHvo Combine derivation paths and passwords Note that the secret seed is not password protected. Although it can still recover an account, the key pair that's derived is not the same account as recovered with any password! The same seed with different derivation paths passwords will derive different keys. The secret phrase is not sufficient to recover a key pair. Keep your paths and passwords secure, as without it your key pair cannot be recovered! You can derive a soft key as a child of a hard key. Doing so enables you to use the public address of the derived hard\u2014with an optional password\u2014to derive new public addresses. For example, the following command derives a hard key ( //derived-hard-key ) with a soft key leaf ( /0 ): subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0` is account: Secret seed: n/a Public key (hex): 0x525039c770a07a38d8dc066927ad1f0d2b2113f4bc890c4fd39a37d477d0d336 Account ID: 0x525039c770a07a38d8dc066927ad1f0d2b2113f4bc890c4fd39a37d477d0d336 Public key (SS58): 5DvdcfXQe2QcWHNZrUR5Bb2AJQ199BiNH5aHefE4kXSRP1VR SS58 Address: 5DvdcfXQe2QcWHNZrUR5Bb2AJQ199BiNH5aHefE4kXSRP1VR To protect the derived hard key, you can add your password to the end of the secret phrase: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0///pencil laptop kitchen cutter\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0///pencil laptop kitchen cutter` is account: Secret seed: n/a Public key (hex): 0x2efb74b4a21294f0031129a1d271c7be00171d207052af567fc76de03a81fe52 Account ID: 0x2efb74b4a21294f0031129a1d271c7be00171d207052af567fc76de03a81fe52 Public key (SS58): 5D8JkugWWMDmQ4h2yUuBLWwQXaBi2nBdiDmY4DR7hW76QmuW SS58 Address: 5D8JkugWWMDmQ4h2yUuBLWwQXaBi2nBdiDmY4DR7hW76QmuW The following command creates a soft key derived from a public address with a hidden seed, hard key derivation path, and a password. subkey inspect \"5GsbzysSK8TKahXBC7FpS2myx3nWehMyYU7q8CLrzZCjpKbM/0\" The command displays output similar to the following: Public Key URI `5GsbzysSK8TKahXBC7FpS2myx3nWehMyYU7q8CLrzZCjpKbM/0` is account: Network ID/version: substrate Public key (hex): 0xcaf1f5ec14b507b5c365c6528cc06de74a5615274694a0c895ed4109c0ff0d32 Public key (SS58): 5GeoQa3nkeNmzZSfgBFuK3BkAggnTHcX3S1j94sffJYYphrP Account ID: 0xcaf1f5ec14b507b5c365c6528cc06de74a5615274694a0c895ed4109c0ff0d32 SS58 Address: 5GeoQa3nkeNmzZSfgBFuK3BkAggnTHcX3S1j94sffJYYphrP This example illustrates that the soft key derived using the SS58-address/derivation path produces the same address as the secret phrase//derivation path/index///password . With this strategy for combining hard and soft keys, you can reveal a parent public address and soft derivation paths without revealing your secret phrase or password, retaining control of all derived addresses. Predefined accounts and keys Substrate includes several predefined accounts that you can use for testing in a local development environment. These predefined accounts are all derived from the same seed using a single secret phrase. The secret phrase used to generate the keys for all of the predefined accounts consists of the following words: bottom drive obey lake curtain smoke basket hold race lonely fit walk You can inspect the keys for the predefined account using the derivation path. For example: subkey inspect //Alice The command Secret Key URI `//Alice` is account: Secret seed: 0xe5be9a5092b81bca64be81d212e7f2f9eba183bb7a90954f7b76361f6edb5c0a Public key (hex): 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Account ID: 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Public key (SS58): 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY SS58 Address: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY It is important to note that //Alice and //alice are different derivation paths and the secret phrase and derivation path for the predefined account is actually: bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice You can run the following command to verify the keys match: subkey inspect \"bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice\" The command output displays the following: Secret Key URI `bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice` is account: Secret seed: 0xe5be9a5092b81bca64be81d212e7f2f9eba183bb7a90954f7b76361f6edb5c0a Public key (hex): 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Account ID: 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Public key (SS58): 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY SS58 Address: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY Further resources Subkey README . PolkadotJS Apps UI . Cryptographic algorithms and choosing between them .","title":"subkey"},{"location":"reference/command-line-tools/subkey/#subkey","text":"The subkey program is a key generation and management utility that is included in the Substrate repository. You can use the subkey program to perform the following tasks: Generate and inspect cryptographically-secure public and private key pairs. Restore keys from secret phrases and raw seeds. Sign and verify signatures on messages. Sign and verify signatures for encoded transactions. Derive hierarchical deterministic child key pairs.","title":"subkey"},{"location":"reference/command-line-tools/subkey/#signature-schemes","text":"The subkey program currently supporting the following signature schemes: sr25519 : Schorr signatures on the Ristretto group. ed25519 : SHA-512 (SHA-2) on Curve25519. secp256k1 : ECDSA signatures on secp256k1. In Substrate-based networks, the sr25519 encoded keys are used to produce SS58 addresses as the public keys for interacting with the blockchain.","title":"Signature schemes"},{"location":"reference/command-line-tools/subkey/#installation","text":"You can download, install, an compile subkey using cargo without cloning the full Substrate repository. However, you must add Substrate build dependencies to your environment before you can install subkey as a standalone binary. To ensure dependencies are available, you can build the subkey binary from a clone of the Substrate repository. To install and compile the subkey program: Open a terminal shell, if necessary. Verify that you have the Rust compiler and toolchain, if necessary. Clone the Substrate repository, if necessary, by running the following command: bash git clone https://github.com/paritytech/substrate.git Change to the root directory of the Substrate repository by running the following command: bash cd substrate Compile the subkey program using the nightly toolchain by running the following command: bash cargo +nightly build --package subkey --release Because of the number of packages involved, compiling the node can take several minutes. Verify that your node is ready to use and information about the options available by running the following command: bash ./target/release/subkey --help","title":"Installation"},{"location":"reference/command-line-tools/subkey/#hierarchical-deterministic-keys","text":"The subkey program supports hierarchical deterministic keys. Hierarchical deterministic (HD) keys enable you to use a parent seed to derive child key pairs in a hierarchical tree structure. In this hierarchical structure, each child derived from a parent has its own key pair. The derived keys can also be used to derive additional child key pairs, similar to how a file system can have nested directories in a hierarchical directory structure. For background information about how hierarchical deterministic keys are derived, see the BIP32 specification for hierarchical deterministic wallets. For information about deriving hierarchical deterministic keys using subkey commands, see Working with derived keys .","title":"Hierarchical deterministic keys"},{"location":"reference/command-line-tools/subkey/#basic-command-usage","text":"The basic syntax for running subkey commands is: subkey [subcommand] [flag] Depending on the subcommand you specify, additional arguments, options, and flags might apply or be required. To view usage information for a specific subkey subcommand, specify the subcommand and the --help flag. For example, to see usage information for subkey inspect , you can run the following command: subkey inspect --help","title":"Basic command usage"},{"location":"reference/command-line-tools/subkey/#flags","text":"You can use the following optional flags with the subkey command. Flag Description -h, --help Displays usage information. -V, --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#subcommands","text":"You can use the following subcommands with the subkey command. For reference information and examples that illustrate using subkey subcommands, select an appropriate command. Command Description generate Generates a random account key. generate-node-key Generates a random node libp2p secret key. You can save the secret key to a file or display it as standard output ( stdout ). help Displays usage message for subkey or for a specified subcommand. inspect Displays the public key and SS58 address for the secret URI you specify. inspect-node-key Displays the peer ID that corresponds with the secret node key in the file name you specify. sign Signs a message with the secret key you specify. vanity Generates a seed that provides a vanity address. verify Verifies the signature for a message is valid for the public or secret key you specify.","title":"Subcommands"},{"location":"reference/command-line-tools/subkey/#output","text":"Depending on the subcommand you specify, the output from the subkey program displays some or all of the following information: This field Contains Secret phrase A series of English words that encodes the secret key in a human-friendly way. This series of words\u2014also referred to as a mnemonic phrase or seed phrase\u2014can be used to recover a secret key if the correct set of words are provided in the correct order. Secret Seed The minimum information necessary to restore a key pair. The secret seed is also sometimes referred to as a private key or raw seed. All other information is calculated from this value. Public Key (hex) The public half of the cryptographic key pair in hexadecimal format. Public Key (SS58) The public half of the cryptographic key pair in SS58 encoding. Account ID An alias for the public key in hexadecimal format. SS58 Address An SS58-encoded public address based on the public key.","title":"Output"},{"location":"reference/command-line-tools/subkey/#examples","text":"To display version information for the subkey program, run the following command: subkey --version To display usage information for the subkey verify command, run the following command: subkey verify --help","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-generate","text":"Use the subkey generate command to generate public and private keys and account addresses. You can use command-line options to generate keys with different signature schemes or mnemonic phrases with more or fewer words.","title":"subkey generate"},{"location":"reference/command-line-tools/subkey/#basic-usage","text":"subkey generate [FLAGS] [OPTIONS]","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_1","text":"You can use the following optional flags with the subkey generate command. Flag Description -h , --help Displays usage information. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options","text":"You can use the following command-line options with the subkey generate command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services -n , --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic scheme for the key you are generating. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . -w , --words <words> Specifies the number of words in the secret phrase for the key you are generating. Valid values are 12, 15, 18, 21, 24. By default, the secret phrase consists of 12 words.","title":"Options"},{"location":"reference/command-line-tools/subkey/#examples_1","text":"To generate a new key pair that uses the sr25519 signature scheme, run the following command: subkey generate The command displays output similar to the following with a 12-word secret phrase: Secret phrase: bread tongue spell stadium clean grief coin rent spend total practice document Secret seed: 0xd5836897dc77e6c87e5cc268abaaa9c661bcf19aea9f0f50a1e149d21ce31eb7 Public key (hex): 0xb6a8b4b6bf796991065035093d3265e314c3fe89e75ccb623985e57b0c2e0c30 Account ID: 0xb6a8b4b6bf796991065035093d3265e314c3fe89e75ccb623985e57b0c2e0c30 Public key (SS58): 5GCCgshTQCfGkXy6kAkFDW1TZXAdsbCNZJ9Uz2c7ViBnwcVg SS58 Address: 5GCCgshTQCfGkXy6kAkFDW1TZXAdsbCNZJ9Uz2c7ViBnwcVg The subkey program encodes the address associated with a public/private key pair differently depending on the format required for the network where it is used. If you want to use the same private key on the Kusama and Polkadot networks, you can use the --network option to generate the separate address formats for the Kusama and Polkadot networks. The public key is the same, but the address formats are network-specific. To generate a key pair for a specific network, run a command similar to the following: subkey generate --network picasso The command displays the same fields as output, but uses the address format for the network you specify. To generate a more secure key pair that uses the ed25519 signature scheme and an 24-word secret phrase for the moonriver network, you would run the following command: subkey generate --scheme ed25519 --words 24 --network moonriver The command displays the same fields as output, but uses the Ed25519 signature scheme, a 24-word secret phrase, and the address format for the moonriver network. Secret phrase: cloth elevator sadness twice arctic adjust axis vendor grant angle face section key safe under fee fine garage pupil hotel museum valve popular motor Secret seed: 0x5fa5923c1d6753fa30f268ffd363efb730ca0db906f55bc17efe65cd24f92097 Public key (hex): 0x3f1da4d35489e3d84739de1490f51b567ad2a62793cca1357e624fbfa534fc85 Account ID: 0x3f1da4d35489e3d84739de1490f51b567ad2a62793cca1357e624fbfa534fc85 Public key (SS58): VkFLVqcighJnssSbL4LDSGy5ShJQZvYhm7G8K8W1ZXt96Z5VG SS58 Address: VkFLVqcighJnssSbL4LDSGy5ShJQZvYhm7G8K8W1ZXt96Z5VG To generate a key that is password-protected, run the subkey generate command using the --password <password> option. For example: subkey generate --password \"pencil laptop kitchen cutter\" After you generate a key that requires a password, you can retrieve it by including the --password option and password string in the command line or by adding three slashes ( /// ) at the end of the secret phrase. Remember that it is important to keep passwords, secret phrases, and secret seeds secure and to back them up in a secure location.","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-generate-node-key","text":"Use the subkey generate-node-key command to generate random public and private keys for peer-to-peer ( libp2p ) communication between Substrate nodes. The public key is the peer identifier that is used in chain specification files or as a command-line argument to identify a node participating in the blockchain network. In most cases, you use run this command with a command-line option to save the private key to a file.","title":"subkey generate-node-key"},{"location":"reference/command-line-tools/subkey/#basic-usage_1","text":"subkey generate-node-key [FLAGS] [OPTIONS]","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_2","text":"You can use the following optional flags with the subkey generate-node-key command. Flag Description -h , --help Displays usage information. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_1","text":"You can use the following command-line option with the subkey generate-node-key command. Option Description --file <file-name> Specifies the file location you want to use to save the secret key generated for the local node. If you don't specify this option, the generated keys are displayed as standard output ( stdout ).","title":"Options"},{"location":"reference/command-line-tools/subkey/#examples_2","text":"To generate a random key pair for peer-to-peer communication and save the secret key in a file, run a command similar to the following: subkey generate-node-key --file ../generated-node-key This command displays the peer identifier for the node key in the terminal and the private key is saved in the generated-node-key file. In this example, the saved key in the parent directory instead of the current working directory. 12D3KooWHALHfL7dDBiGTt4JTEAvCbDWts8zHwvcPvJXDF9fxue7","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-help","text":"Use the subkey help command to displays usage message for subkey or for a specified subcommand.","title":"subkey help"},{"location":"reference/command-line-tools/subkey/#basic-usage_2","text":"subkey help [SUBCOMMAND]","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#examples_3","text":"To display usage information for the verify subcommand, run the following command: subkey help verify","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-inspect","text":"Use the subkey inspect command to recalculate the public key and public address for specified secret key or mnemonic phrase.","title":"subkey inspect"},{"location":"reference/command-line-tools/subkey/#basic-usage_3","text":"subkey inspect [FLAGS] [OPTIONS] uri","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_3","text":"You can use the following optional flags with the subkey inspect command. Flag Description -h , --help Displays usage information. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. --public Indicates that the uri you specify to inspect is a hex-encoded public key. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_2","text":"You can use the following command-line options with the subkey inspect command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services. -n , --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic scheme for the key you are inspecting. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 .","title":"Options"},{"location":"reference/command-line-tools/subkey/#arguments","text":"You must specify the following required argument with the subkey inspect command. Argument Description uri Specifies the key URI you want to inspect. You can specify the key using its secret phrase, secret seed (with derivation paths and password), SS58 address, public key, or hex-encoded public key. If you specify the uri using a hex-encoded public key, you must also include the --public flag on the command line. If you specify a file name for the uri , the file content is used as the URI.","title":"Arguments"},{"location":"reference/command-line-tools/subkey/#examples_4","text":"To inspect the public keys derived from a mnemonic phrase, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\" The command displays output similar to the following: Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account: Secret seed: 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR To inspect the public keys derived from a secret seed, you can run a command similar to the following: subkey inspect 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 If you store a secret phrase or secret seed in a text file\u2014for example, my-secret-key \u2014you can specify the file name on the command-line to pass the contents of the file and display the public keys associated with that secret phrase or secret seed. For example, you can run a command similar to the following: subkey inspect my-secret-key To inspect the public keys using a hex-encoded public key, you can run a command similar to the following: subkey inspect --public 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 In this case, the command only displays public information similar to the following: Network ID/version: substrate Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746 Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR The subkey program encodes the address associated with a public/private key pair differently depending on the format required for the network where it is used. If you use the same private key on the Kusama and Polkadot networks, you can use the --network option to inspect the address used for a specific network. The public key is the same, but the address format is network-specific. To inspect a key pair for a specific network, run a command similar to the following: subkey inspect --network kusama \"caution juice atom organ advance problem want pledge someone senior holiday very\" In the command output, the secret phrase, secret seed, and public keys are the same, but the address for the Kusama network is: SS58 Address: HRkCrbmke2XeabJ5fxJdgXWpBRPkXWfWHY8eTeCKwDdf4k6 To inspect the address for the same private key on the Polkadot network, you would run a command similar to the following: subkey inspect --network polkadot \"caution juice atom organ advance problem want pledge someone senior holiday very\" In the command output, the secret phrase, secret seed, and public keys are the same as the Kusama network, but the address for the Polkadot network is: SS58 Address: 15rRgsWxz4H5LTnNGcCFsszfXD8oeAFd8QRsR6MbQE2f6XFF To inspect password-protected keys by specifying the --password option and password, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\" --password \"pencil laptop kitchen cutter\" If you specify the --password option and password in the command line, the command output does not display the password used. Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account: Secret seed: 0xdfc5d5d5235a37fdc907ee1cb720299f96aeb02f9c7c2fcad7ee8c7bfbd2a4db Public key (hex): 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 Public key (SS58): 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK Account ID: 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 SS58 Address: 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK You can also inspect password-protected keys by adding /// and the password to the secret phrase. For example, you can run a command similar to the following: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very///pencil laptop kitchen cutter\" In this case, the command output displays the password used. For example: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very///pencil laptop kitchen cutter` is account: Secret seed: 0xdfc5d5d5235a37fdc907ee1cb720299f96aeb02f9c7c2fcad7ee8c7bfbd2a4db Public key (hex): 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 Public key (SS58): 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK Account ID: 0xdef8f78b123475265815b65a7c55e105e1ab185f4969954f68d92b7bb67a1045 SS58 Address: 5H74SqH1iQCWh5Gumyghh1WJMcmM6TdBHYSK7mKVJbv9NuSK","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-inspect-node-key","text":"Use the subkey inspect-node-key command to display the peer identifier for the node that corresponds with the node key in the specified file name. Before using this command, you should have previously used the subkey generate-node-key command and saved the key to a file.","title":"subkey inspect-node-key"},{"location":"reference/command-line-tools/subkey/#basic-usage_4","text":"subkey inspect-node-key [FLAGS] [OPTIONS] --file <file-name>","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_4","text":"You can use the following optional flags with the subkey inspect-node-key command. Flag Description -h , --help Displays usage information. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_3","text":"You can use the following command-line option with the subkey inspect-node-key command. Option Description -n, --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information.","title":"Options"},{"location":"reference/command-line-tools/subkey/#arguments_1","text":"You must specify the following required argument with the subkey inspect-node-key command. Argument Description --file <file-name> Specifies the file that contains the secret key generated for the peer-to-peer communication with a node.","title":"Arguments"},{"location":"reference/command-line-tools/subkey/#subkey-sign","text":"Use the subkey sign command to sign a message by passing the message as standard input ( stdin ). You can sign messages using your secret seed or secret phrase.","title":"subkey sign"},{"location":"reference/command-line-tools/subkey/#basic-usage_5","text":"subkey sign [FLAGS] [OPTIONS]","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_5","text":"You can use the following optional flags with the subkey sign command. Flag Description -h , --help Displays usage information. --hex Indicates that the message you specify as standard input is a hex-encoded message. --password-interactive Enables you to enter the password for accessing the keystore interactively in the terminal. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_4","text":"You can use the following command-line options with the subkey sign command. Option Description --keystore-path <path> Specifies a custom keystore path. --keystore-uri <keystore-uri> Specifies a custom URI to connect to for keystore services. --message <network> Specifies the message string to sign. --password <password> Specifies the password used by the keystore. This option enables you to append an extra secret to the seed. --password-filename <path> Specifies the name of a file that contains the password used by the keystore. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 . --suri <secret-seed> Specifies the secret key URI you want to use to sign the message. You can specify the key using its secret phrase, secret seed (with derivation paths and password). If you specify a file name for the --suri option, the file content is used as the URI. If you omit this option, you are prompted for the URI.","title":"Options"},{"location":"reference/command-line-tools/subkey/#examples_5","text":"The following example uses the echo command to pipe a test message as input to the subkey sign command. To sign a text message in a terminal, you can run a command similar to the following: echo \"test message\" | subkey sign --suri 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 The command output displays the signature for the message. For example: f052504de653a5617c46eeb1daa73e2dbbf625b6bf8f16d9d8de6767bc40d91dfbd38c13207f8a03594221c9f68c00a158eb3120311b80ab2da563b82a995b86 To sign a hex-encoded message, run a command similar to the following: subkey sign --hex --message 68656c6c6f2c20776f726c64 --suri 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849 The command output displays the signature for the message. For example: 9ae07defc0ddb752651836c25ac643fbdf9d45ba180ec6d09e4423ff6446487a52b609d69c06bd1c3ec09b3d06a43f019bacba12dc5a5697291c5e9faab13288","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-vanity","text":"Use the subkey vanity command to create an address that contains a specified string patter. This command does not generate a secret phrase for the custom address.","title":"subkey vanity"},{"location":"reference/command-line-tools/subkey/#basic-usage_6","text":"subkey vanity [FLAGS] [OPTIONS] --pattern <pattern>","title":"Basic usage"},{"location":"reference/command-line-tools/subkey/#flags_6","text":"You can use the following optional flags with the subkey vanity command. Flag Description -h , --help Displays usage information. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_5","text":"You can use the following command-line options with the subkey vanity command. Option Description -n, --network <network> Specifies the network address format to use. For example, kusama or polkadot . For a complete list of networks supported, see the online usage information. --output-type <format> Specifies the output format to use. Valid values are Json and Text. The default output format is Text. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 .","title":"Options"},{"location":"reference/command-line-tools/subkey/#arguments_2","text":"You must specify the following required argument with the subkey vanity command. Argument Description --pattern <pattern> Specifies the string you want to include in the generated address.","title":"Arguments"},{"location":"reference/command-line-tools/subkey/#examples_6","text":"Depending on the pattern you specify, the subkey vanity command can take some time to search keystores and generate an address that contains the custom string. In general, you should use as few characters as possible for the --pattern and use the --network option to specify the network where you want to use the custom address, To generate an address that contains a specific string, you can run a command similar to the following: subkey vanity --network kusama --pattern DUNE The command displays output similar to the following: Generating key containing pattern 'DUNE' 100000 keys searched; best is 187/237 complete 200000 keys searched; best is 189/237 complete 300000 keys searched; best is 221/237 complete 400000 keys searched; best is 221/237 complete 500000 keys searched; best is 221/237 complete 600000 keys searched; best is 221/237 complete best: 237 == top: 237 Secret Key URI `0x82737756075d15409053afd19a6b29ae2abeed96a3487d71d2af9b3eff19cbfa` is account: Secret seed: 0x82737756075d15409053afd19a6b29ae2abeed96a3487d71d2af9b3eff19cbfa Public key (hex): 0xe025cc93383436f61f067ff918ec632d0933c2d81da3bc1fbc27c9d33579bc40 Account ID: 0xe025cc93383436f61f067ff918ec632d0933c2d81da3bc1fbc27c9d33579bc40 Public key (SS58): HeDUNE7vd4cYtwHadXBWTgYrsKGQXZ5xFLVbgPVo71X1ccF SS58 Address: HeDUNE7vd4cYtwHadXBWTgYrsKGQXZ5xFLVbgPVo71X1ccF After the key pair is generated, the SS58 address and public key both contain the custom string DUNE .","title":"Examples"},{"location":"reference/command-line-tools/subkey/#subkey-verify","text":"Use the subkey verify command to verify the signature for a message using a public or secret key.","title":"subkey verify"},{"location":"reference/command-line-tools/subkey/#basic-syntax","text":"subkey verify [FLAGS] [OPTIONS] <signature> <uri>","title":"Basic syntax"},{"location":"reference/command-line-tools/subkey/#flags_7","text":"You can use the following optional flags with the subkey verify command. Flag Description -h , --help Displays usage information. --hex Indicates that the message you specify as standard input is a hex-encoded message. -V , --version Displays version information.","title":"Flags"},{"location":"reference/command-line-tools/subkey/#options_6","text":"You can use the following command-line options with the subkey verify command. Option Description --message <message> Specifies the message to verify. --scheme <scheme> Specifies the cryptographic signature scheme for the key. Valid values are Ecdsa , Ed25519 , Sr25519 . The default scheme is Sr25519 .","title":"Options"},{"location":"reference/command-line-tools/subkey/#arguments_3","text":"You must specify the following required argument with the subkey verify command. Argument Description <signature> Specifies the hex-encoded signature to verify. <uri> Specifies the public or secret key URI that you want to use to verify the message. If you specify a file name for the uri , the file content is used as the URI. If you omit this option, you are prompted for the URI.","title":"Arguments"},{"location":"reference/command-line-tools/subkey/#examples_7","text":"The following example uses the echo command to pipe a test message as input to the subkey verify command. echo \"test message\" | subkey verify f052504de653a5617c46eeb1daa73e2dbbf625b6bf8f16d9d8de6767bc40d91dfbd38c13207f8a03594221c9f68c00a158eb3120311b80ab2da563b82a995b86 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR If the message signature is verified, the command output confirms the signature, For example: Signature verifies correctly. To verify the signature for a hex-encoded message, run a command similar to the following: subkey verify --hex --message 68656c6c6f2c20776f726c64 4e9d84c9d67241f916272c3f39cd145d847cfeed322b3a4fcba67e1113f8b21440396cb7624113c14af2cd76850fc8445ec538005d7d39ce664e5fb0d926a48f 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR If the message signature is verified, the command output confirms the signature, For example: Signature verifies correctly.","title":"Examples"},{"location":"reference/command-line-tools/subkey/#working-with-derived-keys","text":"In Substrate, hierarchical deterministic derived keys are classified as hard keys or as soft keys based on how they are derived. For example, hard keys can only be derived using the parent private key and a derivation path. The parent public key cannot be used to derive a hard key. Soft keys can be derived using either the parent private key or the parent public key and a derivation path. Because soft keys can be derived using the parent public key, they can be used to identify the parent key without exposing the parent seed. You can derive either hard keys or soft keys by using different syntax in subkey commands. You can then use the addresses associated with derived keys to sign messages with the same security as messages signed by their root key.","title":"Working with derived keys"},{"location":"reference/command-line-tools/subkey/#derive-a-hard-key","text":"To derive a hard child key pair, you add two slashes ( // ), a derivation path, and an index after the secret phrase associated with its parent key. Because you derive child key pairs and addresses from keys that have been previously generated, you use the subkey inspect command. For example: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key//0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key//0` is account: Secret seed: 0x667fe31c1d1d8f00811aa0163001b5b3055b26f11e82ae17e28668d0e08ced51 Public key (hex): 0xd61bbc562fc43d43d80a3372a25c52e4aa862bbfdbb4aa1a5ec86f042f787f24 Account ID: 0xd61bbc562fc43d43d80a3372a25c52e4aa862bbfdbb4aa1a5ec86f042f787f24 Public key (SS58): 5GuSLtVEbYgYT9Q78CX99RSSPuHjsAyAadwC1GmweDvTvFTZ SS58 Address: 5GuSLtVEbYgYT9Q78CX99RSSPuHjsAyAadwC1GmweDvTvFTZ","title":"Derive a hard key"},{"location":"reference/command-line-tools/subkey/#derive-a-soft-key","text":"To derive a soft child key pair from a parent private key, you add one slash ( / ), a derivation path, and an index after the secret phrase associated with the parent key. Because you are deriving a new key pair and address from a key that ahs been previously generated, you use the subkey inspect command. For example: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very/derived-soft-key/0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very/derived-soft-key/0` is account: Secret seed: n/a Public key (hex): 0x8826cc3730441dc4b67ea118997780db878ce7848c1548a9d36624ca39cf7c2c Account ID: 0x8826cc3730441dc4b67ea118997780db878ce7848c1548a9d36624ca39cf7c2c Public key (SS58): 5F9DtrPk3SaFs6U6S8HxnuJcoQ2jF8Wdt3ygwbbBnbVcsdiC SS58 Address: 5F9DtrPk3SaFs6U6S8HxnuJcoQ2jF8Wdt3ygwbbBnbVcsdiC To derive a soft child key pair from a parent public key, you can use the public SS58 address instead of the secret phrase. Because you are deriving a soft key, you use a single slash ( / ) to delimit the derivation path and index fields. For example: subkey inspect \"5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-public/0\" The command displays output similar to the following: Public Key URI `5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-public/0` is account: Network ID/version: substrate Public key (hex): 0xee3792a82ba43fc503bcbdabd7d090df71496a43928e25f87843f1d9d40e8a14 Account ID: 0xee3792a82ba43fc503bcbdabd7d090df71496a43928e25f87843f1d9d40e8a14 Public key (SS58): 5HT3mAg8NnpgeZFUsM9aUYVdS5iq6ZWVUoNcTDiuqVvjkgKR SS58 Address: 5HT3mAg8NnpgeZFUsM9aUYVdS5iq6ZWVUoNcTDiuqVvjkgKR If you use the same derivation path and index, the soft child key is the same whether you use the parent private key or parent public address. If you change either the derivation path\u2014for example, from derived-soft-key to derived-public \u2014or the index\u2014from 0 to 1 \u2014you derive different child keys with different addresses. For example: subkey inspect \"5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-soft-key/1\" The command displays output similar to the following: Public Key URI `5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR/derived-soft-key/1` is account: Network ID/version: substrate Public key (hex): 0x688d5a9761bc2705efd3ff0171a535e97de12aab59659177efae453873b18673 Account ID: 0x688d5a9761bc2705efd3ff0171a535e97de12aab59659177efae453873b18673 Public key (SS58): 5ERnpynLaQweDhrBQLe3vz8aWYodKYEeJ92xsbnpgG7GhHvo SS58 Address: 5ERnpynLaQweDhrBQLe3vz8aWYodKYEeJ92xsbnpgG7GhHvo","title":"Derive a soft key"},{"location":"reference/command-line-tools/subkey/#combine-derivation-paths-and-passwords","text":"Note that the secret seed is not password protected. Although it can still recover an account, the key pair that's derived is not the same account as recovered with any password! The same seed with different derivation paths passwords will derive different keys. The secret phrase is not sufficient to recover a key pair. Keep your paths and passwords secure, as without it your key pair cannot be recovered! You can derive a soft key as a child of a hard key. Doing so enables you to use the public address of the derived hard\u2014with an optional password\u2014to derive new public addresses. For example, the following command derives a hard key ( //derived-hard-key ) with a soft key leaf ( /0 ): subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0` is account: Secret seed: n/a Public key (hex): 0x525039c770a07a38d8dc066927ad1f0d2b2113f4bc890c4fd39a37d477d0d336 Account ID: 0x525039c770a07a38d8dc066927ad1f0d2b2113f4bc890c4fd39a37d477d0d336 Public key (SS58): 5DvdcfXQe2QcWHNZrUR5Bb2AJQ199BiNH5aHefE4kXSRP1VR SS58 Address: 5DvdcfXQe2QcWHNZrUR5Bb2AJQ199BiNH5aHefE4kXSRP1VR To protect the derived hard key, you can add your password to the end of the secret phrase: subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0///pencil laptop kitchen cutter\" The command displays output similar to the following: Secret Key URI `caution juice atom organ advance problem want pledge someone senior holiday very//derived-hard-key/0///pencil laptop kitchen cutter` is account: Secret seed: n/a Public key (hex): 0x2efb74b4a21294f0031129a1d271c7be00171d207052af567fc76de03a81fe52 Account ID: 0x2efb74b4a21294f0031129a1d271c7be00171d207052af567fc76de03a81fe52 Public key (SS58): 5D8JkugWWMDmQ4h2yUuBLWwQXaBi2nBdiDmY4DR7hW76QmuW SS58 Address: 5D8JkugWWMDmQ4h2yUuBLWwQXaBi2nBdiDmY4DR7hW76QmuW The following command creates a soft key derived from a public address with a hidden seed, hard key derivation path, and a password. subkey inspect \"5GsbzysSK8TKahXBC7FpS2myx3nWehMyYU7q8CLrzZCjpKbM/0\" The command displays output similar to the following: Public Key URI `5GsbzysSK8TKahXBC7FpS2myx3nWehMyYU7q8CLrzZCjpKbM/0` is account: Network ID/version: substrate Public key (hex): 0xcaf1f5ec14b507b5c365c6528cc06de74a5615274694a0c895ed4109c0ff0d32 Public key (SS58): 5GeoQa3nkeNmzZSfgBFuK3BkAggnTHcX3S1j94sffJYYphrP Account ID: 0xcaf1f5ec14b507b5c365c6528cc06de74a5615274694a0c895ed4109c0ff0d32 SS58 Address: 5GeoQa3nkeNmzZSfgBFuK3BkAggnTHcX3S1j94sffJYYphrP This example illustrates that the soft key derived using the SS58-address/derivation path produces the same address as the secret phrase//derivation path/index///password . With this strategy for combining hard and soft keys, you can reveal a parent public address and soft derivation paths without revealing your secret phrase or password, retaining control of all derived addresses.","title":"Combine derivation paths and passwords"},{"location":"reference/command-line-tools/subkey/#predefined-accounts-and-keys","text":"Substrate includes several predefined accounts that you can use for testing in a local development environment. These predefined accounts are all derived from the same seed using a single secret phrase. The secret phrase used to generate the keys for all of the predefined accounts consists of the following words: bottom drive obey lake curtain smoke basket hold race lonely fit walk You can inspect the keys for the predefined account using the derivation path. For example: subkey inspect //Alice The command Secret Key URI `//Alice` is account: Secret seed: 0xe5be9a5092b81bca64be81d212e7f2f9eba183bb7a90954f7b76361f6edb5c0a Public key (hex): 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Account ID: 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Public key (SS58): 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY SS58 Address: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY It is important to note that //Alice and //alice are different derivation paths and the secret phrase and derivation path for the predefined account is actually: bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice You can run the following command to verify the keys match: subkey inspect \"bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice\" The command output displays the following: Secret Key URI `bottom drive obey lake curtain smoke basket hold race lonely fit walk//Alice` is account: Secret seed: 0xe5be9a5092b81bca64be81d212e7f2f9eba183bb7a90954f7b76361f6edb5c0a Public key (hex): 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Account ID: 0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d Public key (SS58): 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY SS58 Address: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY","title":"Predefined accounts and keys"},{"location":"reference/command-line-tools/subkey/#further-resources","text":"Subkey README . PolkadotJS Apps UI . Cryptographic algorithms and choosing between them .","title":"Further resources"},{"location":"reference/command-line-tools/subxt/","text":"A library to submit extrinsics to a Substrate node via RPC. Go to documentation . Rough notes [WIP]: What does subxt do? Download the metadata of a substrate node using subxt-cli Generates runtime API from the downloaded metadata Architecture / HL : - ClientBuilder core - What the relationship between tokio and jsonrpsee? - How is subxt different from https://github.com/scs/substrate-api-client/ ? - without TypeInfo it's likely stuck in the same way subxt was for a long time: it can work but has to be recompiled for each runtime upgrade. What's the difference between using metadata at compile time to generate the API and using metadata at runtime to constuct exstrinsic indices and decode events? Reference structure what is it used for? any requirements? what options/parameters/arguments does it support? command-line examples input/output? Notes: topic is metadata and how it relates to subxt what is the metadata problem? problem: everyone who develops clients run into this issue: 1. only javascript to interact to substrate and 2. if you want to have multiple substrate chains you need to maintain a registry of types on the client solving the problem of clients needing to maintain their own types. Solution is that types are moved to the metadata itself subxt is the rust client solution purely based on the metadata Prelude Stack: - pallets used in runtimes - they are exposed in frame and metadata - used in rpcs responses - which uses scale codec from crate - that type information is extracted or turned into presentable form with scale-info crate which is able to describe types and derive descriptions for all the types below the stack This is preparatory work for tools like subxt to be possible to write. What's the lifecycle of a Substrate type? Users / use: - everyone that uses polkadot js could and should be able to use subxt - it hasn't been possible to do something robust worth investing outside of the Javascript land. - This is a tool to be used outside the Wasm context. - Anyone who's a rust client developer - Tool for lower level applications, maybe non-browser GUIs - Benchmarking - CLI in rust - Interlay is using it - Phala is using it too - SGX hardware use cases - tinkerer hobbyist who prefers Rust - devops tool / infrastructure stuff - also runtime engineers Whats missing? - event subscription api needs some work - it used to be opinionated. It should be clear it'll only return an event for an extrinsics. It does the filtering for you. Pain points: - Need to upgrade firmware each time a chain changes (for hardware wallets) - Previously you needed to recompile substrate every time Nice to have: - Not no_std compatible because json_rpsee See Rust docs Macros from partiy-scale-codec derive all Subxt cli: - encourage usability - used to download the metadata - creates a json serialized metadata file - used to generate the api - subxt macro uses the metadata file to generate the api - It generates a bunch of types and an api in order to submit txns and read from storage Requirements: - connects to the rpc of a node - node needs to be running rpc What other things can you put in the module?","title":"Subxt"},{"location":"reference/command-line-tools/subxt/#reference-structure","text":"what is it used for? any requirements? what options/parameters/arguments does it support? command-line examples input/output? Notes: topic is metadata and how it relates to subxt what is the metadata problem? problem: everyone who develops clients run into this issue: 1. only javascript to interact to substrate and 2. if you want to have multiple substrate chains you need to maintain a registry of types on the client solving the problem of clients needing to maintain their own types. Solution is that types are moved to the metadata itself subxt is the rust client solution purely based on the metadata Prelude Stack: - pallets used in runtimes - they are exposed in frame and metadata - used in rpcs responses - which uses scale codec from crate - that type information is extracted or turned into presentable form with scale-info crate which is able to describe types and derive descriptions for all the types below the stack This is preparatory work for tools like subxt to be possible to write. What's the lifecycle of a Substrate type? Users / use: - everyone that uses polkadot js could and should be able to use subxt - it hasn't been possible to do something robust worth investing outside of the Javascript land. - This is a tool to be used outside the Wasm context. - Anyone who's a rust client developer - Tool for lower level applications, maybe non-browser GUIs - Benchmarking - CLI in rust - Interlay is using it - Phala is using it too - SGX hardware use cases - tinkerer hobbyist who prefers Rust - devops tool / infrastructure stuff - also runtime engineers Whats missing? - event subscription api needs some work - it used to be opinionated. It should be clear it'll only return an event for an extrinsics. It does the filtering for you. Pain points: - Need to upgrade firmware each time a chain changes (for hardware wallets) - Previously you needed to recompile substrate every time Nice to have: - Not no_std compatible because json_rpsee See Rust docs Macros from partiy-scale-codec derive all Subxt cli: - encourage usability - used to download the metadata - creates a json serialized metadata file - used to generate the api - subxt macro uses the metadata file to generate the api - It generates a bunch of types and an api in order to submit txns and read from storage Requirements: - connects to the rpc of a node - node needs to be running rpc What other things can you put in the module?","title":"Reference structure"},{"location":"reference/command-line-tools/try-runtime/","text":"The try-runtime tool is built to query a snapshot of runtime storage, using an in-memory-externalities to store state. In this way, it enables runtime engineers to write tests for a specified runtime state, for testing against real chain state before going to production. It is designed to be used as a command line interface to specify at which block to query state. In its simplest form, try-runtime is a tool that enables: Connecting to a remote node and calling into some runtime API. Scraping the specified state from a node at a given block. Writing tests for that data. Motivation The initial motivation for try-runtime came from the need to test runtime changes against state from a real chain. Prior TestExternalities and BasicExternalities existed for writing unit and integrated tests with mock data, but lacked an avenue to test against a chain's actual state. try-runtime extends TestExternalities and BasicExternalities by scraping state (which is stored with key value pairs) via a node's RPC endpoints getStorage and getKeysPaged and inserting them into TestExternalities . How it works The try-runtime tool has its own implementation of externalities called remote_externalities which is just a builder wrapper around TestExternalities that uses a generic key-value store where data is SCALE encoded . The diagram below illustrates the way externalities sits outside a compiled runtime as a means to capture the storage of that runtime. Storage externalities Testing with externalities With remote_externalities , developers can capture some chain state and run tests on it. Essentially, RemoteExternalities will populate a TestExternalities with a real chain's data. In order to query state, try-runtime makes use of Substrate's RPCs, namely StateApi . In particular: storage : A method which returns a storage value under the given key. storage_key_paged : A method which returns the keys with prefix with pagination support. Usage The most common use case for try-runtime is with storage migrations and runtime upgrades. There are a number of flags that need to be preferably set on a running node in order to work well with try-runtime\u2019s expensive RPC queries, namely: set --rpc-max-payload 1000 to ensure large RPC queries can work. set --rpc-cors all to ensure ws connections can come through. Combine \\ try-runtime\\` with \u0002klzzwxh:0036\u0003fork-off-substrate\u0002klzzwxh:0037\u0003 to test your chain before production. Use \\`try-runtime\\` to test your chain's migration and its pre and post states. Then, use \\`fork-off-substrate\\` if you want to check that block production continues fine after the migration, and do some other arbitrary testing.`} /> Calling into hooks from OnRuntimeUpgrade By default, there are two ways of defining a runtime upgrade in the runtime. The OnRuntimeUpgrade trait provides the different methods to achieve this. From inside a runtime . For example: rust struct Custom; impl OnRuntimeUpgrade for Custom { fn on_runtime_upgrade() -> Weight { // -- snip -- } } From inside a pallet . For example: rust #[pallet::hooks] impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> { fn on_runtime_upgrade() -> Weight { // -- snip -- } } These hooks will specify what should happen upon a runtime upgrade . For testing purposes, we prefer having hooks that allow us to inspect the state before and after a runtime upgrade as well. These hooks are not available by default, and are only available under a specific feature flag, named try-runtime . The new hooks are as follows: #[cfg(feature = \"try-runtime\")] fn pre_upgrade() -> Result<(), &'static str> { Ok(()) } #[cfg(feature = \"try-runtime\")] fn post_upgrade() -> Result<(), &'static str> { Ok(()) } Helper functions OnRuntimeUpgradeHelpersExt are a set of helper functions made available from frame_support::hooks in order to use try-runtime for testing storage migrations. These include: storage_key : Generates a storage key unique to this runtime upgrade. This can be used to communicate data from pre-upgrade to post-upgrade state and check them. set_temp_storage : Writes some temporary data to a specific storage that can be read (potentially in the post-upgrade hook). get_temp_storage : Gets temporary storage data written by set_temp_storage . Using the frame_executive::Executive struct, these helper functions in action would look like: pub struct CheckTotalIssuance; impl OnRuntimeUpgrade for CheckTotalIssuance { #[cfg(feature = \"try-runtime\")] fn post_upgrade() { // iterate over all accounts, sum their balance and ensure that sum is correct. } } pub struct EnsureAccountsWontDie; impl OnRuntimeUpgrade for EnsureAccountsWontDie { #[cfg(feature = \"try-runtime\")] fn pre_upgrade() { let account_count = frame_system::Accounts::<Runtime>::iter().count(); Self::set_temp_storage(account_count, \"account_count\"); } #[cfg(feature = \"try-runtime\")] fn post_upgrade() { // ensure that this migration doesn't kill any account. let post_migration = frame_system::Accounts::<Runtime>::iter().count(); let pre_migration = Self::get_temp_storage::<u32>(\"account_count\"); ensure!(post_migration == pre_migration, \"error ...\"); } } pub type CheckerMigrations = (EnsureAccountsWontDie, CheckTotalIssuance); pub type Executive = Executive<_, _, _, _, (CheckerMigrations)>; CLI interface To use try-runtime from the command line, run your node with the --features=try-runtime flag. The possible sub-commands include: on-runtime-upgrade : Executes \"tryRuntime_on_runtime_upgrade\" against the given runtime state. offchain-worker : Executes \"offchainWorkerApi_offchain_worker\" against the given runtime state. execute-block : Executes \"core_execute_block\" using the given block and the runtime state of the parent block. follow-chain : Follows a given chain's finalized blocks and applies to all its extrinsics. This allows the behavior of a new runtime to be inspected over a long period of time, with real transactions coming as input. For example, running try-runtime with the \"on-runtime-upgrade\" subcommand on a chain running locally: cargo run --release --features=try-runtime try-runtime on-runtime-upgrade live ws://localhost:9944 Other scenarios Using it to re-execute code from a ElectionProviderMultiPhase off-chain worker on localhost:9944 : cargo run -- --release \\ --features=try-runtime \\ try-runtime \\ --execution Wasm \\ --wasm-execution Compiled \\ offchain-worker \\ --header-at 0x491d09f313c707b5096650d76600f063b09835fd820e2916d3f8b0f5b45bec30 \\ live \\ -b 0x491d09f313c707b5096650d76600f063b09835fd820e2916d3f8b0f5b45bec30 \\ -m ElectionProviderMultiPhase --uri wss://localhost:9944 You can pass in the --help flag after each subcommand to see the command's different options. Run the migrations of the local runtime on the state of SomeChain, for example: RUST_LOG=runtime=trace,try-runtime::cli=trace,executor=trace \\ cargo run try-runtime \\ --execution Native \\ --chain somechain-dev \\ on-runtime-upgrade \\ live \\ --uri wss://rpc.polkadot.io Running it at a specific block number's state: RUST_LOG=runtime=trace,try-runtime::cli=trace,executor=trace \\ cargo run try-runtime \\ --execution Native \\ --chain dev \\ --no-spec-name-check \\ # mind this one! on-runtime-upgrade \\ live \\ --uri wss://rpc.polkadot.io \\ --at <block-hash> Next steps Learn more Refer to this how-to guide on how to integrate try-runtime to your project. Read more about Storage keys OnRuntimeUpgrade FRAME trait try-runtime-upgrade from frame_executive set_storage from sp_core::traits::Externalities storage_keys_paged from sc_rpc::state::StateApi Examples try-runtime in FRAME's Staking pallet","title":"Try runtime"},{"location":"reference/command-line-tools/try-runtime/#motivation","text":"The initial motivation for try-runtime came from the need to test runtime changes against state from a real chain. Prior TestExternalities and BasicExternalities existed for writing unit and integrated tests with mock data, but lacked an avenue to test against a chain's actual state. try-runtime extends TestExternalities and BasicExternalities by scraping state (which is stored with key value pairs) via a node's RPC endpoints getStorage and getKeysPaged and inserting them into TestExternalities .","title":"Motivation"},{"location":"reference/command-line-tools/try-runtime/#how-it-works","text":"The try-runtime tool has its own implementation of externalities called remote_externalities which is just a builder wrapper around TestExternalities that uses a generic key-value store where data is SCALE encoded . The diagram below illustrates the way externalities sits outside a compiled runtime as a means to capture the storage of that runtime.","title":"How it works"},{"location":"reference/command-line-tools/try-runtime/#storage-externalities","text":"","title":"Storage externalities"},{"location":"reference/command-line-tools/try-runtime/#testing-with-externalities","text":"With remote_externalities , developers can capture some chain state and run tests on it. Essentially, RemoteExternalities will populate a TestExternalities with a real chain's data. In order to query state, try-runtime makes use of Substrate's RPCs, namely StateApi . In particular: storage : A method which returns a storage value under the given key. storage_key_paged : A method which returns the keys with prefix with pagination support.","title":"Testing with externalities"},{"location":"reference/command-line-tools/try-runtime/#usage","text":"The most common use case for try-runtime is with storage migrations and runtime upgrades. There are a number of flags that need to be preferably set on a running node in order to work well with try-runtime\u2019s expensive RPC queries, namely: set --rpc-max-payload 1000 to ensure large RPC queries can work. set --rpc-cors all to ensure ws connections can come through. Combine \\ try-runtime\\` with \u0002klzzwxh:0036\u0003fork-off-substrate\u0002klzzwxh:0037\u0003 to test your chain before production. Use \\`try-runtime\\` to test your chain's migration and its pre and post states. Then, use \\`fork-off-substrate\\` if you want to check that block production continues fine after the migration, and do some other arbitrary testing.`} />","title":"Usage"},{"location":"reference/command-line-tools/try-runtime/#calling-into-hooks-from-onruntimeupgrade","text":"By default, there are two ways of defining a runtime upgrade in the runtime. The OnRuntimeUpgrade trait provides the different methods to achieve this. From inside a runtime . For example: rust struct Custom; impl OnRuntimeUpgrade for Custom { fn on_runtime_upgrade() -> Weight { // -- snip -- } } From inside a pallet . For example: rust #[pallet::hooks] impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> { fn on_runtime_upgrade() -> Weight { // -- snip -- } } These hooks will specify what should happen upon a runtime upgrade . For testing purposes, we prefer having hooks that allow us to inspect the state before and after a runtime upgrade as well. These hooks are not available by default, and are only available under a specific feature flag, named try-runtime . The new hooks are as follows: #[cfg(feature = \"try-runtime\")] fn pre_upgrade() -> Result<(), &'static str> { Ok(()) } #[cfg(feature = \"try-runtime\")] fn post_upgrade() -> Result<(), &'static str> { Ok(()) }","title":"Calling into hooks from OnRuntimeUpgrade"},{"location":"reference/command-line-tools/try-runtime/#helper-functions","text":"OnRuntimeUpgradeHelpersExt are a set of helper functions made available from frame_support::hooks in order to use try-runtime for testing storage migrations. These include: storage_key : Generates a storage key unique to this runtime upgrade. This can be used to communicate data from pre-upgrade to post-upgrade state and check them. set_temp_storage : Writes some temporary data to a specific storage that can be read (potentially in the post-upgrade hook). get_temp_storage : Gets temporary storage data written by set_temp_storage . Using the frame_executive::Executive struct, these helper functions in action would look like: pub struct CheckTotalIssuance; impl OnRuntimeUpgrade for CheckTotalIssuance { #[cfg(feature = \"try-runtime\")] fn post_upgrade() { // iterate over all accounts, sum their balance and ensure that sum is correct. } } pub struct EnsureAccountsWontDie; impl OnRuntimeUpgrade for EnsureAccountsWontDie { #[cfg(feature = \"try-runtime\")] fn pre_upgrade() { let account_count = frame_system::Accounts::<Runtime>::iter().count(); Self::set_temp_storage(account_count, \"account_count\"); } #[cfg(feature = \"try-runtime\")] fn post_upgrade() { // ensure that this migration doesn't kill any account. let post_migration = frame_system::Accounts::<Runtime>::iter().count(); let pre_migration = Self::get_temp_storage::<u32>(\"account_count\"); ensure!(post_migration == pre_migration, \"error ...\"); } } pub type CheckerMigrations = (EnsureAccountsWontDie, CheckTotalIssuance); pub type Executive = Executive<_, _, _, _, (CheckerMigrations)>;","title":"Helper functions"},{"location":"reference/command-line-tools/try-runtime/#cli-interface","text":"To use try-runtime from the command line, run your node with the --features=try-runtime flag. The possible sub-commands include: on-runtime-upgrade : Executes \"tryRuntime_on_runtime_upgrade\" against the given runtime state. offchain-worker : Executes \"offchainWorkerApi_offchain_worker\" against the given runtime state. execute-block : Executes \"core_execute_block\" using the given block and the runtime state of the parent block. follow-chain : Follows a given chain's finalized blocks and applies to all its extrinsics. This allows the behavior of a new runtime to be inspected over a long period of time, with real transactions coming as input. For example, running try-runtime with the \"on-runtime-upgrade\" subcommand on a chain running locally: cargo run --release --features=try-runtime try-runtime on-runtime-upgrade live ws://localhost:9944","title":"CLI interface"},{"location":"reference/command-line-tools/try-runtime/#other-scenarios","text":"Using it to re-execute code from a ElectionProviderMultiPhase off-chain worker on localhost:9944 : cargo run -- --release \\ --features=try-runtime \\ try-runtime \\ --execution Wasm \\ --wasm-execution Compiled \\ offchain-worker \\ --header-at 0x491d09f313c707b5096650d76600f063b09835fd820e2916d3f8b0f5b45bec30 \\ live \\ -b 0x491d09f313c707b5096650d76600f063b09835fd820e2916d3f8b0f5b45bec30 \\ -m ElectionProviderMultiPhase --uri wss://localhost:9944 You can pass in the --help flag after each subcommand to see the command's different options. Run the migrations of the local runtime on the state of SomeChain, for example: RUST_LOG=runtime=trace,try-runtime::cli=trace,executor=trace \\ cargo run try-runtime \\ --execution Native \\ --chain somechain-dev \\ on-runtime-upgrade \\ live \\ --uri wss://rpc.polkadot.io Running it at a specific block number's state: RUST_LOG=runtime=trace,try-runtime::cli=trace,executor=trace \\ cargo run try-runtime \\ --execution Native \\ --chain dev \\ --no-spec-name-check \\ # mind this one! on-runtime-upgrade \\ live \\ --uri wss://rpc.polkadot.io \\ --at <block-hash>","title":"Other scenarios"},{"location":"reference/command-line-tools/try-runtime/#next-steps","text":"","title":"Next steps"},{"location":"reference/command-line-tools/try-runtime/#learn-more","text":"Refer to this how-to guide on how to integrate try-runtime to your project. Read more about Storage keys OnRuntimeUpgrade FRAME trait try-runtime-upgrade from frame_executive set_storage from sp_core::traits::Externalities storage_keys_paged from sc_rpc::state::StateApi","title":"Learn more"},{"location":"reference/command-line-tools/try-runtime/#examples","text":"try-runtime in FRAME's Staking pallet","title":"Examples"},{"location":"reference/command-line-tools/tx-wrapper/","text":"tx wrapper Tools for FRAME chain builders to publish chain specific offline transaction generation libraries. Go to documentation .","title":"Tx wrapper"},{"location":"reference/command-line-tools/tx-wrapper/#tx-wrapper","text":"Tools for FRAME chain builders to publish chain specific offline transaction generation libraries. Go to documentation .","title":"tx wrapper"},{"location":"reference/how-to-guides/","text":"Substrate How-to quick reference guides provide instructions for achieving specific goals. Each guide explains how to perform a specific task with the assumption that you are already familiar with Substrate and programming in Rust. The How-to quick reference guides are organized into the following categories: Basics Learn the simple patterns that runtime engineers know inside out. These guides cover the basics that will help you understand more complex topics. Pallet Design A collection of best practices on building pallets using FRAME. Weights All guides about benchmarking and weight configurations for runtime engineers. Testing Guides to cover different use cases for testing pallets and other runtime logic. Storage migrations A collection of guides to help runtime engineers with different types of storage migrations. Consensus Discover different ways to implement consensus mechanisms in your runtimes. Parachains All things related to integrating and extending standalone Substrate chains to parachains. Tools Guides for tools that are not included out-of-the-box to help you managing Substrate chains in production. Learn more about contributing to these guides here .","title":"How-to quick reference guides"},{"location":"reference/how-to-guides/#basics","text":"Learn the simple patterns that runtime engineers know inside out. These guides cover the basics that will help you understand more complex topics.","title":"Basics"},{"location":"reference/how-to-guides/#pallet-design","text":"A collection of best practices on building pallets using FRAME.","title":"Pallet Design"},{"location":"reference/how-to-guides/#weights","text":"All guides about benchmarking and weight configurations for runtime engineers.","title":"Weights"},{"location":"reference/how-to-guides/#testing","text":"Guides to cover different use cases for testing pallets and other runtime logic.","title":"Testing"},{"location":"reference/how-to-guides/#storage-migrations","text":"A collection of guides to help runtime engineers with different types of storage migrations.","title":"Storage migrations"},{"location":"reference/how-to-guides/#consensus","text":"Discover different ways to implement consensus mechanisms in your runtimes.","title":"Consensus"},{"location":"reference/how-to-guides/#parachains","text":"All things related to integrating and extending standalone Substrate chains to parachains.","title":"Parachains"},{"location":"reference/how-to-guides/#tools","text":"Guides for tools that are not included out-of-the-box to help you managing Substrate chains in production. Learn more about contributing to these guides here .","title":"Tools"},{"location":"tutorials/","text":"Tutorials Landing page or recommended path for different developer journeys.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"Landing page or recommended path for different developer journeys.","title":"Tutorials"},{"location":"tutorials/01-build-local-blockchain/","text":"As you learned in Blockchain basics , a blockchain consists of decentralized computers\u2014called nodes\u2014to form a network. Substrate provides a flexible, open, and extensible development environment that allows you to design and build fully-customized blockchain nodes to suit your application or business model needs. Get started The first step in becoming a blockchain developer is to learn how to compile and launch a single local blockchain node. In this tutorial, you build and start a single node blockchain using a node template. The Substrate node template provides a working single-node blockchain that you can run locally in your development environment. The node template includes several predefined components\u2014such as user accounts and account balances\u2014so that you can experiment with performing common tasks. Without making any changes to the template, you can run a functional node that produces blocks and allows transactions. After you start the local blockchain node, this tutorial illustrates how you can use a Substrate front-end template to view information about blockchain activity and submit a transaction. Who is this tutorial for? This tutorial provides a basic introduction to Substrate and prepares a minimal working development environment that you can use to explore further in additional tutorials. It is intended for anyone interested in learning about Substrate and blockchain development. The tutorial assumes you have no prior experience or knowledge of Substrate. You don't need any programming or blockchain experience to complete this tutorial. This is just the first step, but hopefully, it inspires you to continue your journey. How much time do you need to complete this tutorial? This tutorial requires compiling Rust code and takes approximately one to two hours to complete. Before you begin For this tutorial, you download and use working code. Before you begin, verify the following: You have good internet connection and access to a shell terminal on your local computer. You are generally familiar with software development and use command-line interfaces. You are generally familiar with blockchains and smart contract platforms. Tutorial objectives By completing this tutorial, you will accomplish the following objectives: Set up a Substrate development environment on your computer. Install the node template to start a Substrate-based blockchain. Install a front-end template to interact with the local blockchain node. Use the front-end template to submit a transaction and view the result. Install required packages Substrate development is easiest on UNIX-based operating systems like macOS or Linux. If you are using Microsoft Windows, refer to the Windows installation page . To install required packages on macOS or Linux: Open a terminal shell on your computer. Locate your operating system in the following table and run the appropriate commands for your development environment. OS Installation commands Ubuntu or Debian sudo apt update && sudo apt install -y git clang curl libssl-dev llvm libudev-dev Arch Linux pacman -Syu --needed --noconfirm curl git clang Fedora sudo dnf update sudo dnf install clang curl git openssl-devel OpenSUSE sudo zypper install clang curl git openssl-devel llvm-devel libudev-devel macOS brew update && brew install openssl Windows Refer to this installation guide . If you are using macOS and do not have Homebrew installed, run the following command to install Homebrew: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" After installing Homebrew, run brew install openssl . Install Rust and the Rust toolchain To install and configure Rust manually: Install rustup by running the following command: bash curl https://sh.rustup.rs -sSf | sh Configure your current shell to reload your PATH environment variable so that it includes the Cargo bin directory by running the following command: bash source ~/.cargo/env Configure the Rust toolchain to default to the latest stable version by running the following commands: bash rustup default stable rustup update Add the nightly release and the nightly WebAssembly ( wasm ) targets by running the following commands: bash rustup update nightly rustup target add wasm32-unknown-unknown --toolchain nightly Verify your installation by running the following commands: bash rustc --version rustup show The previous steps walked you through the installation and configuration of Rust and the Rust toolchain so that you could see the full process for yourself. It is also possible to automate the steps using a script. If you want to try installing and configuring Rust using a script, see the getsubstrate automation script. Set up a development environment After you install the required packages and the Rust compiler and toolchain, you are ready to set up a development environment on your local computer. You could build a development environment manually using the tools of your choice, but the Substrate Developer Hub has templates to get you started. After you set up the development environment, you can use it in subsequent tutorials as you learn more about building on Substrate. Prepare a Substrate node The Substrate node template provides a working development environment so that you can start building on Substrate right away. To compile the Substrate node template: Clone the node template repository using the version latest branch by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-node-template Change to the root of the node template directory by running the following command: bash cd substrate-node-template Compile the node template by running the following command: bash cargo build --release You should always use the --release flag to build optimized artifacts. Install the front-end template The front-end template uses ReactJS to render a web browser interface that enables you to interact with the Substrate-based blockchain node. You can use this Front-end template as a starting point for creating user interfaces for your own projects in future. The front-end template requires Yarn and Node.js . If you don't have these tools, install them first. To install the front-end template: Check whether node is installed on your local computer by running the following command: bash node --version If the command doesn\u2019t return a version number, download and install node by following the instructions for the operating system you use on the Node.js website. The node version should be at least v14 to run the front-end template. Check whether yarn is installed on your local computer by running the following command: bash yarn --version The yarn version should be at least v3 to run the front-end template. If the command doesn\u2019t return a version number, download and install yarn by running the following command: bash npm install -g yarn Clone the front-end template repository by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-front-end-template Change to the root of the front-end template directory by running the following command: bash cd substrate-front-end-template Install the dependencies for the front-end template by running the following command: bash yarn install Start the local node After your node compiles, you are ready to start exploring what it does using the front-end template. To start the local Substrate node: Open a terminal shell. Change to the root directory where you compiled the Substrate node template. Start the node in development mode by running the following command: bash ./target/release/node-template --dev The node-template command-line options specify how you want the running node to operate. In this case, the --dev option specifies that the node runs in developer mode using the predefined development chain specification. By default, this option also deletes all active data\u2014such as keys, the blockchain database, and networking information when you stop the node by pressing Control-c. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify your node is up and running successfully by reviewing the output displayed in the terminal. The terminal should display output similar to this: bash 2021-11-24 15:36:35 Running in --dev mode, RPC CORS has been disabled. 2021-11-24 15:36:35 Substrate Node 2021-11-24 15:36:35 \u270c\ufe0f version 4.0.0-dev-82b7c2c-aarch64-macos 2021-11-24 15:36:35 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-11-24 15:36:35 \ud83d\udccb Chain specification: Development 2021-11-24 15:36:35 \ud83c\udff7 Node name: six-wash-9274 2021-11-24 15:36:35 \ud83d\udc64 Role: AUTHORITY 2021-11-24 15:36:35 \ud83d\udcbe Database: RocksDb at /tmp/substrateP1jD7H/chains/dev/db 2021-11-24 15:36:35 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-11-24 15:36:35 \ud83d\udd28 Initializing Genesis block/state (state: 0xa59b\u20265331, header-hash: 0xc5d2\u202637f3) 2021-11-24 15:36:35 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-11-24 15:36:35 \u23f1 Loaded block-time = 6s from block 0xc5d2fdad35e14684753f087c1a20f022274e154d39add4f7efe34e95476a37f3 2021-11-24 15:36:35 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-11-24 15:36:35 \ud83c\udff7 Local node identity is: 12D3KooWG5niQF5bjsFao3D8DZRpUUB6uWZC2pK8hCDZ94zsr8Sc 2021-11-24 15:36:35 \ud83d\udce6 Highest known block at #0 ... ... ... 2021-11-24 15:36:40 \ud83d\udca4 Idle (0 peers), best: #1 (0xd2b5\u2026d03f), finalized #0 (0xc5d2\u202637f3), \u2b07 0 \u2b06 0 If the number after finalized is increasing, your blockchain is producing new blocks and reaching consensus about the state they describe. We'll explore the details of the log output in a later tutorial. For now, it's only important to know that your node is running and producing blocks. Keep the terminal that displays the node output open to continue. Start the front-end template The Substrate front-end template consists of user interface components to enable you to interact with the Substrate node and perform a few common tasks. To use the front-end template: Open a new terminal shell on your computer, change to the root directory where you installed the front-end template. Start the front-end template by running the following command: bash yarn start Open http://localhost:8000 in a browser to view the front-end template. The top section has an Account selection list for selecting the account to work with when you want to perform on-chain operations. The top section of the template also displays information about the chain to which you're connected. You might also notice that the front-end template displays a Balances table with some predefined accounts and that a few of those accounts are preconfigured with funds. You can use this sample data to try out operations like transferring funds. Transfer funds from an account Now that you have a blockchain node running on your local computer and you have a front-end template available for performing on-chain operations, you are ready to explore different ways to interact with the blockchain. By default, the front-end template includes several components that allow you to try different common tasks. For this tutorial, you can perform a simple transfer operation that moves funds from one account to another. To transfer funds to an account: In the Balances table, notice the predefined accounts\u2014such as dave\u2014that have no funds associated with them. Under the Balances table, the front-end template also displays a Transfer component. You use this component to transfer funds from one account to another. Copy and paste the address for the dave account to specify the address to which you are transferring funds. Specify at least 1000000000000 as the amount to transfer, then click Submit . Notice that the values in Balances table is updated with the transfer. Check the Events component to see events related to the transfer you just completed. The Substrate blockchain reports the result of asynchronous operations as events, so you can use the Events components to see details about each operation performed as part of the transfer. For example: When the transaction has been completed and included in a block, you see a confirmation message similar to the following: \ud83d\ude09 Finalized. Block hash: 0xda7e9e935abf5a3a2fdb0a27d67cd7a69e628165b5827255af2635ba226411a4 Stop the local node After a successful transfer, you can continue to explore the front-end template components or stop the local Substrate node the state changes you made. Because you specified the --dev option when you started the node, stopping the local node stops the blockchain and purges all persistent block data so that you can start with a clean state next time you start the node. To stop the local Substrate node: Return to the terminal shell where the node output is displayed. Press Control-c to terminate the running process. Verify your terminal returns to the terminal prompt in the substrate-node-template directory. Next steps Congratulations! In this tutorial, you learned: How to start a working Substrate-based blockchain node using the node. How to view and interact with the blockchain node using a front-end user interface. How to make a simple transfer from one account to another. The front-end template includes several additional components for you to experiment with while you're connected to a local development node. You can explore these components on your own or learn more in the following topics: Explore blockchain metadata . Call extrinsic functions . Add a new pallet . Upgrade the runtime . If you experienced any issues with this tutorial or want to provide feedback: Ask questions on Stack Overflow tagged substrate . Contact the Substrate community on Element .","title":"Build a local blockchain"},{"location":"tutorials/01-build-local-blockchain/#get-started","text":"The first step in becoming a blockchain developer is to learn how to compile and launch a single local blockchain node. In this tutorial, you build and start a single node blockchain using a node template. The Substrate node template provides a working single-node blockchain that you can run locally in your development environment. The node template includes several predefined components\u2014such as user accounts and account balances\u2014so that you can experiment with performing common tasks. Without making any changes to the template, you can run a functional node that produces blocks and allows transactions. After you start the local blockchain node, this tutorial illustrates how you can use a Substrate front-end template to view information about blockchain activity and submit a transaction.","title":"Get started"},{"location":"tutorials/01-build-local-blockchain/#who-is-this-tutorial-for","text":"This tutorial provides a basic introduction to Substrate and prepares a minimal working development environment that you can use to explore further in additional tutorials. It is intended for anyone interested in learning about Substrate and blockchain development. The tutorial assumes you have no prior experience or knowledge of Substrate. You don't need any programming or blockchain experience to complete this tutorial. This is just the first step, but hopefully, it inspires you to continue your journey.","title":"Who is this tutorial for?"},{"location":"tutorials/01-build-local-blockchain/#how-much-time-do-you-need-to-complete-this-tutorial","text":"This tutorial requires compiling Rust code and takes approximately one to two hours to complete.","title":"How much time do you need to complete this tutorial?"},{"location":"tutorials/01-build-local-blockchain/#before-you-begin","text":"For this tutorial, you download and use working code. Before you begin, verify the following: You have good internet connection and access to a shell terminal on your local computer. You are generally familiar with software development and use command-line interfaces. You are generally familiar with blockchains and smart contract platforms.","title":"Before you begin"},{"location":"tutorials/01-build-local-blockchain/#tutorial-objectives","text":"By completing this tutorial, you will accomplish the following objectives: Set up a Substrate development environment on your computer. Install the node template to start a Substrate-based blockchain. Install a front-end template to interact with the local blockchain node. Use the front-end template to submit a transaction and view the result.","title":"Tutorial objectives"},{"location":"tutorials/01-build-local-blockchain/#install-required-packages","text":"Substrate development is easiest on UNIX-based operating systems like macOS or Linux. If you are using Microsoft Windows, refer to the Windows installation page . To install required packages on macOS or Linux: Open a terminal shell on your computer. Locate your operating system in the following table and run the appropriate commands for your development environment. OS Installation commands Ubuntu or Debian sudo apt update && sudo apt install -y git clang curl libssl-dev llvm libudev-dev Arch Linux pacman -Syu --needed --noconfirm curl git clang Fedora sudo dnf update sudo dnf install clang curl git openssl-devel OpenSUSE sudo zypper install clang curl git openssl-devel llvm-devel libudev-devel macOS brew update && brew install openssl Windows Refer to this installation guide . If you are using macOS and do not have Homebrew installed, run the following command to install Homebrew: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" After installing Homebrew, run brew install openssl .","title":"Install required packages"},{"location":"tutorials/01-build-local-blockchain/#install-rust-and-the-rust-toolchain","text":"To install and configure Rust manually: Install rustup by running the following command: bash curl https://sh.rustup.rs -sSf | sh Configure your current shell to reload your PATH environment variable so that it includes the Cargo bin directory by running the following command: bash source ~/.cargo/env Configure the Rust toolchain to default to the latest stable version by running the following commands: bash rustup default stable rustup update Add the nightly release and the nightly WebAssembly ( wasm ) targets by running the following commands: bash rustup update nightly rustup target add wasm32-unknown-unknown --toolchain nightly Verify your installation by running the following commands: bash rustc --version rustup show The previous steps walked you through the installation and configuration of Rust and the Rust toolchain so that you could see the full process for yourself. It is also possible to automate the steps using a script. If you want to try installing and configuring Rust using a script, see the getsubstrate automation script.","title":"Install Rust and the Rust toolchain"},{"location":"tutorials/01-build-local-blockchain/#set-up-a-development-environment","text":"After you install the required packages and the Rust compiler and toolchain, you are ready to set up a development environment on your local computer. You could build a development environment manually using the tools of your choice, but the Substrate Developer Hub has templates to get you started. After you set up the development environment, you can use it in subsequent tutorials as you learn more about building on Substrate.","title":"Set up a development environment"},{"location":"tutorials/01-build-local-blockchain/#prepare-a-substrate-node","text":"The Substrate node template provides a working development environment so that you can start building on Substrate right away. To compile the Substrate node template: Clone the node template repository using the version latest branch by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-node-template Change to the root of the node template directory by running the following command: bash cd substrate-node-template Compile the node template by running the following command: bash cargo build --release You should always use the --release flag to build optimized artifacts.","title":"Prepare a Substrate node"},{"location":"tutorials/01-build-local-blockchain/#install-the-front-end-template","text":"The front-end template uses ReactJS to render a web browser interface that enables you to interact with the Substrate-based blockchain node. You can use this Front-end template as a starting point for creating user interfaces for your own projects in future. The front-end template requires Yarn and Node.js . If you don't have these tools, install them first. To install the front-end template: Check whether node is installed on your local computer by running the following command: bash node --version If the command doesn\u2019t return a version number, download and install node by following the instructions for the operating system you use on the Node.js website. The node version should be at least v14 to run the front-end template. Check whether yarn is installed on your local computer by running the following command: bash yarn --version The yarn version should be at least v3 to run the front-end template. If the command doesn\u2019t return a version number, download and install yarn by running the following command: bash npm install -g yarn Clone the front-end template repository by running the following command: bash git clone https://github.com/substrate-developer-hub/substrate-front-end-template Change to the root of the front-end template directory by running the following command: bash cd substrate-front-end-template Install the dependencies for the front-end template by running the following command: bash yarn install","title":"Install the front-end template"},{"location":"tutorials/01-build-local-blockchain/#start-the-local-node","text":"After your node compiles, you are ready to start exploring what it does using the front-end template. To start the local Substrate node: Open a terminal shell. Change to the root directory where you compiled the Substrate node template. Start the node in development mode by running the following command: bash ./target/release/node-template --dev The node-template command-line options specify how you want the running node to operate. In this case, the --dev option specifies that the node runs in developer mode using the predefined development chain specification. By default, this option also deletes all active data\u2014such as keys, the blockchain database, and networking information when you stop the node by pressing Control-c. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify your node is up and running successfully by reviewing the output displayed in the terminal. The terminal should display output similar to this: bash 2021-11-24 15:36:35 Running in --dev mode, RPC CORS has been disabled. 2021-11-24 15:36:35 Substrate Node 2021-11-24 15:36:35 \u270c\ufe0f version 4.0.0-dev-82b7c2c-aarch64-macos 2021-11-24 15:36:35 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-11-24 15:36:35 \ud83d\udccb Chain specification: Development 2021-11-24 15:36:35 \ud83c\udff7 Node name: six-wash-9274 2021-11-24 15:36:35 \ud83d\udc64 Role: AUTHORITY 2021-11-24 15:36:35 \ud83d\udcbe Database: RocksDb at /tmp/substrateP1jD7H/chains/dev/db 2021-11-24 15:36:35 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-11-24 15:36:35 \ud83d\udd28 Initializing Genesis block/state (state: 0xa59b\u20265331, header-hash: 0xc5d2\u202637f3) 2021-11-24 15:36:35 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-11-24 15:36:35 \u23f1 Loaded block-time = 6s from block 0xc5d2fdad35e14684753f087c1a20f022274e154d39add4f7efe34e95476a37f3 2021-11-24 15:36:35 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-11-24 15:36:35 \ud83c\udff7 Local node identity is: 12D3KooWG5niQF5bjsFao3D8DZRpUUB6uWZC2pK8hCDZ94zsr8Sc 2021-11-24 15:36:35 \ud83d\udce6 Highest known block at #0 ... ... ... 2021-11-24 15:36:40 \ud83d\udca4 Idle (0 peers), best: #1 (0xd2b5\u2026d03f), finalized #0 (0xc5d2\u202637f3), \u2b07 0 \u2b06 0 If the number after finalized is increasing, your blockchain is producing new blocks and reaching consensus about the state they describe. We'll explore the details of the log output in a later tutorial. For now, it's only important to know that your node is running and producing blocks. Keep the terminal that displays the node output open to continue.","title":"Start the local node"},{"location":"tutorials/01-build-local-blockchain/#start-the-front-end-template","text":"The Substrate front-end template consists of user interface components to enable you to interact with the Substrate node and perform a few common tasks. To use the front-end template: Open a new terminal shell on your computer, change to the root directory where you installed the front-end template. Start the front-end template by running the following command: bash yarn start Open http://localhost:8000 in a browser to view the front-end template. The top section has an Account selection list for selecting the account to work with when you want to perform on-chain operations. The top section of the template also displays information about the chain to which you're connected. You might also notice that the front-end template displays a Balances table with some predefined accounts and that a few of those accounts are preconfigured with funds. You can use this sample data to try out operations like transferring funds.","title":"Start the front-end template"},{"location":"tutorials/01-build-local-blockchain/#transfer-funds-from-an-account","text":"Now that you have a blockchain node running on your local computer and you have a front-end template available for performing on-chain operations, you are ready to explore different ways to interact with the blockchain. By default, the front-end template includes several components that allow you to try different common tasks. For this tutorial, you can perform a simple transfer operation that moves funds from one account to another. To transfer funds to an account: In the Balances table, notice the predefined accounts\u2014such as dave\u2014that have no funds associated with them. Under the Balances table, the front-end template also displays a Transfer component. You use this component to transfer funds from one account to another. Copy and paste the address for the dave account to specify the address to which you are transferring funds. Specify at least 1000000000000 as the amount to transfer, then click Submit . Notice that the values in Balances table is updated with the transfer. Check the Events component to see events related to the transfer you just completed. The Substrate blockchain reports the result of asynchronous operations as events, so you can use the Events components to see details about each operation performed as part of the transfer. For example: When the transaction has been completed and included in a block, you see a confirmation message similar to the following: \ud83d\ude09 Finalized. Block hash: 0xda7e9e935abf5a3a2fdb0a27d67cd7a69e628165b5827255af2635ba226411a4","title":"Transfer funds from an account"},{"location":"tutorials/01-build-local-blockchain/#stop-the-local-node","text":"After a successful transfer, you can continue to explore the front-end template components or stop the local Substrate node the state changes you made. Because you specified the --dev option when you started the node, stopping the local node stops the blockchain and purges all persistent block data so that you can start with a clean state next time you start the node. To stop the local Substrate node: Return to the terminal shell where the node output is displayed. Press Control-c to terminate the running process. Verify your terminal returns to the terminal prompt in the substrate-node-template directory.","title":"Stop the local node"},{"location":"tutorials/01-build-local-blockchain/#next-steps","text":"Congratulations! In this tutorial, you learned: How to start a working Substrate-based blockchain node using the node. How to view and interact with the blockchain node using a front-end user interface. How to make a simple transfer from one account to another. The front-end template includes several additional components for you to experiment with while you're connected to a local development node. You can explore these components on your own or learn more in the following topics: Explore blockchain metadata . Call extrinsic functions . Add a new pallet . Upgrade the runtime . If you experienced any issues with this tutorial or want to provide feedback: Ask questions on Stack Overflow tagged substrate . Contact the Substrate community on Element .","title":"Next steps"},{"location":"tutorials/02-simulate-network/","text":"This tutorial provides a basic introduction to how to start a private blockchain network with an authority set of private validators . The Substrate node template uses an authority consensus model that limits block production to a rotating list of authorized accounts. The authorized accounts\u2014 authorities \u2014are responsible for creating blocks in a round robin fashion. In this tutorial, you'll see how the authority consensus model works in practice by using two predefined accounts as the authorities that enable the nodes to produce blocks. In this simulated network, the two nodes are started using different accounts and keys but run on a single computer. Before you begin Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed Build a local blockchain and have the Substrate node template installed locally. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms. Tutorial objectives By completing this tutorial, you will accomplish the following objectives: Start a blockchain node using using a predefined account. Learn the key command-line options used to start a node. Determine if a node is running and producing blocks. Connect a second node to a running network. Verify peer computers produce and finalize blocks. Start the first blockchain node Before you generate keys to start your own private Substrate network, you can learn the fundamental principles using a predefined network specification called local and running under predefined user accounts. This tutorial simulates a private network by running two Substrate nodes on a single local computer using predefined accounts that are named alice and bob . To start the blockchain: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data by running the following command: ./target/release/node-template purge-chain --base-path /tmp/alice --chain local The command prompts you to confirm the operation: bash Are you sure to remove \"/tmp/alice/chains/local_testnet/db\"? [y/N]: Type y to confirm that you want to remove the chain data. You should always remove old chain data when starting a new network. Start the local blockchain node using the alice account by running the following command: ./target/release/node-template \\ --base-path /tmp/alice \\ --chain local \\ --alice \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --node-key 0000000000000000000000000000000000000000000000000000000000000001 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator Review the command-line options Before moving on, have a look at how the following options are used to start the node template. : Option : Description --base-path Specifies the directory for storing all of the data related to this chain. --chain local Specifies the chain specification to use. Valid predefined chain specifications include local , development , and staging . --alice Adds the predefined keys for the alice account to the node's keystore. With this setting, the alice account is used for block production and finalization. --port 30333 Specifies the port to listen on for peer-to-peer ( p2p ) traffic. Because this tutorial uses two nodes running on the same physical computer to simulate a network, you must explicitly specify a different port for at least one account. --ws-port 9945 Specifies the port to listen on for incoming WebSocket traffic. The default port is 9944 . This tutorial uses a custom web socket port number ( 9945 ). --rpc-port 9933 Specifies the port to listen on for incoming RPC traffic. The default port is 9933 . --node-key <key> Specifies the Ed25519 secret key to use for libp2p networking. You should only use this option for development and testing. --telemetry-url Specifies where to send telemetry data. For this tutorial, you can send telemetry data to a server hosted by Parity that is available for anyone to use. --validator Specifies that this node participates in block production and finalization for the network. For more information about the command-line options that are available for the node template, see the usage help by running the following command: ./target/release/node-template --help Review the node messages displayed If the node starts successfully, the terminal displays messages describing network operations. For example, you should see output similar to this: 2021-03-10 17:34:27 Substrate Node 2021-03-10 17:34:27 \u270c\ufe0f version 3.0.0-1c5b984-x86_64-linux-gnu 2021-03-10 17:34:27 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-03-10 17:34:27 \ud83d\udccb Chain specification: Local Testnet 2021-03-10 17:34:27 \ud83c\udff7 Node name: Alice 2021-03-10 17:34:27 \ud83d\udc64 Role: AUTHORITY 2021-03-10 17:34:27 \ud83d\udcbe Database: RocksDb at /tmp/alice/chains/local_testnet/db 2021-03-10 17:34:27 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-03-10 17:34:27 \ud83d\udd28 Initializing Genesis block/state (state: 0xea47\u20269ba8, header-hash: 0x9d07\u20267cce) 2021-03-10 17:34:27 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-03-10 17:34:27 \u23f1 Loaded block-time = 6000 milliseconds from genesis on first-launch 2021-03-10 17:34:27 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-03-10 17:34:27 \ud83c\udff7 Local node identity is: 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:34:27 \ud83d\udce6 Highest known block at #0 2021-03-10 17:34:27 \u303d\ufe0f Prometheus server started at 127.0.0.1:9615 2021-03-10 17:34:27 Listening for new connections on 127.0.0.1:9945. 2021-03-10 17:34:32 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 2021-03-10 17:34:37 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 ... In particular, you should note the following messages in the output: \ud83d\udd28 Initializing Genesis block/state (state: 0xea47\u20269ba8, header-hash: 0x9d07\u20267cce) identifies the initial or genesis block that the node is using. When you start the next node, verify that these values are the same. \ud83c\udff7 Local node identity is: 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp specifies a string that uniquely identifies this node. This string is determined by the --node-key that was used to start the node using the alice account. You use this string to identify the node to connect to when you start a second node. 2021-03-10 17:34:37 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 indicates that there are no other nodes in the network and that no blocks are being produced. Another node must join the network before blocks can start to be produced. Add a second node to the blockchain network Now that the node you started using the alice account keys is running, you can add another node to the network using the bob account. Because you are joining a network that is already running, you can use the running node to identify the network for the new node to join. The commands are similar to the ones you used before, but with a few important differences. To add a node to the running blockchain: Open a new terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data by running the following command: ./target/release/node-template purge-chain --base-path /tmp/bob --chain local -y By adding -y to the command, you can remove chain data without being prompted you to confirm the operation. Start a second local blockchain node using the bob account by running the following command: ./target/release/node-template \\ --base-path /tmp/bob \\ --chain local \\ --bob \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp Note the following differences between this command and the previous one: Because the two nodes are running on the same physical computer, you must specify different values for the --base-path , --port , --ws-port , and --rpc-port options. This command includes the --bootnodes option and specifies a single boot node, the node started by alice . The --bootnodes option specifies the following information: ip4 indicates that the IP address for the node uses the IPv4 format 127.0.0.1 specifies the IP address for the running node. In this case, the address for the localhost . tcp specifies TCP as the protocol used for peer-to-peer communication. 30333 specifies the port number used for peer-to-peer communication. In this case, the port number for TCP traffic. 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp identifies the running node to communicate with for this network. In this case, the identifier for the node started using the alice account. Verify blocks are produced and finalized After you start the second node, the nodes should connect to each other as peers and start producing blocks. To verify blocks are being finalized: Verify that you see lines similar to the following in the terminal where you started the first node: bash 2021-03-10 17:47:32 \ud83d\udd0d Discovered new external address for our node: /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:47:32 \ud83d\udd0d Discovered new external address for our node: /ip4/<your-computer-LAN-IP>/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:47:33 \ud83d\udca4 Idle (1 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 1.0kiB/s \u2b06 1.0kiB/s 2021-03-10 17:47:36 \ud83d\ude4c Starting consensus session on top of parent 0x9d07d1757a9ca248e58141ce52a11fca37f71007dec16650b87a853f0d4c7cce 2021-03-10 17:47:36 \ud83c\udf81 Prepared block for proposing at 1 [hash: 0x727826a5e6fba9a13af11422d4677b5f0743cc733c382232328e69fd307d1d2f; parent_hash: 0x9d07\u20267cce; extrinsics (1): [0x768a\u2026a9e2]] 2021-03-10 17:47:36 \ud83d\udd16 Pre-sealed block for proposal at 1. Hash now 0x4841d8b2e62483fa4702b3ddcd1b603803842374dcdc1e9533ad407708b33dd8, previously 0x727826a5e6fba9a13af11422d4677b5f0743cc733c382232328e69fd307d1d2f. 2021-03-10 17:47:36 \u2728 Imported #1 (0x4841\u20263dd8) 2021-03-10 17:47:36 \u2728 Imported #1 (0xb241\u20262ae8) 2021-03-10 17:47:38 \ud83d\udca4 Idle (1 peers), best: #1 (0x4841\u20263dd8), finalized #0 (0x9d07\u20267cce), \u2b07 0.8kiB/s \u2b06 0.8kiB/s 2021-03-10 17:47:42 \u267b\ufe0f Reorg on #1,0x4841\u20263dd8 to #2,0x8b6a\u2026dce6, common ancestor #0,0x9d07\u20267cce 2021-03-10 17:47:42 \u2728 Imported #2 (0x8b6a\u2026dce6) 2021-03-10 17:47:43 \ud83d\udca4 Idle (1 peers), best: #2 (0x8b6a\u2026dce6), finalized #0 (0x9d07\u20267cce), \u2b07 0.8kiB/s \u2b06 0.7kiB/s 2021-03-10 17:47:48 \ud83d\ude4c Starting consensus session on top of parent 0x8b6a3ab2fe9891b1af008ea0d92dae9bc84cfa5578231e81066d47928822dce6 2021-03-10 17:47:48 \ud83c\udf81 Prepared block for proposing at 3 [hash: 0xb887aef2097eff5869e38ccec0302bce372ad05ac2cdf9cc4725c38ec071fb7a; parent_hash: 0x8b6a\u2026dce6; extrinsics (1): [0x82ac\u20262f20]] 2021-03-10 17:47:48 \ud83d\udd16 Pre-sealed block for proposal at 3. Hash now 0x34d608dd8be6b82bef4a7aaae1ec80930a5c4b8cf9bdc99013410e91544f3a2a, previously 0xb887aef2097eff5869e38ccec0302bce372ad05ac2cdf9cc4725c38ec071fb7a. 2021-03-10 17:47:48 \u2728 Imported #3 (0x34d6\u20263a2a) 2021-03-10 17:47:48 \ud83d\udca4 Idle (1 peers), best: #3 (0x34d6\u20263a2a), finalized #0 (0x9d07\u20267cce), \u2b07 0.7kiB/s \u2b06 0.8kiB/s 2021-03-10 17:47:53 \ud83d\udca4 Idle (1 peers), best: #3 (0x34d6\u20263a2a), finalized #1 (0xb241\u20262ae8), \u2b07 0.6kiB/s \u2b06 0.7kiB/s 2021-03-10 17:47:54 \u2728 Imported #4 (0x2b8a\u2026fdc4) 2021-03-10 17:47:58 \ud83d\udca4 Idle (1 peers), best: #4 (0x2b8a\u2026fdc4), finalized #2 (0x8b6a\u2026dce6), \u2b07 0.7kiB/s \u2b06 0.6kiB/s ... In these lines, you can see the following information aout your blockchain: The first node was started by alice . The node has a one peer ( 1 peers ). The nodes have produced some blocks ( best: #4 (0x2b8a\u2026fdc4) ). The blocks are being finalized ( finalized #2 (0x8b6a\u2026dce6) ). Verify that you see similar output in the terminal where you started the second node. Shut down both nodes by pressing Control-c in each terminal shell. Next steps This tutorial introduced the first basic steps for starting a private blockchain network. In this tutorial, you simulated the private network by running two nodes on a single computer and using predefined accounts as participants. You learned: How to use several of the node template commands and command-line options. How to start two blockchain nodes that communicate with each other as peers. How to verify your private blockchain nodes are producing blocks. The next tutorial builds on the information you learned in this tutorial to illustrate how you can start a private network with other participants and nodes running on separate computers. In Start a private network , you'll learn: How to generate your own secret key pairs. How to create a custom chain specification that uses the keys you generated. How to add validators to a private network that uses your custom chain specification.","title":"Simulate a network"},{"location":"tutorials/02-simulate-network/#before-you-begin","text":"Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed Build a local blockchain and have the Substrate node template installed locally. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms.","title":"Before you begin"},{"location":"tutorials/02-simulate-network/#tutorial-objectives","text":"By completing this tutorial, you will accomplish the following objectives: Start a blockchain node using using a predefined account. Learn the key command-line options used to start a node. Determine if a node is running and producing blocks. Connect a second node to a running network. Verify peer computers produce and finalize blocks.","title":"Tutorial objectives"},{"location":"tutorials/02-simulate-network/#start-the-first-blockchain-node","text":"Before you generate keys to start your own private Substrate network, you can learn the fundamental principles using a predefined network specification called local and running under predefined user accounts. This tutorial simulates a private network by running two Substrate nodes on a single local computer using predefined accounts that are named alice and bob . To start the blockchain: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data by running the following command: ./target/release/node-template purge-chain --base-path /tmp/alice --chain local The command prompts you to confirm the operation: bash Are you sure to remove \"/tmp/alice/chains/local_testnet/db\"? [y/N]: Type y to confirm that you want to remove the chain data. You should always remove old chain data when starting a new network. Start the local blockchain node using the alice account by running the following command: ./target/release/node-template \\ --base-path /tmp/alice \\ --chain local \\ --alice \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --node-key 0000000000000000000000000000000000000000000000000000000000000001 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator","title":"Start the first blockchain node"},{"location":"tutorials/02-simulate-network/#review-the-command-line-options","text":"Before moving on, have a look at how the following options are used to start the node template. : Option : Description --base-path Specifies the directory for storing all of the data related to this chain. --chain local Specifies the chain specification to use. Valid predefined chain specifications include local , development , and staging . --alice Adds the predefined keys for the alice account to the node's keystore. With this setting, the alice account is used for block production and finalization. --port 30333 Specifies the port to listen on for peer-to-peer ( p2p ) traffic. Because this tutorial uses two nodes running on the same physical computer to simulate a network, you must explicitly specify a different port for at least one account. --ws-port 9945 Specifies the port to listen on for incoming WebSocket traffic. The default port is 9944 . This tutorial uses a custom web socket port number ( 9945 ). --rpc-port 9933 Specifies the port to listen on for incoming RPC traffic. The default port is 9933 . --node-key <key> Specifies the Ed25519 secret key to use for libp2p networking. You should only use this option for development and testing. --telemetry-url Specifies where to send telemetry data. For this tutorial, you can send telemetry data to a server hosted by Parity that is available for anyone to use. --validator Specifies that this node participates in block production and finalization for the network. For more information about the command-line options that are available for the node template, see the usage help by running the following command: ./target/release/node-template --help","title":"Review the command-line options"},{"location":"tutorials/02-simulate-network/#review-the-node-messages-displayed","text":"If the node starts successfully, the terminal displays messages describing network operations. For example, you should see output similar to this: 2021-03-10 17:34:27 Substrate Node 2021-03-10 17:34:27 \u270c\ufe0f version 3.0.0-1c5b984-x86_64-linux-gnu 2021-03-10 17:34:27 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-03-10 17:34:27 \ud83d\udccb Chain specification: Local Testnet 2021-03-10 17:34:27 \ud83c\udff7 Node name: Alice 2021-03-10 17:34:27 \ud83d\udc64 Role: AUTHORITY 2021-03-10 17:34:27 \ud83d\udcbe Database: RocksDb at /tmp/alice/chains/local_testnet/db 2021-03-10 17:34:27 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-03-10 17:34:27 \ud83d\udd28 Initializing Genesis block/state (state: 0xea47\u20269ba8, header-hash: 0x9d07\u20267cce) 2021-03-10 17:34:27 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-03-10 17:34:27 \u23f1 Loaded block-time = 6000 milliseconds from genesis on first-launch 2021-03-10 17:34:27 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-03-10 17:34:27 \ud83c\udff7 Local node identity is: 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:34:27 \ud83d\udce6 Highest known block at #0 2021-03-10 17:34:27 \u303d\ufe0f Prometheus server started at 127.0.0.1:9615 2021-03-10 17:34:27 Listening for new connections on 127.0.0.1:9945. 2021-03-10 17:34:32 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 2021-03-10 17:34:37 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 ... In particular, you should note the following messages in the output: \ud83d\udd28 Initializing Genesis block/state (state: 0xea47\u20269ba8, header-hash: 0x9d07\u20267cce) identifies the initial or genesis block that the node is using. When you start the next node, verify that these values are the same. \ud83c\udff7 Local node identity is: 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp specifies a string that uniquely identifies this node. This string is determined by the --node-key that was used to start the node using the alice account. You use this string to identify the node to connect to when you start a second node. 2021-03-10 17:34:37 \ud83d\udca4 Idle (0 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 0 \u2b06 0 indicates that there are no other nodes in the network and that no blocks are being produced. Another node must join the network before blocks can start to be produced.","title":"Review the node messages displayed"},{"location":"tutorials/02-simulate-network/#add-a-second-node-to-the-blockchain-network","text":"Now that the node you started using the alice account keys is running, you can add another node to the network using the bob account. Because you are joining a network that is already running, you can use the running node to identify the network for the new node to join. The commands are similar to the ones you used before, but with a few important differences. To add a node to the running blockchain: Open a new terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data by running the following command: ./target/release/node-template purge-chain --base-path /tmp/bob --chain local -y By adding -y to the command, you can remove chain data without being prompted you to confirm the operation. Start a second local blockchain node using the bob account by running the following command: ./target/release/node-template \\ --base-path /tmp/bob \\ --chain local \\ --bob \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp Note the following differences between this command and the previous one: Because the two nodes are running on the same physical computer, you must specify different values for the --base-path , --port , --ws-port , and --rpc-port options. This command includes the --bootnodes option and specifies a single boot node, the node started by alice . The --bootnodes option specifies the following information: ip4 indicates that the IP address for the node uses the IPv4 format 127.0.0.1 specifies the IP address for the running node. In this case, the address for the localhost . tcp specifies TCP as the protocol used for peer-to-peer communication. 30333 specifies the port number used for peer-to-peer communication. In this case, the port number for TCP traffic. 12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp identifies the running node to communicate with for this network. In this case, the identifier for the node started using the alice account.","title":"Add a second node to the blockchain network"},{"location":"tutorials/02-simulate-network/#verify-blocks-are-produced-and-finalized","text":"After you start the second node, the nodes should connect to each other as peers and start producing blocks. To verify blocks are being finalized: Verify that you see lines similar to the following in the terminal where you started the first node: bash 2021-03-10 17:47:32 \ud83d\udd0d Discovered new external address for our node: /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:47:32 \ud83d\udd0d Discovered new external address for our node: /ip4/<your-computer-LAN-IP>/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp 2021-03-10 17:47:33 \ud83d\udca4 Idle (1 peers), best: #0 (0x9d07\u20267cce), finalized #0 (0x9d07\u20267cce), \u2b07 1.0kiB/s \u2b06 1.0kiB/s 2021-03-10 17:47:36 \ud83d\ude4c Starting consensus session on top of parent 0x9d07d1757a9ca248e58141ce52a11fca37f71007dec16650b87a853f0d4c7cce 2021-03-10 17:47:36 \ud83c\udf81 Prepared block for proposing at 1 [hash: 0x727826a5e6fba9a13af11422d4677b5f0743cc733c382232328e69fd307d1d2f; parent_hash: 0x9d07\u20267cce; extrinsics (1): [0x768a\u2026a9e2]] 2021-03-10 17:47:36 \ud83d\udd16 Pre-sealed block for proposal at 1. Hash now 0x4841d8b2e62483fa4702b3ddcd1b603803842374dcdc1e9533ad407708b33dd8, previously 0x727826a5e6fba9a13af11422d4677b5f0743cc733c382232328e69fd307d1d2f. 2021-03-10 17:47:36 \u2728 Imported #1 (0x4841\u20263dd8) 2021-03-10 17:47:36 \u2728 Imported #1 (0xb241\u20262ae8) 2021-03-10 17:47:38 \ud83d\udca4 Idle (1 peers), best: #1 (0x4841\u20263dd8), finalized #0 (0x9d07\u20267cce), \u2b07 0.8kiB/s \u2b06 0.8kiB/s 2021-03-10 17:47:42 \u267b\ufe0f Reorg on #1,0x4841\u20263dd8 to #2,0x8b6a\u2026dce6, common ancestor #0,0x9d07\u20267cce 2021-03-10 17:47:42 \u2728 Imported #2 (0x8b6a\u2026dce6) 2021-03-10 17:47:43 \ud83d\udca4 Idle (1 peers), best: #2 (0x8b6a\u2026dce6), finalized #0 (0x9d07\u20267cce), \u2b07 0.8kiB/s \u2b06 0.7kiB/s 2021-03-10 17:47:48 \ud83d\ude4c Starting consensus session on top of parent 0x8b6a3ab2fe9891b1af008ea0d92dae9bc84cfa5578231e81066d47928822dce6 2021-03-10 17:47:48 \ud83c\udf81 Prepared block for proposing at 3 [hash: 0xb887aef2097eff5869e38ccec0302bce372ad05ac2cdf9cc4725c38ec071fb7a; parent_hash: 0x8b6a\u2026dce6; extrinsics (1): [0x82ac\u20262f20]] 2021-03-10 17:47:48 \ud83d\udd16 Pre-sealed block for proposal at 3. Hash now 0x34d608dd8be6b82bef4a7aaae1ec80930a5c4b8cf9bdc99013410e91544f3a2a, previously 0xb887aef2097eff5869e38ccec0302bce372ad05ac2cdf9cc4725c38ec071fb7a. 2021-03-10 17:47:48 \u2728 Imported #3 (0x34d6\u20263a2a) 2021-03-10 17:47:48 \ud83d\udca4 Idle (1 peers), best: #3 (0x34d6\u20263a2a), finalized #0 (0x9d07\u20267cce), \u2b07 0.7kiB/s \u2b06 0.8kiB/s 2021-03-10 17:47:53 \ud83d\udca4 Idle (1 peers), best: #3 (0x34d6\u20263a2a), finalized #1 (0xb241\u20262ae8), \u2b07 0.6kiB/s \u2b06 0.7kiB/s 2021-03-10 17:47:54 \u2728 Imported #4 (0x2b8a\u2026fdc4) 2021-03-10 17:47:58 \ud83d\udca4 Idle (1 peers), best: #4 (0x2b8a\u2026fdc4), finalized #2 (0x8b6a\u2026dce6), \u2b07 0.7kiB/s \u2b06 0.6kiB/s ... In these lines, you can see the following information aout your blockchain: The first node was started by alice . The node has a one peer ( 1 peers ). The nodes have produced some blocks ( best: #4 (0x2b8a\u2026fdc4) ). The blocks are being finalized ( finalized #2 (0x8b6a\u2026dce6) ). Verify that you see similar output in the terminal where you started the second node. Shut down both nodes by pressing Control-c in each terminal shell.","title":"Verify blocks are produced and finalized"},{"location":"tutorials/02-simulate-network/#next-steps","text":"This tutorial introduced the first basic steps for starting a private blockchain network. In this tutorial, you simulated the private network by running two nodes on a single computer and using predefined accounts as participants. You learned: How to use several of the node template commands and command-line options. How to start two blockchain nodes that communicate with each other as peers. How to verify your private blockchain nodes are producing blocks. The next tutorial builds on the information you learned in this tutorial to illustrate how you can start a private network with other participants and nodes running on separate computers. In Start a private network , you'll learn: How to generate your own secret key pairs. How to create a custom chain specification that uses the keys you generated. How to add validators to a private network that uses your custom chain specification.","title":"Next steps"},{"location":"tutorials/03-private-network/","text":"This tutorial illustrates how you can start a small, standalone blockchain network with an authority set of private validators . As you learned in Blockchain basics , all blockchains require the nodes in the network to agree on the state of data at any specific point in time and this agreement about the state is called consensus . The Substrate node template uses a proof of authority consensus model also referred to as authority round or Aura consensus. The Aura consensus protocol limits block production to a rotating list of authorized accounts. The authorized accounts\u2014 authorities \u2014create blocks in a round robin fashion and are generally considered to be trusted participants in the network. This consensus model provides a simple approach to starting a solo blockchain for a limited number of participants. In this tutorial, you'll see how to generate the keys required to authorize a node to participate in the network, how to configure and share information about the network with other authorized accounts, and how to launch the network with an approved set of validators. Before you begin Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed Build a local blockchain and have the Substrate node template installed locally. You have used predefined accounts as described in Simulate a private two-node network to start nodes on a single computer. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms. Tutorial objectives By completing this tutorial, you will accomplish the following objectives: Generate key pairs for use as a network authority. Create a custom chain specification file. Launch a private two-node blockchain network. Generate your account and keys Now that you know how to start and connect running nodes as peers using command-line options, you are ready to generate your own secret keys instead of using the predefined account keys. It's important to remember that each participant in the blockchain network is responsible for generating unique keys. Key generation options There are several ways you can generate keys. For example, you can generate key pairs using a node-template subcommand, the standalone Subkey command-line program, the Polkadot-JS application, or third-party key generation utilities. Although you could use predefined key pairs to complete this tutorial, you would never use those keys in a production environment. Instead of using predefined keys or the more secure subkey program, this tutorial illustrates how to generate keys using the Substrate node template and the key subcommand. Generate local keys using the node template You have already used the some command-line options to start your local blockchain node using the predefined alice and bob accounts. You can also use command-line options to generate random keys to use with Substrate. For this tutorial, you can remain connected to the internet and use your local node to generate your keys. As a best practice, you should use an air-gapped computer that has never been connected to the internet when you generate keys for a production blockchain. At a minimum, you should disconnect from the internet before you generate any keys you intend to use on a public or private blockchain that is not under your control. To generate keys using the node template: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Generate a random secret phrase and keys by running the following command: ./target/release/node-template key generate --scheme Sr25519 --password-interactive Type a password for the generated keys. The command generates keys and displays output similar to the following: Secret phrase: pig giraffe ceiling enter weird liar orange decline behind total despair fly Secret seed: 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Public key (hex): 0x1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Account ID: 0x1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Public key (SS58): 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW SS58 Address: 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW Use the secret seed for the account you generated to derive keys using the Ed25519 signature scheme by running the following command: ./target/release/node-template key inspect \\ --password-interactive --scheme Ed25519 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Type the password you used to the generated keys. The command displays output similar to the following: Secret Key URI 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f is account: Secret seed: 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Public key (hex): 0x2577ba03f47cdbea161851d737e41200e471cd7a31a5c88242a527837efc1e7b Account ID: 0x2577ba03f47cdbea161851d737e41200e471cd7a31a5c88242a527837efc1e7b Public key (SS58): 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN SS58 Address: 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN You now have the Sr25519 key for producing blocks using aura and the Ed25519 key for finalizing blocks using grandpa for one node. 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW for aura . 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN for grandpa . Generate or collect additional accounts and keys You can repeat the steps to generate a second key pair on another computer or you can recruit other participants to generate the accounts and keys required to join your private network. For this tutorial, the private network consists of just two nodes, so you need two sets of keys. For illustration purposes, the second set of keys used in this tutorial are: 5CXGP4oPXC1Je3zf5wEDkYeAqGcGXyKWSRX2Jm14GdME5Xc5 for aura . 5DpdMN4bVTMy67TfMMtinQTcUmLhZBWoWarHvEYPM4jYziqm for grandpa . If you recruit other participants to join your network, be sure to collect the Sr25519 key for producing blocks using aura and the Ed25519 key for finalizing blocks using grandpa for each participant you plan to authorize as a validator before continuing to the next step. Create a custom chain specification After you generate and collect the keys to use with your blockchain, you are ready to create a custom chain specification using those key then share your custom chain specification with trusted network participants that you are authorizing as validators. To enable others to participate in your blockchain network, you should ensure that they generate their own keys. If other participants have generated their key pairs, you can create a custom chain specification to replace the local chain specification that you used previously. For simplicity, the custom chain specification you create in this tutorial is a modified version of the local chain specification that illustrates how to create a two-node network. You can follow the same steps to add more nodes to the network if you have the required keys. Modify the local chain specification Instead of writing a completely new chain specification, you can modify the predefined local chain specification. To create a new chain specification based on the local specification: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Export the local chain specification to a file named customSpec.json by running the following command: bash ./target/release/node-template build-spec --disable-default-bootnode --chain local > customSpec.json If you open the customSpec.json file in a text editor, you would see that it contains several fields, including a large blob that contains the WebAssembly (Wasm) binary for the runtime you built using the cargo build --release command. Instead of viewing the entire file, you can preview the first and last few lines to see the fields you need to change. Preview the first few fields in the customSpec.json file by running the following command: bash head customSpec.json The command displays the first fields from the file. For example: bash { \"name\": \"Local Testnet\", \"id\": \"local_testnet\", \"chainType\": \"Local\", \"bootNodes\": [], \"telemetryEndpoints\": null, \"protocolId\": null, \"properties\": null, \"consensusEngine\": null, \"codeSubstitutes\": {}, Preview the last fields in the customSpec.json file by running the following command: bash tail -n 80 customSpec.json This command displays the last sections following the Wasm binary field, including the details for several of the pallets\u2014such as the sudo and balances pallets\u2014that are used in the runtime. Open the customSpec.json file in a text editor. Modify the name field to identify this chain specification as a custom chain specification. For example: json \"name\": \"My Custom Testnet\", Modify aura field to specify the nodes with the authority to create blocks by adding the Sr25519 SS58 address keys for each network participant. json \"aura\": { \"authorities\": [ \"5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW\", \"5CXGP4oPXC1Je3zf5wEDkYeAqGcGXyKWSRX2Jm14GdME5Xc5\" ] }, Modify the grandpa field to specify the nodes with the authority to finalize blocks by adding the Ed25519 SS58 address keys for each network participant. json \"grandpa\": { \"authorities\": [ [ \"5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN\", 1 ], [ \"5DpdMN4bVTMy67TfMMtinQTcUmLhZBWoWarHvEYPM4jYziqm\", 1 ] ] }, Note that there are two data values for the authorities field in the grandpa section. The first value is the address key. The second value is used to support weighted votes . In this example, each validator has a weight of 1 vote. Save your changes and close the file. Add validators As you have just seen, you can add and change the authority addresses in a chain specification by modifying the aura and grandpa sections. You can use this technique to add as many validators as you like. To add validators: Modify the aura section to include Sr25519 addresses. Modify the grandpa section to include Ed25519 addresses and a voting weight. Be sure to use unique keys for each validator. If two validators have the same keys, they produce conflicting blocks. For additional information about working with key pairs and signatures, see Public-Key cryptography . Convert the chain specification to use the raw format After you prepare a chain specification with the information you want to use, you must convert it into a raw specification before it can be used. The raw chain specification includes the same information as the unconverted specification. However, the raw chain specification also contains encoded storage keys that the node uses to reference the data in its local storage. Distributing a raw chain specification ensures that each node stores the data using the proper storage keys. To convert a chain specification to use the raw format: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Convert the customSpec.json chain specification to the raw format with the file name customSpecRaw.json by running the following command: bash ./target/release/node-template build-spec --chain=customSpec.json --raw --disable-default-bootnode > customSpecRaw.json Share the chain specification with others If you are creating a private blockchain network to share with other participants, ensure that only one person creates the chain specifiction and shares the resulting raw version of that specification\u2014for example, the customSpecRaw.json file\u2014with all of the other validators in the network. Because the Rust compiler produces optimized WebAssembly binaries that aren't deterministically reproducible, each person who generates the Wasm runtime produces a slightly different Wasm blob. To ensure determinism, all participants in the blockchain network must use exactly the same raw chain specification file. For more information about this issue, see Hunting down a non-determinism-bug in our Rust Wasm build . Prepare to launch the private network After you distribute the custom chain specification to all network participants, you're ready to launch your own private blockchain. The steps are similar to the steps you followed in Start the blockchain using predefined accounts . To continue with this part of the tutorial, you are no longer using a single physical computer or a single binary. To continue, verify the following: You have generated or collected the account keys for at least two authority accounts. You have updated your custom chain specification to include the keys for block production ( aura ) and block finalization ( grandpa ). You have converted your custom chain specification to raw format and distributed the raw chain specification to the nodes participating in the private network. If you have completed these steps, you are ready to start the first node in the private blockchain. Start the first blockchain node As the first participant in the private blockchain network, you are responsible for starting the first node, called the bootnode . To start the first node: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data, if needed, by running the following command: bash ./target/release/node-template purge-chain --base-path /tmp/node01 --chain local -y Start the first node using the custom chain specification by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node01 \\ --chain ./customSpecRaw.json \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode01 Note the following changes to the command you are running to start the node: Instead of the predefined --alice account, you are using your own keys. You'll add your keys to the keystore in a separate step. The --chain command-line option specifies the custom chain specification. The --name command-line option enables you to give your node a human-readable name in the telemetry UI. The --rpc-methods Unsafe command-line option allows you to continue the tutorial using an unsafe communication mode because your blockchain is not being used in a production setting. Before moving on, have a look at how the following options are used to start the node template. : Option : Description --base-path Specifies the directory for storing all of the data related to this chain. --chain Specifies the custom chain specification to use. --port | Specifies the port to listen on for peer-to-peer ( p2p`) traffic. --ws-port Specifies the port to listen on for incoming WebSocket traffic. --rpc-port Specifies the port to listen on for incoming RPC traffic. --telemetry-url Specifies where to send telemetry data. --validator Specifies that this node participates in block production and finalization for the network. --rpc-methods Specifies the RPC methods to allow. The Unsafe setting allows unsafe communication methods because this blockchain is not being used in a production setting. --name Specifies a human-readable name for the node that you can view in the telemetry user interface. For more information about the command-line options that are available for the node template, see the usage help by running the following command: ./target/release/node-template --help Verify that you see output similar to the following: bash 2021-11-03 15:32:14 Substrate Node 2021-11-03 15:32:14 \u270c\ufe0f version 3.0.0-monthly-2021-09+1-bf52814-x86_64-macos 2021-11-03 15:32:14 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-11-03 15:32:14 \ud83d\udccb Chain specification: My Custom Testnet 2021-11-03 15:32:14 \ud83c\udff7 Node name: MyNode01 2021-11-03 15:32:14 \ud83d\udc64 Role: AUTHORITY 2021-11-03 15:32:14 \ud83d\udcbe Database: RocksDb at /tmp/node01/chains/local_testnet/db 2021-11-03 15:32:14 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-11-03 15:32:15 \ud83d\udd28 Initializing Genesis block/state (state: 0x2bde\u20268f66, header-hash: 0x6c78\u202637de) 2021-11-03 15:32:15 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-11-03 15:32:15 \u23f1 Loaded block-time = 6s from block 0x6c78abc724f83285d1487ddcb1f948a2773cb38219c4674f84c727833be737de 2021-11-03 15:32:15 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-11-03 15:32:15 \ud83c\udff7 Local node identity is: 12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX 2021-11-03 15:32:15 \ud83d\udce6 Highest known block at #0 2021-11-03 15:32:15 \u303d\ufe0f Prometheus exporter started at 127.0.0.1:9615 2021-11-03 15:32:15 Listening for new connections on 127.0.0.1:9945. 2021-11-03 15:32:20 \ud83d\udca4 Idle (0 peers), best: #0 (0x6c78\u202637de), finalized #0 (0x6c78\u202637de), \u2b07 0 \u2b06 0 In the output, take note of the following information: The initial or genesis block that the node is using is (state: 0x2bde\u20268f66, header-hash: 0x6c78\u202637de) . When you start the next node, verify that these values are the same. The node identity is 12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX . The IP address is 127.0.0.1 . The peer-to-peer (p2p) port is --port = 30333 . These values are for this specific tutorial example. The values will be different for your node and you must provide the values for your node to other network participants to connect to the bootnode. Add keys to the keystore After you start the first node, no blocks are yet produced. The next step is to add two types of keys to the keystore for each node in the network. For each node: Add the aura authority keys to enable block production . Add the grandpa authority keys to enable block finalization . There are several ways you can insert keys into the keystore. For this tutorial, you can use the key subcommand to insert locally-generated secret keys. To insert keys into the keystore: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Insert the aura secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node01 \\ --chain customSpecRaw.json \\ --suri 0x563d22ef5f00e589e07445a3ad88bb92efaa897d7f73a4543d9ac87476434e65 \\ --password-interactive \\ --key-type aura This example uses the secret seed generated from the key subcommand into the keystore. You can also insert a key from a specified file location. For information about the command-line option available, run the following command: bash ./target/release/node-template key insert --help Insert the grandpa secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node01 \\ --chain customSpecRaw.json \\ --suri 0x563d22ef5f00e589e07445a3ad88bb92efaa897d7f73a4543d9ac87476434e65 \\ --password-interactive \\ --key-type gran Verify that your keys are in the keystore for node01 by running the following command: bash ls /tmp/node01/chains/local_testnet/keystore The command displays output similar to the following: bash 617572611441ddcb22724420b87ee295c6d47c5adff0ce598c87d3c749b776ba9a647f04 6772616e1441ddcb22724420b87ee295c6d47c5adff0ce598c87d3c749b776ba9a647f04 Enable other participants to join You can now allow other validators to join the network using the --bootnodes and --validator command-line options. To add a second validator to the private network: Open a terminal shell on a second computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data, if needed, by running the following command: bash ./target/release/node-template purge-chain --base-path /tmp/node02 --chain local -y Start a second blockchain node by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node02 \\ --chain ./customSpecRaw.json \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode02 \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX Be sure to set the correct bootnode identifier in the command. If you don't set the correct bootnode identifier, you see errors like this: \ud83d\udc94 The bootnode you want to connect to at ... provided a different peer ID than the one you expect: ... Note that the command includes the base-path and name command-line options plus an additional validator option to specify that this node is a validator for the private network. Also note that all validators must be using identical chain specifications to peer. Add the aura secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node02 \\ --chain customSpecRaw.json \\ --suri 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f \\ --password-interactive \\ --key-type aura Note that this command uses the second participant's secret key and that the aura key type is required to enable block production. Add the grandpa secret key generated from the key subcommand to the local keystore by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node02 \\ --chain customSpecRaw.json \\ --suri 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f \\ --password-interactive \\ --key-type gran Note that this command uses the second participant's secret key and that the gran key type is required to enable block finalization. Block finalization requires at least two-thirds of the validators to add their keys to their respective keystores. Because this network is configured with two validators in the chain specification, block finalization starts after the second node has added its keys. Verify that your keys are in the keystore for node02 by running the following command: bash ls /tmp/node02/chains/local_testnet/keystore The command displays output similar to the following: bash 617572611a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 6772616e1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Substrate nodes require a restart after inserting a grandpa key, so you must shut down and restart nodes before you see blocks being finalized. Shut down the node by pressing Control-c. Restart the second blockchain node by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node02 \\ --chain ./customSpecRaw.json \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url 'wss://telemetry.polkadot.io/submit/ 0' \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode02 \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX Note that the command includes the base-path and name command-line options plus an additional validator option to specify that this node is a validator for the private network. Also note that all validators must be using identical chain specifications to peer. Be sure to set the correct bootnode identifier in the command. If you don't set the correct bootnode identifier, you see errors like this: \ud83d\udc94 The bootnode you want to connect to at ... provided a different peer ID than the one you expect: ... After both nodes have added their keys to their respective keystores and been restarted, you should see the same genesis block and state root hashes. You should also see that each node has one peer ( 1 peers ), and they have produced a block proposal ( best: #2 (0xe111\u2026c084) ). After a few seconds, you should see new blocks being finalized. ```bash ``` Next steps You have now seen how you can start a private blockchain with trusted participants. In this tutorial you learned: How to start and stop peer blockchain nodes. How to generate your own secret key pairs. How to create a custom chain specification that uses the keys you generated. How to add validators to a private network that uses your custom chain specification. To learn more about the topics introduced in this tutorial, see the following sections: Executor for more information about the WebAssembly runtime that is a core component of the chain specification. Accounts and Key management for more information about key generation and storage options. Cryptography for more information about the signature schemes used for different keys.","title":"Start a trusted validator network"},{"location":"tutorials/03-private-network/#before-you-begin","text":"Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed Build a local blockchain and have the Substrate node template installed locally. You have used predefined accounts as described in Simulate a private two-node network to start nodes on a single computer. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms.","title":"Before you begin"},{"location":"tutorials/03-private-network/#tutorial-objectives","text":"By completing this tutorial, you will accomplish the following objectives: Generate key pairs for use as a network authority. Create a custom chain specification file. Launch a private two-node blockchain network.","title":"Tutorial objectives"},{"location":"tutorials/03-private-network/#generate-your-account-and-keys","text":"Now that you know how to start and connect running nodes as peers using command-line options, you are ready to generate your own secret keys instead of using the predefined account keys. It's important to remember that each participant in the blockchain network is responsible for generating unique keys.","title":"Generate your account and keys"},{"location":"tutorials/03-private-network/#key-generation-options","text":"There are several ways you can generate keys. For example, you can generate key pairs using a node-template subcommand, the standalone Subkey command-line program, the Polkadot-JS application, or third-party key generation utilities. Although you could use predefined key pairs to complete this tutorial, you would never use those keys in a production environment. Instead of using predefined keys or the more secure subkey program, this tutorial illustrates how to generate keys using the Substrate node template and the key subcommand.","title":"Key generation options"},{"location":"tutorials/03-private-network/#generate-local-keys-using-the-node-template","text":"You have already used the some command-line options to start your local blockchain node using the predefined alice and bob accounts. You can also use command-line options to generate random keys to use with Substrate. For this tutorial, you can remain connected to the internet and use your local node to generate your keys. As a best practice, you should use an air-gapped computer that has never been connected to the internet when you generate keys for a production blockchain. At a minimum, you should disconnect from the internet before you generate any keys you intend to use on a public or private blockchain that is not under your control. To generate keys using the node template: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Generate a random secret phrase and keys by running the following command: ./target/release/node-template key generate --scheme Sr25519 --password-interactive Type a password for the generated keys. The command generates keys and displays output similar to the following: Secret phrase: pig giraffe ceiling enter weird liar orange decline behind total despair fly Secret seed: 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Public key (hex): 0x1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Account ID: 0x1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Public key (SS58): 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW SS58 Address: 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW Use the secret seed for the account you generated to derive keys using the Ed25519 signature scheme by running the following command: ./target/release/node-template key inspect \\ --password-interactive --scheme Ed25519 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Type the password you used to the generated keys. The command displays output similar to the following: Secret Key URI 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f is account: Secret seed: 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f Public key (hex): 0x2577ba03f47cdbea161851d737e41200e471cd7a31a5c88242a527837efc1e7b Account ID: 0x2577ba03f47cdbea161851d737e41200e471cd7a31a5c88242a527837efc1e7b Public key (SS58): 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN SS58 Address: 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN You now have the Sr25519 key for producing blocks using aura and the Ed25519 key for finalizing blocks using grandpa for one node. 5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW for aura . 5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN for grandpa .","title":"Generate local keys using the node template"},{"location":"tutorials/03-private-network/#generate-or-collect-additional-accounts-and-keys","text":"You can repeat the steps to generate a second key pair on another computer or you can recruit other participants to generate the accounts and keys required to join your private network. For this tutorial, the private network consists of just two nodes, so you need two sets of keys. For illustration purposes, the second set of keys used in this tutorial are: 5CXGP4oPXC1Je3zf5wEDkYeAqGcGXyKWSRX2Jm14GdME5Xc5 for aura . 5DpdMN4bVTMy67TfMMtinQTcUmLhZBWoWarHvEYPM4jYziqm for grandpa . If you recruit other participants to join your network, be sure to collect the Sr25519 key for producing blocks using aura and the Ed25519 key for finalizing blocks using grandpa for each participant you plan to authorize as a validator before continuing to the next step.","title":"Generate or collect additional accounts and keys"},{"location":"tutorials/03-private-network/#create-a-custom-chain-specification","text":"After you generate and collect the keys to use with your blockchain, you are ready to create a custom chain specification using those key then share your custom chain specification with trusted network participants that you are authorizing as validators. To enable others to participate in your blockchain network, you should ensure that they generate their own keys. If other participants have generated their key pairs, you can create a custom chain specification to replace the local chain specification that you used previously. For simplicity, the custom chain specification you create in this tutorial is a modified version of the local chain specification that illustrates how to create a two-node network. You can follow the same steps to add more nodes to the network if you have the required keys.","title":"Create a custom chain specification"},{"location":"tutorials/03-private-network/#modify-the-local-chain-specification","text":"Instead of writing a completely new chain specification, you can modify the predefined local chain specification. To create a new chain specification based on the local specification: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Export the local chain specification to a file named customSpec.json by running the following command: bash ./target/release/node-template build-spec --disable-default-bootnode --chain local > customSpec.json If you open the customSpec.json file in a text editor, you would see that it contains several fields, including a large blob that contains the WebAssembly (Wasm) binary for the runtime you built using the cargo build --release command. Instead of viewing the entire file, you can preview the first and last few lines to see the fields you need to change. Preview the first few fields in the customSpec.json file by running the following command: bash head customSpec.json The command displays the first fields from the file. For example: bash { \"name\": \"Local Testnet\", \"id\": \"local_testnet\", \"chainType\": \"Local\", \"bootNodes\": [], \"telemetryEndpoints\": null, \"protocolId\": null, \"properties\": null, \"consensusEngine\": null, \"codeSubstitutes\": {}, Preview the last fields in the customSpec.json file by running the following command: bash tail -n 80 customSpec.json This command displays the last sections following the Wasm binary field, including the details for several of the pallets\u2014such as the sudo and balances pallets\u2014that are used in the runtime. Open the customSpec.json file in a text editor. Modify the name field to identify this chain specification as a custom chain specification. For example: json \"name\": \"My Custom Testnet\", Modify aura field to specify the nodes with the authority to create blocks by adding the Sr25519 SS58 address keys for each network participant. json \"aura\": { \"authorities\": [ \"5CfBuoHDvZ4fd8jkLQicNL8tgjnK8pVG9AiuJrsNrRAx6CNW\", \"5CXGP4oPXC1Je3zf5wEDkYeAqGcGXyKWSRX2Jm14GdME5Xc5\" ] }, Modify the grandpa field to specify the nodes with the authority to finalize blocks by adding the Ed25519 SS58 address keys for each network participant. json \"grandpa\": { \"authorities\": [ [ \"5CuqCGfwqhjGzSqz5mnq36tMe651mU9Ji8xQ4JRuUTvPcjVN\", 1 ], [ \"5DpdMN4bVTMy67TfMMtinQTcUmLhZBWoWarHvEYPM4jYziqm\", 1 ] ] }, Note that there are two data values for the authorities field in the grandpa section. The first value is the address key. The second value is used to support weighted votes . In this example, each validator has a weight of 1 vote. Save your changes and close the file.","title":"Modify the local chain specification"},{"location":"tutorials/03-private-network/#add-validators","text":"As you have just seen, you can add and change the authority addresses in a chain specification by modifying the aura and grandpa sections. You can use this technique to add as many validators as you like. To add validators: Modify the aura section to include Sr25519 addresses. Modify the grandpa section to include Ed25519 addresses and a voting weight. Be sure to use unique keys for each validator. If two validators have the same keys, they produce conflicting blocks. For additional information about working with key pairs and signatures, see Public-Key cryptography .","title":"Add validators"},{"location":"tutorials/03-private-network/#convert-the-chain-specification-to-use-the-raw-format","text":"After you prepare a chain specification with the information you want to use, you must convert it into a raw specification before it can be used. The raw chain specification includes the same information as the unconverted specification. However, the raw chain specification also contains encoded storage keys that the node uses to reference the data in its local storage. Distributing a raw chain specification ensures that each node stores the data using the proper storage keys. To convert a chain specification to use the raw format: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Convert the customSpec.json chain specification to the raw format with the file name customSpecRaw.json by running the following command: bash ./target/release/node-template build-spec --chain=customSpec.json --raw --disable-default-bootnode > customSpecRaw.json","title":"Convert the chain specification to use the raw format"},{"location":"tutorials/03-private-network/#share-the-chain-specification-with-others","text":"If you are creating a private blockchain network to share with other participants, ensure that only one person creates the chain specifiction and shares the resulting raw version of that specification\u2014for example, the customSpecRaw.json file\u2014with all of the other validators in the network. Because the Rust compiler produces optimized WebAssembly binaries that aren't deterministically reproducible, each person who generates the Wasm runtime produces a slightly different Wasm blob. To ensure determinism, all participants in the blockchain network must use exactly the same raw chain specification file. For more information about this issue, see Hunting down a non-determinism-bug in our Rust Wasm build .","title":"Share the chain specification with others"},{"location":"tutorials/03-private-network/#prepare-to-launch-the-private-network","text":"After you distribute the custom chain specification to all network participants, you're ready to launch your own private blockchain. The steps are similar to the steps you followed in Start the blockchain using predefined accounts . To continue with this part of the tutorial, you are no longer using a single physical computer or a single binary. To continue, verify the following: You have generated or collected the account keys for at least two authority accounts. You have updated your custom chain specification to include the keys for block production ( aura ) and block finalization ( grandpa ). You have converted your custom chain specification to raw format and distributed the raw chain specification to the nodes participating in the private network. If you have completed these steps, you are ready to start the first node in the private blockchain.","title":"Prepare to launch the private network"},{"location":"tutorials/03-private-network/#start-the-first-blockchain-node","text":"As the first participant in the private blockchain network, you are responsible for starting the first node, called the bootnode . To start the first node: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data, if needed, by running the following command: bash ./target/release/node-template purge-chain --base-path /tmp/node01 --chain local -y Start the first node using the custom chain specification by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node01 \\ --chain ./customSpecRaw.json \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode01 Note the following changes to the command you are running to start the node: Instead of the predefined --alice account, you are using your own keys. You'll add your keys to the keystore in a separate step. The --chain command-line option specifies the custom chain specification. The --name command-line option enables you to give your node a human-readable name in the telemetry UI. The --rpc-methods Unsafe command-line option allows you to continue the tutorial using an unsafe communication mode because your blockchain is not being used in a production setting. Before moving on, have a look at how the following options are used to start the node template. : Option : Description --base-path Specifies the directory for storing all of the data related to this chain. --chain Specifies the custom chain specification to use. --port | Specifies the port to listen on for peer-to-peer ( p2p`) traffic. --ws-port Specifies the port to listen on for incoming WebSocket traffic. --rpc-port Specifies the port to listen on for incoming RPC traffic. --telemetry-url Specifies where to send telemetry data. --validator Specifies that this node participates in block production and finalization for the network. --rpc-methods Specifies the RPC methods to allow. The Unsafe setting allows unsafe communication methods because this blockchain is not being used in a production setting. --name Specifies a human-readable name for the node that you can view in the telemetry user interface. For more information about the command-line options that are available for the node template, see the usage help by running the following command: ./target/release/node-template --help Verify that you see output similar to the following: bash 2021-11-03 15:32:14 Substrate Node 2021-11-03 15:32:14 \u270c\ufe0f version 3.0.0-monthly-2021-09+1-bf52814-x86_64-macos 2021-11-03 15:32:14 \u2764\ufe0f by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2021 2021-11-03 15:32:14 \ud83d\udccb Chain specification: My Custom Testnet 2021-11-03 15:32:14 \ud83c\udff7 Node name: MyNode01 2021-11-03 15:32:14 \ud83d\udc64 Role: AUTHORITY 2021-11-03 15:32:14 \ud83d\udcbe Database: RocksDb at /tmp/node01/chains/local_testnet/db 2021-11-03 15:32:14 \u26d3 Native runtime: node-template-100 (node-template-1.tx1.au1) 2021-11-03 15:32:15 \ud83d\udd28 Initializing Genesis block/state (state: 0x2bde\u20268f66, header-hash: 0x6c78\u202637de) 2021-11-03 15:32:15 \ud83d\udc74 Loading GRANDPA authority set from genesis on what appears to be first startup. 2021-11-03 15:32:15 \u23f1 Loaded block-time = 6s from block 0x6c78abc724f83285d1487ddcb1f948a2773cb38219c4674f84c727833be737de 2021-11-03 15:32:15 Using default protocol ID \"sup\" because none is configured in the chain specs 2021-11-03 15:32:15 \ud83c\udff7 Local node identity is: 12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX 2021-11-03 15:32:15 \ud83d\udce6 Highest known block at #0 2021-11-03 15:32:15 \u303d\ufe0f Prometheus exporter started at 127.0.0.1:9615 2021-11-03 15:32:15 Listening for new connections on 127.0.0.1:9945. 2021-11-03 15:32:20 \ud83d\udca4 Idle (0 peers), best: #0 (0x6c78\u202637de), finalized #0 (0x6c78\u202637de), \u2b07 0 \u2b06 0 In the output, take note of the following information: The initial or genesis block that the node is using is (state: 0x2bde\u20268f66, header-hash: 0x6c78\u202637de) . When you start the next node, verify that these values are the same. The node identity is 12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX . The IP address is 127.0.0.1 . The peer-to-peer (p2p) port is --port = 30333 . These values are for this specific tutorial example. The values will be different for your node and you must provide the values for your node to other network participants to connect to the bootnode.","title":"Start the first blockchain node"},{"location":"tutorials/03-private-network/#add-keys-to-the-keystore","text":"After you start the first node, no blocks are yet produced. The next step is to add two types of keys to the keystore for each node in the network. For each node: Add the aura authority keys to enable block production . Add the grandpa authority keys to enable block finalization . There are several ways you can insert keys into the keystore. For this tutorial, you can use the key subcommand to insert locally-generated secret keys. To insert keys into the keystore: Open a terminal shell on your computer. Change to the root directory where you compiled the Substrate node template. Insert the aura secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node01 \\ --chain customSpecRaw.json \\ --suri 0x563d22ef5f00e589e07445a3ad88bb92efaa897d7f73a4543d9ac87476434e65 \\ --password-interactive \\ --key-type aura This example uses the secret seed generated from the key subcommand into the keystore. You can also insert a key from a specified file location. For information about the command-line option available, run the following command: bash ./target/release/node-template key insert --help Insert the grandpa secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node01 \\ --chain customSpecRaw.json \\ --suri 0x563d22ef5f00e589e07445a3ad88bb92efaa897d7f73a4543d9ac87476434e65 \\ --password-interactive \\ --key-type gran Verify that your keys are in the keystore for node01 by running the following command: bash ls /tmp/node01/chains/local_testnet/keystore The command displays output similar to the following: bash 617572611441ddcb22724420b87ee295c6d47c5adff0ce598c87d3c749b776ba9a647f04 6772616e1441ddcb22724420b87ee295c6d47c5adff0ce598c87d3c749b776ba9a647f04","title":"Add keys to the keystore"},{"location":"tutorials/03-private-network/#enable-other-participants-to-join","text":"You can now allow other validators to join the network using the --bootnodes and --validator command-line options. To add a second validator to the private network: Open a terminal shell on a second computer. Change to the root directory where you compiled the Substrate node template. Purge old chain data, if needed, by running the following command: bash ./target/release/node-template purge-chain --base-path /tmp/node02 --chain local -y Start a second blockchain node by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node02 \\ --chain ./customSpecRaw.json \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url \"wss://telemetry.polkadot.io/submit/ 0\" \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode02 \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX Be sure to set the correct bootnode identifier in the command. If you don't set the correct bootnode identifier, you see errors like this: \ud83d\udc94 The bootnode you want to connect to at ... provided a different peer ID than the one you expect: ... Note that the command includes the base-path and name command-line options plus an additional validator option to specify that this node is a validator for the private network. Also note that all validators must be using identical chain specifications to peer. Add the aura secret key generated from the key subcommand by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node02 \\ --chain customSpecRaw.json \\ --suri 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f \\ --password-interactive \\ --key-type aura Note that this command uses the second participant's secret key and that the aura key type is required to enable block production. Add the grandpa secret key generated from the key subcommand to the local keystore by running a command similar to the following: bash ./target/release/node-template key insert --base-path /tmp/node02 \\ --chain customSpecRaw.json \\ --suri 0x0087016ebbdcf03d1b7b2ad9a958e14a43f2351cd42f2f0a973771b90fb0112f \\ --password-interactive \\ --key-type gran Note that this command uses the second participant's secret key and that the gran key type is required to enable block finalization. Block finalization requires at least two-thirds of the validators to add their keys to their respective keystores. Because this network is configured with two validators in the chain specification, block finalization starts after the second node has added its keys. Verify that your keys are in the keystore for node02 by running the following command: bash ls /tmp/node02/chains/local_testnet/keystore The command displays output similar to the following: bash 617572611a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 6772616e1a4cc824f6585859851f818e71ac63cf6fdc81018189809814677b2a4699cf45 Substrate nodes require a restart after inserting a grandpa key, so you must shut down and restart nodes before you see blocks being finalized. Shut down the node by pressing Control-c. Restart the second blockchain node by running the following command: bash ./target/release/node-template \\ --base-path /tmp/node02 \\ --chain ./customSpecRaw.json \\ --port 30334 \\ --ws-port 9946 \\ --rpc-port 9934 \\ --telemetry-url 'wss://telemetry.polkadot.io/submit/ 0' \\ --validator \\ --rpc-methods Unsafe \\ --name MyNode02 \\ --bootnodes /ip4/127.0.0.1/tcp/30333/p2p/12D3KooWLmrYDLoNTyTYtRdDyZLWDe1paxzxTw5RgjmHLfzW96SX Note that the command includes the base-path and name command-line options plus an additional validator option to specify that this node is a validator for the private network. Also note that all validators must be using identical chain specifications to peer. Be sure to set the correct bootnode identifier in the command. If you don't set the correct bootnode identifier, you see errors like this: \ud83d\udc94 The bootnode you want to connect to at ... provided a different peer ID than the one you expect: ... After both nodes have added their keys to their respective keystores and been restarted, you should see the same genesis block and state root hashes. You should also see that each node has one peer ( 1 peers ), and they have produced a block proposal ( best: #2 (0xe111\u2026c084) ). After a few seconds, you should see new blocks being finalized. ```bash ```","title":"Enable other participants to join"},{"location":"tutorials/03-private-network/#next-steps","text":"You have now seen how you can start a private blockchain with trusted participants. In this tutorial you learned: How to start and stop peer blockchain nodes. How to generate your own secret key pairs. How to create a custom chain specification that uses the keys you generated. How to add validators to a private network that uses your custom chain specification. To learn more about the topics introduced in this tutorial, see the following sections: Executor for more information about the WebAssembly runtime that is a core component of the chain specification. Accounts and Key management for more information about key generation and storage options. Cryptography for more information about the signature schemes used for different keys.","title":"Next steps"},{"location":"tutorials/07-add-a-pallet/","text":"As you saw Build a local blockchain , the Substrate node template provides a working runtime that includes some default FRAME development modules\u2014 pallets \u2014to get you started building a custom blockchain. This tutorial introduces the basic steps for adding a new pallet to the runtime for the node template. The steps are similar any time you want to add a new FRAME pallet to the runtime. However, each pallet requires specific configuration settings\u2014for example, the specific parameters and types required to perform the functions that the pallet implements. For this tutorial, you'll add the Nicks pallet to the runtime for the node template, so you'll see how to configure the settings that are specific to the Nicks pallet. The Nicks pallet allows blockchain users to pay a deposit to reserve a nickname for an account they control. It implements the following functions: The set_name function to collect a deposit and set the name of an account if the name is not already taken. The clear_name function to remove the name associated with an account and return the deposit. The kill_name function to forcibly remove an account name without returning the deposit. Note that this tutorial is a stepping stone to more advanced tutorials that illustrate how to add pallets with more complex configuration settings, how to create custom pallets, and how to publish pallets. Before you begin Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed the Build a local blockchain tutorial and have the Substrate node template installed locally. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms. Tutorial objectives By completing this tutorial, you will use the Nicks pallet to accomplish the following objectives: Learn how to update runtime dependencies to include a new pallet. Learn how to configure a pallet-specific Rust trait. See changes to the runtime by interacting with the new pallet using the front-end template. Add the Nicks pallet dependencies Before you can use a new pallet, you must add some information about it to the configuration file that the compiler uses to build the runtime binary. For Rust programs, you use the Cargo.toml file to define the configuration settings and dependencies that determine what gets compiled in the resulting binary. Because the Substrate runtime compiles to both a native Rust binary that includes standard library functions and a WebAssembly (Wasm) binary that does not include the standard library, the Cargo.toml file controls two important pieces of information: The pallets to be imported as dependencies for the runtime, including the location and version of the pallets to import. The features in each pallet that should be enabled when compiling the native Rust binary. By enabling the standard ( std ) feature set from each pallet, you can compile the runtime to include functions, types, and primitives that would otherwise be missing when you build the WebAssembly binary. For information about adding dependencies in Cargo.toml files, see Dependencies in the Cargo documentation. For information about enabling and managing features from dependent packages, see Features in the Cargo documentation. To add the dependencies for the Nicks pallet to the runtime: Open a terminal shell and change to the root directory for the node template. Open the runtime/Cargo.toml configuration file in a text editor. Import the pallet-nicks crate to make it available to the node template runtime by adding it to the list of dependencies. toml [dependencies.pallet-nicks] default-features = false git = 'https://github.com/paritytech/substrate.git' tag = 'monthly-2021-10' version = '4.0.0-dev' The first line imports the pallet-nicks crate as a dependency. The second line specifies that the pallet features are not enabled by default when compiling the runtime. The third line specifies the repository location for retrieving the pallet-nicks crate. The fourth line specifies a commit tag using the monthly-YYYY-MM naming convention for retrieving the crate. The fifth line specifies a version identifier for the crate. Add the pallet-nicks/std features to the list of features to enable when compiling the runtime. toml [features] default = ['std'] std = [ ... 'pallet-aura/std', 'pallet-balances/std', 'pallet-nicks/std', # add this line ... ] This section specifies the default feature set to compile for this runtime is the std features set. When the runtime is compiled using the std feature set, the std features from all of the pallets listed as dependencies are enabled. For more detailed information about how the runtime is compiled as a native Rust binary with the standard library and as a WebAssembly binary using the no_std attribute, see Building the runtime . If you forget to update the features section in the Cargo.toml file, you might see cannot find function errors when you compile the runtime binary. Check that the new dependencies resolve correctly by running the following command: bash cargo check -p node-template-runtime Review the configuration trait for the pallet Every pallet has a Rust trait called Config . The Config trait is used to identify the parameters and types that the pallet needs to carry out its functions. Most of the pallet-specific code required to add a pallet is implemented using the Config trait. You can review what you to need to implement for any pallet by referring to its Rust documentation or the source code for the pallet. For example, to see what you need to implement for the nicks pallet, you can refer to the Rust documentation for pallet_nicks::Config or the trait definition in the Nicks pallet source code . For this tutorial, you can see that the Config trait in the nicks pallet declares the following types: pub trait Config: frame_system::Config { /// The overarching event type. type Event: From<Event<Self>> + IsType<<Self as frame_system::Config>::Event>; /// The currency trait. type Currency: ReservableCurrency<Self::AccountId>; /// Reservation fee. #[pallet::constant] type ReservationFee: Get<BalanceOf<Self>>; /// What to do with slashed funds. type Slashed: OnUnbalanced<NegativeImbalanceOf<Self>>; /// The origin account that can forcibly set or remove a name. Root can always do this. type ForceOrigin: EnsureOrigin<Self::Origin>; /// The minimum length for a name. #[pallet::constant] type MinLength: Get<u32>; /// The maximum length for a name. #[pallet::constant] type MaxLength: Get<u32>; } After you identify the types your pallet requires, you need to add code to the runtime to implement the Config trait. To learn how to implement the Config trait for a pallet, you can use the Balances pallet \u2014which is already implemented in the node template runtime\u2014as an example. To review the Config trait for the Balances pallet: Open the runtime/src/lib.rs file in a text editor. Locate the Balances pallet section. Note that the implementation for the Balances pallet consists of two parts: The parameter_types! block where constant values are defined. rust parameter_types! { // The u128 constant value 500 is aliased to a type named ExistentialDeposit. pub const ExistentialDeposit: u128 = 500; // A heuristic that is used for weight estimation. pub const MaxLocks: u32 = 50; } The impl block where the types and values defined by the Config interface are configured. rust impl pallet_balances::Config for Runtime { // The previously defined parameter_type is used as a configuration parameter. type MaxLocks = MaxLocks; // The \"Balance\" that appears after the equal sign is an alias for the u128 type. type Balance = Balance; // The empty value, (), is used to specify a no-op callback function. type DustRemoval = (); // The previously defined parameter_type is used as a configuration parameter. type ExistentialDeposit = ExistentialDeposit; // The FRAME runtime system is used to track the accounts that hold balances. type AccountStore = System; // Weight information is supplied to the Balances pallet by the node template runtime. // type WeightInfo = (); // old way type WeightInfo = pallet_balances::weights::SubstrateWeight<Runtime>; // The ubiquitous event type. type Event = Event; } As you can see in this example, the impl pallet_balances::Config block allows you to configure the types and parameters that are specified by the Balances pallet Config trait. For example, this impl block configures the Balances pallet to use the u128 type to track balances. Implement the Config trait for the pallet Now that you have seen an example of how the Config trait is implemented for the Balances pallet, you're ready to implement the Config trait for the Nicks pallet. To implement the nicks pallet in your runtime: Open the runtime/src/lib.rs file in a text editor. Locate the last line of the Balances code block. Add the following code block for the Nicks pallet: ```rust /// Add this code block to your template for Nicks: parameter_types! { // Choose a fee that incentivizes desireable behavior. pub const NickReservationFee: u128 = 100; pub const MinNickLength: u32 = 8; // Maximum bounds on storage are important to secure your chain. pub const MaxNickLength: u32 = 32; } impl pallet_nicks::Config for Runtime { // The Balances pallet implements the ReservableCurrency trait. // Balances is defined in construct_runtime! macro. See below. // https://docs.substrate.io/rustdocs/latest/pallet_balances/index.html#implementations-2 type Currency = Balances; // Use the NickReservationFee from the parameter_types block. type ReservationFee = NickReservationFee; // No action is taken when deposits are forfeited. type Slashed = (); // Configure the FRAME System Root origin as the Nick pallet admin. // https://docs.substrate.io/rustdocs/latest/frame_system/enum.RawOrigin.html#variant.Root type ForceOrigin = frame_system::EnsureRoot<AccountId>; // Use the MinNickLength from the parameter_types block. type MinLength = MinNickLength; // Use the MaxNickLength from the parameter_types block. type MaxLength = MaxNickLength; // The ubiquitous event type. type Event = Event; } ``` Identify the types that the Nicks pallet exposes. You can find a complete list of types in the construct_runtime! macro documentation. The Nicks pallet uses the following types: Storage because it uses the #[pallet::storage] macro. Event because it uses the #[pallet::events] macro. In the nicks pallet, the Event keyword is parameterized with respect to a type because at least one of the events defined by the Nicks pallet depends on a type that is configured with the Config configuration trait. Call because it has dispatchable functions in the #[pallet::call] macro. Pallet because it uses the #[pallet::pallet] macro. Add Nicks to the construct_runtime! macro. For example: ```rust construct_runtime!( pub enum Runtime where Block = Block, NodeBlock = opaque::Block, UncheckedExtrinsic = UncheckedExtrinsic { / --snip-- / Balances: pallet_balances::{Pallet, Call, Storage, Config , Event }, /*** Add This Line ***/ Nicks: pallet_nicks::{Pallet, Call, Storage, Event<T>}, } ); ``` Check that the new dependencies resolve correctly by running the following command: bash cargo check -p node-template-runtime If there are no errors, you are ready to compile. Compile the node in release mode by running the following command: bash cargo build --release Start the blockchain node After your node compiles, you are ready to start the node that has been enhanced with nickname capabilities from the Nicks pallet and interact with it using the front-end template. To start the local Substrate node: Open a terminal shell, if necessary. Change to the root directory of the Substrate node template. Start the node in development mode by running the following command: ./target/release/node-template --dev In this case, the --dev option specifies that the node runs in developer mode using the predefined development chain specification. By default, this option also deletes all active data\u2014such as keys, the blockchain database, and networking information\u2014when you stop the node by pressing Control-c. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify your node is up and running successfully by reviewing the output displayed in the terminal. If the number after finalized is increasing in the console output, your blockchain is producing new blocks and reaching consensus about the state they describe. Keep the terminal that displays the node output open to continue. Start the front-end template Now that you have added a new pallet to your runtime, you can use the Substrate front-end template to interact with the node template and access the Nicks pallet. To start the front-end template: Open a new terminal shell on your computer. In the new terminal, change to the root directory where you installed the front-end template. Start the web server for the front-end template by running the following command: bash yarn start Open http://localhost:8000/ in a browser to view the front-end template. Set a nickname using the Nicks pallet After you start the front-end template, you can use it to interact with the Nicks pallet you just added to the runtime. To set a nickname for an account: Check the account selection list to verify that the Alice account is currently selected. In the Pallet Interactor component, verify that Extrinsic is selected. Select nicks from the list of pallets available to call. Select the setName dispatchable as the function to call from the nicks pallet. Type a name that is longer than the MinNickLength (8 characters) and no longer than the MaxNickLength (32 characters). Click Signed to execute the function. Observe the status of the call and the events emitted by the Nicks pallet. Query information for an account using the Nicks pallet Next, you can use Query capability to read the value of Alice's nickname from the runtime storage for the Nicks pallet. To return the information stored for Alice: In the Pallet Interactor component, select Query . Select nicks from the list of pallets available to query. Select the nameOf . Copy and paste the address for the alice account in the Account field, then click Query . The return type is a tuple that contains two values: The hex-encoded nickname for the Alice account. The amount that was reserved from Alice's account to secure the nickname. If you were to query the Nicks pallet for the nameOf for Bob's account, you would see the None value returned because Bob has not invoked the setName function to reserve a nickname. Explore additional functions This tutorial illustrates how to add a simple pallet to the runtime and demonstrates how to interact with the new pallet using the front-end template. In this case, you added the nicks pallet to the runtime and called the set_name function using the front-end template. The nicks pallet also provides two additional functions\u2014the clear_name function and the kill_name function\u2014that enable an account owner to remove the reserved name or a root-level user to forcibly remove an account name. You can learn about additional features\u2014such as the use of the Sudo pallet and origin accounts\u2014by exploring how these functions work. However, these features are beyond the intended scope of this tutorial. If you want to explore additional features exposed through the Nicks and Sudo pallets, see Next steps and select Specify the origin for invoking a function . Next steps There are several tutorials that can serve as next steps for learning more about Substrate development. Specify the origin for invoking a function explores calling functions using different originating accounts. Configure the contracts pallet demonstrates more complex configuration requirements by adding the Contracts pallet to the runtime. Create a custom pallet using macros References Basic Example Pallet provides detailed comments about what you can access within FRAME. The Cargo book introduces the Cargo package manager, including reference information for Cargo features and commands. Rust and WebAssembly Documentation highlights several resources for learning about Rust and WebAssembly.","title":"Add a simple pallet to the runtime"},{"location":"tutorials/07-add-a-pallet/#before-you-begin","text":"Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed the Build a local blockchain tutorial and have the Substrate node template installed locally. You are generally familiar with software development and using command-line interfaces. You are generally familiar with blockchains and smart contract platforms.","title":"Before you begin"},{"location":"tutorials/07-add-a-pallet/#tutorial-objectives","text":"By completing this tutorial, you will use the Nicks pallet to accomplish the following objectives: Learn how to update runtime dependencies to include a new pallet. Learn how to configure a pallet-specific Rust trait. See changes to the runtime by interacting with the new pallet using the front-end template.","title":"Tutorial objectives"},{"location":"tutorials/07-add-a-pallet/#add-the-nicks-pallet-dependencies","text":"Before you can use a new pallet, you must add some information about it to the configuration file that the compiler uses to build the runtime binary. For Rust programs, you use the Cargo.toml file to define the configuration settings and dependencies that determine what gets compiled in the resulting binary. Because the Substrate runtime compiles to both a native Rust binary that includes standard library functions and a WebAssembly (Wasm) binary that does not include the standard library, the Cargo.toml file controls two important pieces of information: The pallets to be imported as dependencies for the runtime, including the location and version of the pallets to import. The features in each pallet that should be enabled when compiling the native Rust binary. By enabling the standard ( std ) feature set from each pallet, you can compile the runtime to include functions, types, and primitives that would otherwise be missing when you build the WebAssembly binary. For information about adding dependencies in Cargo.toml files, see Dependencies in the Cargo documentation. For information about enabling and managing features from dependent packages, see Features in the Cargo documentation. To add the dependencies for the Nicks pallet to the runtime: Open a terminal shell and change to the root directory for the node template. Open the runtime/Cargo.toml configuration file in a text editor. Import the pallet-nicks crate to make it available to the node template runtime by adding it to the list of dependencies. toml [dependencies.pallet-nicks] default-features = false git = 'https://github.com/paritytech/substrate.git' tag = 'monthly-2021-10' version = '4.0.0-dev' The first line imports the pallet-nicks crate as a dependency. The second line specifies that the pallet features are not enabled by default when compiling the runtime. The third line specifies the repository location for retrieving the pallet-nicks crate. The fourth line specifies a commit tag using the monthly-YYYY-MM naming convention for retrieving the crate. The fifth line specifies a version identifier for the crate. Add the pallet-nicks/std features to the list of features to enable when compiling the runtime. toml [features] default = ['std'] std = [ ... 'pallet-aura/std', 'pallet-balances/std', 'pallet-nicks/std', # add this line ... ] This section specifies the default feature set to compile for this runtime is the std features set. When the runtime is compiled using the std feature set, the std features from all of the pallets listed as dependencies are enabled. For more detailed information about how the runtime is compiled as a native Rust binary with the standard library and as a WebAssembly binary using the no_std attribute, see Building the runtime . If you forget to update the features section in the Cargo.toml file, you might see cannot find function errors when you compile the runtime binary. Check that the new dependencies resolve correctly by running the following command: bash cargo check -p node-template-runtime","title":"Add the Nicks pallet dependencies"},{"location":"tutorials/07-add-a-pallet/#review-the-configuration-trait-for-the-pallet","text":"Every pallet has a Rust trait called Config . The Config trait is used to identify the parameters and types that the pallet needs to carry out its functions. Most of the pallet-specific code required to add a pallet is implemented using the Config trait. You can review what you to need to implement for any pallet by referring to its Rust documentation or the source code for the pallet. For example, to see what you need to implement for the nicks pallet, you can refer to the Rust documentation for pallet_nicks::Config or the trait definition in the Nicks pallet source code . For this tutorial, you can see that the Config trait in the nicks pallet declares the following types: pub trait Config: frame_system::Config { /// The overarching event type. type Event: From<Event<Self>> + IsType<<Self as frame_system::Config>::Event>; /// The currency trait. type Currency: ReservableCurrency<Self::AccountId>; /// Reservation fee. #[pallet::constant] type ReservationFee: Get<BalanceOf<Self>>; /// What to do with slashed funds. type Slashed: OnUnbalanced<NegativeImbalanceOf<Self>>; /// The origin account that can forcibly set or remove a name. Root can always do this. type ForceOrigin: EnsureOrigin<Self::Origin>; /// The minimum length for a name. #[pallet::constant] type MinLength: Get<u32>; /// The maximum length for a name. #[pallet::constant] type MaxLength: Get<u32>; } After you identify the types your pallet requires, you need to add code to the runtime to implement the Config trait. To learn how to implement the Config trait for a pallet, you can use the Balances pallet \u2014which is already implemented in the node template runtime\u2014as an example. To review the Config trait for the Balances pallet: Open the runtime/src/lib.rs file in a text editor. Locate the Balances pallet section. Note that the implementation for the Balances pallet consists of two parts: The parameter_types! block where constant values are defined. rust parameter_types! { // The u128 constant value 500 is aliased to a type named ExistentialDeposit. pub const ExistentialDeposit: u128 = 500; // A heuristic that is used for weight estimation. pub const MaxLocks: u32 = 50; } The impl block where the types and values defined by the Config interface are configured. rust impl pallet_balances::Config for Runtime { // The previously defined parameter_type is used as a configuration parameter. type MaxLocks = MaxLocks; // The \"Balance\" that appears after the equal sign is an alias for the u128 type. type Balance = Balance; // The empty value, (), is used to specify a no-op callback function. type DustRemoval = (); // The previously defined parameter_type is used as a configuration parameter. type ExistentialDeposit = ExistentialDeposit; // The FRAME runtime system is used to track the accounts that hold balances. type AccountStore = System; // Weight information is supplied to the Balances pallet by the node template runtime. // type WeightInfo = (); // old way type WeightInfo = pallet_balances::weights::SubstrateWeight<Runtime>; // The ubiquitous event type. type Event = Event; } As you can see in this example, the impl pallet_balances::Config block allows you to configure the types and parameters that are specified by the Balances pallet Config trait. For example, this impl block configures the Balances pallet to use the u128 type to track balances.","title":"Review the configuration trait for the pallet"},{"location":"tutorials/07-add-a-pallet/#implement-the-config-trait-for-the-pallet","text":"Now that you have seen an example of how the Config trait is implemented for the Balances pallet, you're ready to implement the Config trait for the Nicks pallet. To implement the nicks pallet in your runtime: Open the runtime/src/lib.rs file in a text editor. Locate the last line of the Balances code block. Add the following code block for the Nicks pallet: ```rust /// Add this code block to your template for Nicks: parameter_types! { // Choose a fee that incentivizes desireable behavior. pub const NickReservationFee: u128 = 100; pub const MinNickLength: u32 = 8; // Maximum bounds on storage are important to secure your chain. pub const MaxNickLength: u32 = 32; } impl pallet_nicks::Config for Runtime { // The Balances pallet implements the ReservableCurrency trait. // Balances is defined in construct_runtime! macro. See below. // https://docs.substrate.io/rustdocs/latest/pallet_balances/index.html#implementations-2 type Currency = Balances; // Use the NickReservationFee from the parameter_types block. type ReservationFee = NickReservationFee; // No action is taken when deposits are forfeited. type Slashed = (); // Configure the FRAME System Root origin as the Nick pallet admin. // https://docs.substrate.io/rustdocs/latest/frame_system/enum.RawOrigin.html#variant.Root type ForceOrigin = frame_system::EnsureRoot<AccountId>; // Use the MinNickLength from the parameter_types block. type MinLength = MinNickLength; // Use the MaxNickLength from the parameter_types block. type MaxLength = MaxNickLength; // The ubiquitous event type. type Event = Event; } ``` Identify the types that the Nicks pallet exposes. You can find a complete list of types in the construct_runtime! macro documentation. The Nicks pallet uses the following types: Storage because it uses the #[pallet::storage] macro. Event because it uses the #[pallet::events] macro. In the nicks pallet, the Event keyword is parameterized with respect to a type because at least one of the events defined by the Nicks pallet depends on a type that is configured with the Config configuration trait. Call because it has dispatchable functions in the #[pallet::call] macro. Pallet because it uses the #[pallet::pallet] macro. Add Nicks to the construct_runtime! macro. For example: ```rust construct_runtime!( pub enum Runtime where Block = Block, NodeBlock = opaque::Block, UncheckedExtrinsic = UncheckedExtrinsic { / --snip-- / Balances: pallet_balances::{Pallet, Call, Storage, Config , Event }, /*** Add This Line ***/ Nicks: pallet_nicks::{Pallet, Call, Storage, Event<T>}, } ); ``` Check that the new dependencies resolve correctly by running the following command: bash cargo check -p node-template-runtime If there are no errors, you are ready to compile. Compile the node in release mode by running the following command: bash cargo build --release","title":"Implement the Config trait for the pallet"},{"location":"tutorials/07-add-a-pallet/#start-the-blockchain-node","text":"After your node compiles, you are ready to start the node that has been enhanced with nickname capabilities from the Nicks pallet and interact with it using the front-end template. To start the local Substrate node: Open a terminal shell, if necessary. Change to the root directory of the Substrate node template. Start the node in development mode by running the following command: ./target/release/node-template --dev In this case, the --dev option specifies that the node runs in developer mode using the predefined development chain specification. By default, this option also deletes all active data\u2014such as keys, the blockchain database, and networking information\u2014when you stop the node by pressing Control-c. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify your node is up and running successfully by reviewing the output displayed in the terminal. If the number after finalized is increasing in the console output, your blockchain is producing new blocks and reaching consensus about the state they describe. Keep the terminal that displays the node output open to continue.","title":"Start the blockchain node"},{"location":"tutorials/07-add-a-pallet/#start-the-front-end-template","text":"Now that you have added a new pallet to your runtime, you can use the Substrate front-end template to interact with the node template and access the Nicks pallet. To start the front-end template: Open a new terminal shell on your computer. In the new terminal, change to the root directory where you installed the front-end template. Start the web server for the front-end template by running the following command: bash yarn start Open http://localhost:8000/ in a browser to view the front-end template.","title":"Start the front-end template"},{"location":"tutorials/07-add-a-pallet/#set-a-nickname-using-the-nicks-pallet","text":"After you start the front-end template, you can use it to interact with the Nicks pallet you just added to the runtime. To set a nickname for an account: Check the account selection list to verify that the Alice account is currently selected. In the Pallet Interactor component, verify that Extrinsic is selected. Select nicks from the list of pallets available to call. Select the setName dispatchable as the function to call from the nicks pallet. Type a name that is longer than the MinNickLength (8 characters) and no longer than the MaxNickLength (32 characters). Click Signed to execute the function. Observe the status of the call and the events emitted by the Nicks pallet.","title":"Set a nickname using the Nicks pallet"},{"location":"tutorials/07-add-a-pallet/#query-information-for-an-account-using-the-nicks-pallet","text":"Next, you can use Query capability to read the value of Alice's nickname from the runtime storage for the Nicks pallet. To return the information stored for Alice: In the Pallet Interactor component, select Query . Select nicks from the list of pallets available to query. Select the nameOf . Copy and paste the address for the alice account in the Account field, then click Query . The return type is a tuple that contains two values: The hex-encoded nickname for the Alice account. The amount that was reserved from Alice's account to secure the nickname. If you were to query the Nicks pallet for the nameOf for Bob's account, you would see the None value returned because Bob has not invoked the setName function to reserve a nickname.","title":"Query information for an account using the Nicks pallet"},{"location":"tutorials/07-add-a-pallet/#explore-additional-functions","text":"This tutorial illustrates how to add a simple pallet to the runtime and demonstrates how to interact with the new pallet using the front-end template. In this case, you added the nicks pallet to the runtime and called the set_name function using the front-end template. The nicks pallet also provides two additional functions\u2014the clear_name function and the kill_name function\u2014that enable an account owner to remove the reserved name or a root-level user to forcibly remove an account name. You can learn about additional features\u2014such as the use of the Sudo pallet and origin accounts\u2014by exploring how these functions work. However, these features are beyond the intended scope of this tutorial. If you want to explore additional features exposed through the Nicks and Sudo pallets, see Next steps and select Specify the origin for invoking a function .","title":"Explore additional functions"},{"location":"tutorials/07-add-a-pallet/#next-steps","text":"There are several tutorials that can serve as next steps for learning more about Substrate development. Specify the origin for invoking a function explores calling functions using different originating accounts. Configure the contracts pallet demonstrates more complex configuration requirements by adding the Contracts pallet to the runtime. Create a custom pallet using macros","title":"Next steps"},{"location":"tutorials/07-add-a-pallet/#references","text":"Basic Example Pallet provides detailed comments about what you can access within FRAME. The Cargo book introduces the Cargo package manager, including reference information for Cargo features and commands. Rust and WebAssembly Documentation highlights several resources for learning about Rust and WebAssembly.","title":"References"},{"location":"tutorials/custom-pallet/","text":"This tutorial illustrates how to create a custom pallet for a Substrate runtime using macros that are part of the FRAME development environment. For this tutorial, you'll build a simple proof of existence application. Proof of existence is an approach to validating the authenticity and ownership of a digital object by using the object information stored on the blockchain. Because the blockchain associates a timestamp and signature with the object, the blockchain record can be used to verify\u2014to serve as proof\u2014that a particular object existed at a specific date and time. It can also verify who the owner of a record was at that date and time. Digital objects and hashes Instead of individual files, the blockchain stores digital records using a cryptographic hash . The hash enables the blockchain to store files of arbitrary size efficiently by using a small and unique hash value. Because any change to a file would result in a different hash, users can prove the validity of a file by computing the hash and comparing that hash with the hash stored on chain. Digital objects and account signatures Blockchains use public keys to map digital identities to accounts that have private keys. The blockchain records the account you use to store the hash for a digital object as part of the transaction. Because the account information is stored as part of the transaction, the controller of the account can later prove ownership as the person who initially uploaded the file. How much time do you need to complete this tutorial? This tutorial requires compiling Rust code and takes approximately one to two hours to complete. Before you begin For this tutorial, you download and use working code. Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed the Build a local blockchain and have the node and front-end templates installed. You are generally familiar with software development and use command-line interfaces. By completing this tutorial, you will accomplish the following objectives: Learn the basic structure of a custom pallet. See examples of how Rust macros simplify the code you need to write. Start a blockchain node that contains a custom pallet. Add front-end code that exposes the proof-of-existence pallet. Design the application The proof of existence application exposes the following callable functions: create_claim() allows a user to claim the existence of a file by uploading a hash. revoke_claim() allows the current owner of a claim to revoke ownership. These functions only require you to store information about the proofs that have been claimed, and who made those claims. Build a custom pallet The Substrate node template has a FRAME-based runtime . FRAME is a library of code that allows you to build a Substrate runtime by composing modules called \"pallets\". You can think of the pallets as individual pieces of logic that define what your blockchain can do. Substrate provides you with a number of pre-built pallets for use in FRAME-based runtimes. This tutorial shows you how to create your own FRAME pallet to be included in your custom blockchain. Set up scaffolding for your pallet This tutorial demonstrates how to create a custom pallet from scratch. Therefore, the first step is to remove some files and content from the files in the node template directory. Open a terminal shell and navigate to the root directory for the node template. Change to the pallets/template/src directory by running the following command: bash cd pallets/template/src Remove the following files: bash benchmarking.rs mock.rs tests.rs Open the lib.rs file in a text editor. This file contains code that you can use as a template for a new pallet. You won't be using the template code in this tutorial. However, you can review the template code to see what it provides before you delete it. Delete all of the lines in the lib.rs file. Add the macro required to build both the native Rust binary ( std ) and the WebAssembly ( no_std ) binary. rust #![cfg_attr(not(feature = \"std\"), no_std)] All of the pallets used in a runtime must be set to compile with the no_std features. Add a skeleton set of pallet dependencies and macros that the custom pallet requires by copying the following code: ```rust // Re-export pallet items so that they can be accessed from the crate namespace. pub use pallet::*; #[frame_support::pallet] pub mod pallet { use frame_support::pallet_prelude:: ; use frame_system::pallet_prelude:: ; use sp_std::vec::Vec; // Step 3.1 will include this in Cargo.toml #[pallet::config] // <-- Step 2. code block will replace this. #[pallet::event] // <-- Step 3. code block will replace this. #[pallet::error] // <-- Step 4. code block will replace this. #[pallet::pallet] #[pallet::generate_store(pub(super) trait Store)] #[pallet::generate_storage_info] pub struct Pallet<T>(_); #[pallet::storage] // <-- Step 5. code block will replace this. #[pallet::hooks] impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {} #[pallet::call] // <-- Step 6. code block will replace this. } ``` You now have a framework that includes placeholders for events , errors , storage , and callable functions . Save your changes. Configure the pallet to emit events Every pallet has a Rust \"trait\" called Config . You use this trait to configure the settings that your specific pallet requires. For this tutorial, the configuration setting enables the pallet to emit events. To define the Config trait for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::config] line with the following code block: rust /// Configure the pallet by specifying the parameters and types on which it depends. #[pallet::config] pub trait Config: frame_system::Config { /// Because this pallet emits events, it depends on the runtime's definition of an event. type Event: From<Event<Self>> + IsType<<Self as frame_system::Config>::Event>; } Save your changes. Implement pallet events Now that you've configured the pallet to emit events, you are ready to define those events. As described in Design the application , the proof-of-existence pallet emits an event under the following conditions: When a new proof is added to the blockchain. When a proof is revoked. Each event also displays an AccountId to identify who triggered the event and the proof-of-existence data (as Vec<u8> ) that is being stored or removed. By convention, each event includes an array with descriptive names for its parameters. To implement the pallet events: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::event] line with the following code block: rust // Pallets use events to inform users when important changes are made. // Event documentation should end with an array that provides descriptive names for parameters. // https://docs.substrate.io/v3/runtime/events-and-errors #[pallet::event] #[pallet::generate_deposit(pub(super) fn deposit_event)] pub enum Event<T: Config> { /// Event emitted when a proof has been claimed. [who, claim] ClaimCreated(T::AccountId, Vec<u8>), /// Event emitted when a claim is revoked by the owner. [who, claim] ClaimRevoked(T::AccountId, Vec<u8>), } Save your changes. Include sp-std library You might notice that the proof-of-existence pallet uses the Vec<u8> type. This type is included in the std Rust library. However, you cannot use the std library for pallet development. Instead, the proof-of-existence pallet uses the sp-std crate to declare the Vec<u8> type under the mod pallet section: use sp_std::vec::Vec; The sp-std crate provides many standard Rust library functions modified to be compatible with no_std configuration. To use the sp-std crate, you must update the pallet dependencies in the Cargo.toml file. To add the sp-std crate to the pallet: Open the pallets/template/Cargo.toml file in a text editor. Add the following sp-std dependencies section to the file: toml [dependencies.sp-std] default-features = false git = 'https://github.com/paritytech/substrate.git' tag = 'monthly-2021-11-1' # or the latest monthly version = '4.0.0-dev' # or the latest version Add the sp-std crate to the list of features. toml [features] default = ['std'] std = [ # -- snip -- 'sp-std/std', ] Save your changes and close the file. Include pallet errors The events you defined indicate when calls to the pallet have completed successfully. Errors indicate when a call has failed, and why it has failed. For this tutorial, you define the following error conditions: An attempt to claim a proof that has already been claimed. An attempt to revoke a proof that does not exist. An attempt to revoke a proof that has been claimed by another account. To implement the errors for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::error] line with the following code block: rust #[pallet::error] pub enum Error<T> { /// The proof has already been claimed. ProofAlreadyClaimed, /// The proof does not exist, so it cannot be revoked. NoSuchProof, /// The proof is claimed by another account, so caller can't revoke it. NotProofOwner, } Save your changes. Implement a storage map for stored items To add a new proof to the blockchain, the proof-of-existence pallet requires a storage mechanism. To address this requirement, you can create a hash map that maps each proof to its owner and records the block number when the proof was made. To create this hash map, you can use the FRAME StorageMap trait. To implement storage for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::storage] line with the following code block: rust #[pallet::storage] pub(super) type Proofs<T: Config> = StorageMap<_, Blake2_128Concat, Vec<u8>, (T::AccountId, T::BlockNumber), ValueQuery>; Save your changes. Implement callable functions The proof-of-existence pallet exposes two callable functions to users: create_claim() allows a user to claim the existence of a file with a proof. revoke_claim() allows the owner of a claim to revoke the claim. These functions use the StorageMap to implement the following logic: If a proof has an owner and a block number, then it has been claimed. If a proof does not have an owner and a block number, then it is available to be claimed and written to storage. To implement this logic in the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::call] line with the following code block: ```rust // Dispatchable functions allow users to interact with the pallet and invoke state changes. // These functions materialize as \"extrinsics\", which are often compared to transactions. // Dispatchable functions must be annotated with a weight and must return a DispatchResult. #[pallet::call] impl Pallet { #[pallet::weight(1_000)] pub fn create_claim( origin: OriginFor , proof: Vec , ) -> DispatchResult { // Check that the extrinsic was signed and get the signer. // This function will return an error if the extrinsic is not signed. // https://docs.substrate.io/v3/runtime/origins let sender = ensure_signed(origin)?; // Verify that the specified proof has not already been claimed. ensure!(!Proofs::<T>::contains_key(&proof), Error::<T>::ProofAlreadyClaimed); // Get the block number from the FRAME System pallet. let current_block = <frame_system::Pallet<T>>::block_number(); // Store the proof with the sender and block number. Proofs::<T>::insert(&proof, (&sender, current_block)); // Emit an event that the claim was created. Self::deposit_event(Event::ClaimCreated(sender, proof)); Ok(()) } #[pallet::weight(10_000)] pub fn revoke_claim( origin: OriginFor<T>, proof: Vec<u8>, ) -> DispatchResult { // Check that the extrinsic was signed and get the signer. // This function will return an error if the extrinsic is not signed. // https://docs.substrate.io/v3/runtime/origins let sender = ensure_signed(origin)?; // Verify that the specified proof has been claimed. ensure!(Proofs::<T>::contains_key(&proof), Error::<T>::NoSuchProof); // Get owner of the claim. let (owner, _) = Proofs::<T>::get(&proof); // Verify that sender of the current call is the claim owner. ensure!(sender == owner, Error::<T>::NotProofOwner); // Remove claim from storage. Proofs::<T>::remove(&proof); // Emit an event that the claim was erased. Self::deposit_event(Event::ClaimRevoked(sender, proof)); Ok(()) } } ``` Save your changes and close the file. Check that your code compiles by running the following command: bash cargo check -p node-template-runtime There is a full Node Template solution here to use as a reference if you're stuck. Check the commit diff from the base template for the exact changes. /> Build the runtime with your new pallet After you've copied all of the parts of the proof-of-existence pallet into the pallets/template/lib.rs file, you are ready to compile and start the node. To compile and start the updated Substrate node: Open a terminal shell. Change to the root directory for the node template. Compile the node template by running the following command: bash cargo build --release Start the node in development mode by running the following command: bash ./target/release/node-template --dev The --dev option starts the node using the predefined development chain specification. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify the node produces blocks. Build a custom front-end component Now that you have a new blockchain running with the custom proof-of-existence pallet, let's add a custom React component to the front-end template. This React component enables you to expose the proof-of-existence capabilities and interact with the new pallet you created. Add your custom react component Open a new terminal shell on your computer, then change to the root directory where you installed the front-end template. Open the src/TemplateModule.js file in a text editor. Delete the entire contents of that file. Copy and paste the following code into the src/TemplateModule.js file: ```javascript // React and Semantic UI elements. import React, { useState, useEffect } from 'react' import { Form, Input, Grid, Message } from 'semantic-ui-react' // Pre-built Substrate front-end utilities for connecting to a node // and making a transaction. import { useSubstrate } from './substrate-lib' import { TxButton } from './substrate-lib/components' // Polkadot-JS utilities for hashing data. import { blake2AsHex } from '@polkadot/util-crypto' // Main Proof Of Existence component is exported. export function Main(props) { // Establish an API to talk to the Substrate node. const { api } = useSubstrate() // Get the selected user from the AccountSelector component. const { accountPair } = props // React hooks for all the state variables we track. // Learn more at: https://reactjs.org/docs/hooks-intro.html const [status, setStatus] = useState('') const [digest, setDigest] = useState('') const [owner, setOwner] = useState('') const [block, setBlock] = useState(0) // Our FileReader() which is accessible from our functions below. let fileReader // Takes our file, and creates a digest using the Blake2 256 hash function const bufferToDigest = () => { // Turns the file content to a hexadecimal representation. const content = Array.from(new Uint8Array(fileReader.result)) .map(b => b.toString(16).padStart(2, '0')) .join('') const hash = blake2AsHex(content, 256) setDigest(hash) } // Callback function for when a new file is selected. const handleFileChosen = file => { fileReader = new FileReader() fileReader.onloadend = bufferToDigest fileReader.readAsArrayBuffer(file) } // React hook to update the owner and block number information for a file useEffect(() => { let unsubscribe // Polkadot-JS API query to the `proofs` storage item in our pallet. // This is a subscription, so it will always get the latest value, // even if it changes. api.query.templateModule .proofs(digest, result => { // Our storage item returns a tuple, which is represented as an array. setOwner(result[0].toString()) setBlock(result[1].toNumber()) }) .then(unsub => { unsubscribe = unsub }) return () => unsubscribe && unsubscribe() // This tells the React hook to update whenever the file digest changes // (when a new file is chosen), or when the storage subscription says the // value of the storage item has updated. }, [digest, api.query.templateModule]) // We can say a file digest is claimed if the stored block number is not 0 function isClaimed() { return block !== 0 } // The actual UI elements which are returned from our component. return ( <Grid.Column> <h1>Proof of Existence</h1> {/* Show warning or success message if the file is or is not claimed. */} <Form success={!!digest && !isClaimed()} warning={isClaimed()}> <Form.Field> {/* File selector with a callback to `handleFileChosen`. */} <Input type=\"file\" id=\"file\" label=\"Your File\" onChange={e => handleFileChosen(e.target.files[0])} /> {/* Show this message if the file is available to be claimed */} <Message success header=\"File Digest Unclaimed\" content={digest} /> {/* Show this message if the file is already claimed. */} <Message warning header=\"File Digest Claimed\" list={[digest, `Owner: ${owner}`, `Block: ${block}`]} /> </Form.Field> {/* Buttons for interacting with the component. */} <Form.Field> {/* Button to create a claim. Only active if a file is selected, and not already claimed. Updates the `status`. */} <TxButton accountPair={accountPair} label={'Create Claim'} setStatus={setStatus} type=\"SIGNED-TX\" disabled={isClaimed() || !digest} attrs={{ palletRpc: 'templateModule', callable: 'createClaim', inputParams: [digest], paramFields: [true], }} /> {/* Button to revoke a claim. Only active if a file is selected, and is already claimed. Updates the `status`. */} <TxButton accountPair={accountPair} label=\"Revoke Claim\" setStatus={setStatus} type=\"SIGNED-TX\" disabled={!isClaimed() || owner !== accountPair.address} attrs={{ palletRpc: 'templateModule', callable: 'revokeClaim', inputParams: [digest], paramFields: [true], }} /> </Form.Field> {/* Status message about the transaction. */} <div style={{ overflowWrap: 'break-word' }}>{status}</div> </Form> </Grid.Column> ) } export default function TemplateModule(props) { const { api } = useSubstrate() return api.query.templateModule && api.query.templateModule.proofs ? ( ) : null } ``` Save your changes and close the file. Start the front-end template by running the following command: bash yarn start This will open up a new tab with the front-end serving at http://localhost:8000 . Submit a proof To test the proof-of-existence pallet using the new front-end component: Find the component at the bottom of the page. Click Choose file and select any file on your computer. The proof-of-existence pallet generates the hash for the selected file and displays it in the File Digest field. Because the file does not have an owner or block number, it is available to claim. Click Create Claim to take ownership of the file. Clicking Create Claim calls the create_claim function in the custom proof-of-existence pallet. The front-end component displays the file digest, account identifier, and block number for the completed transaction. Verify the claim is successful and a new claimCreated event appears in the Events component. The front-end component recognizes that the file is now claimed, and gives you the option to revoke the claim. Remember, only the owner can revoke the claim. If you select another user account, the revoke option is disabled. Next steps In this tutorial, you learned the basics of how to create a new custom pallet, including: How to add events, errors, storage, and callable functions to a custom pallet. How to integrate the custom pallet into the runtime. How to compile and start a node that includes your custom pallet. How you can add a React front-end component to expose the custom pallet to users. This tutorial covered the basics without diving too deeply into the code. However, there's much more you can do as you work toward building your own fully-customized blockchain. Custom pallets enable you to expose the features you want your blockchain to support. To learn more about what's possible by creating custom pallets, explore the FRAME documentation and the how-to guides . For a more challenging version of this tutorial, move onto the Substrate Kitties tutorial .","title":"Create a custom pallet using macros"},{"location":"tutorials/custom-pallet/#digital-objects-and-hashes","text":"Instead of individual files, the blockchain stores digital records using a cryptographic hash . The hash enables the blockchain to store files of arbitrary size efficiently by using a small and unique hash value. Because any change to a file would result in a different hash, users can prove the validity of a file by computing the hash and comparing that hash with the hash stored on chain.","title":"Digital objects and hashes"},{"location":"tutorials/custom-pallet/#digital-objects-and-account-signatures","text":"Blockchains use public keys to map digital identities to accounts that have private keys. The blockchain records the account you use to store the hash for a digital object as part of the transaction. Because the account information is stored as part of the transaction, the controller of the account can later prove ownership as the person who initially uploaded the file.","title":"Digital objects and account signatures"},{"location":"tutorials/custom-pallet/#how-much-time-do-you-need-to-complete-this-tutorial","text":"This tutorial requires compiling Rust code and takes approximately one to two hours to complete.","title":"How much time do you need to complete this tutorial?"},{"location":"tutorials/custom-pallet/#before-you-begin","text":"For this tutorial, you download and use working code. Before you begin, verify the following: You have configured your environment for Substrate development by installing Rust and the Rust toolchain . You have completed the Build a local blockchain and have the node and front-end templates installed. You are generally familiar with software development and use command-line interfaces. By completing this tutorial, you will accomplish the following objectives: Learn the basic structure of a custom pallet. See examples of how Rust macros simplify the code you need to write. Start a blockchain node that contains a custom pallet. Add front-end code that exposes the proof-of-existence pallet.","title":"Before you begin"},{"location":"tutorials/custom-pallet/#design-the-application","text":"The proof of existence application exposes the following callable functions: create_claim() allows a user to claim the existence of a file by uploading a hash. revoke_claim() allows the current owner of a claim to revoke ownership. These functions only require you to store information about the proofs that have been claimed, and who made those claims.","title":"Design the application"},{"location":"tutorials/custom-pallet/#build-a-custom-pallet","text":"The Substrate node template has a FRAME-based runtime . FRAME is a library of code that allows you to build a Substrate runtime by composing modules called \"pallets\". You can think of the pallets as individual pieces of logic that define what your blockchain can do. Substrate provides you with a number of pre-built pallets for use in FRAME-based runtimes. This tutorial shows you how to create your own FRAME pallet to be included in your custom blockchain.","title":"Build a custom pallet"},{"location":"tutorials/custom-pallet/#set-up-scaffolding-for-your-pallet","text":"This tutorial demonstrates how to create a custom pallet from scratch. Therefore, the first step is to remove some files and content from the files in the node template directory. Open a terminal shell and navigate to the root directory for the node template. Change to the pallets/template/src directory by running the following command: bash cd pallets/template/src Remove the following files: bash benchmarking.rs mock.rs tests.rs Open the lib.rs file in a text editor. This file contains code that you can use as a template for a new pallet. You won't be using the template code in this tutorial. However, you can review the template code to see what it provides before you delete it. Delete all of the lines in the lib.rs file. Add the macro required to build both the native Rust binary ( std ) and the WebAssembly ( no_std ) binary. rust #![cfg_attr(not(feature = \"std\"), no_std)] All of the pallets used in a runtime must be set to compile with the no_std features. Add a skeleton set of pallet dependencies and macros that the custom pallet requires by copying the following code: ```rust // Re-export pallet items so that they can be accessed from the crate namespace. pub use pallet::*; #[frame_support::pallet] pub mod pallet { use frame_support::pallet_prelude:: ; use frame_system::pallet_prelude:: ; use sp_std::vec::Vec; // Step 3.1 will include this in Cargo.toml #[pallet::config] // <-- Step 2. code block will replace this. #[pallet::event] // <-- Step 3. code block will replace this. #[pallet::error] // <-- Step 4. code block will replace this. #[pallet::pallet] #[pallet::generate_store(pub(super) trait Store)] #[pallet::generate_storage_info] pub struct Pallet<T>(_); #[pallet::storage] // <-- Step 5. code block will replace this. #[pallet::hooks] impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {} #[pallet::call] // <-- Step 6. code block will replace this. } ``` You now have a framework that includes placeholders for events , errors , storage , and callable functions . Save your changes.","title":"Set up scaffolding for your pallet"},{"location":"tutorials/custom-pallet/#configure-the-pallet-to-emit-events","text":"Every pallet has a Rust \"trait\" called Config . You use this trait to configure the settings that your specific pallet requires. For this tutorial, the configuration setting enables the pallet to emit events. To define the Config trait for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::config] line with the following code block: rust /// Configure the pallet by specifying the parameters and types on which it depends. #[pallet::config] pub trait Config: frame_system::Config { /// Because this pallet emits events, it depends on the runtime's definition of an event. type Event: From<Event<Self>> + IsType<<Self as frame_system::Config>::Event>; } Save your changes.","title":"Configure the pallet to emit events"},{"location":"tutorials/custom-pallet/#implement-pallet-events","text":"Now that you've configured the pallet to emit events, you are ready to define those events. As described in Design the application , the proof-of-existence pallet emits an event under the following conditions: When a new proof is added to the blockchain. When a proof is revoked. Each event also displays an AccountId to identify who triggered the event and the proof-of-existence data (as Vec<u8> ) that is being stored or removed. By convention, each event includes an array with descriptive names for its parameters. To implement the pallet events: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::event] line with the following code block: rust // Pallets use events to inform users when important changes are made. // Event documentation should end with an array that provides descriptive names for parameters. // https://docs.substrate.io/v3/runtime/events-and-errors #[pallet::event] #[pallet::generate_deposit(pub(super) fn deposit_event)] pub enum Event<T: Config> { /// Event emitted when a proof has been claimed. [who, claim] ClaimCreated(T::AccountId, Vec<u8>), /// Event emitted when a claim is revoked by the owner. [who, claim] ClaimRevoked(T::AccountId, Vec<u8>), } Save your changes.","title":"Implement pallet events"},{"location":"tutorials/custom-pallet/#include-sp-std-library","text":"You might notice that the proof-of-existence pallet uses the Vec<u8> type. This type is included in the std Rust library. However, you cannot use the std library for pallet development. Instead, the proof-of-existence pallet uses the sp-std crate to declare the Vec<u8> type under the mod pallet section: use sp_std::vec::Vec; The sp-std crate provides many standard Rust library functions modified to be compatible with no_std configuration. To use the sp-std crate, you must update the pallet dependencies in the Cargo.toml file. To add the sp-std crate to the pallet: Open the pallets/template/Cargo.toml file in a text editor. Add the following sp-std dependencies section to the file: toml [dependencies.sp-std] default-features = false git = 'https://github.com/paritytech/substrate.git' tag = 'monthly-2021-11-1' # or the latest monthly version = '4.0.0-dev' # or the latest version Add the sp-std crate to the list of features. toml [features] default = ['std'] std = [ # -- snip -- 'sp-std/std', ] Save your changes and close the file.","title":"Include sp-std library"},{"location":"tutorials/custom-pallet/#include-pallet-errors","text":"The events you defined indicate when calls to the pallet have completed successfully. Errors indicate when a call has failed, and why it has failed. For this tutorial, you define the following error conditions: An attempt to claim a proof that has already been claimed. An attempt to revoke a proof that does not exist. An attempt to revoke a proof that has been claimed by another account. To implement the errors for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::error] line with the following code block: rust #[pallet::error] pub enum Error<T> { /// The proof has already been claimed. ProofAlreadyClaimed, /// The proof does not exist, so it cannot be revoked. NoSuchProof, /// The proof is claimed by another account, so caller can't revoke it. NotProofOwner, } Save your changes.","title":"Include pallet errors"},{"location":"tutorials/custom-pallet/#implement-a-storage-map-for-stored-items","text":"To add a new proof to the blockchain, the proof-of-existence pallet requires a storage mechanism. To address this requirement, you can create a hash map that maps each proof to its owner and records the block number when the proof was made. To create this hash map, you can use the FRAME StorageMap trait. To implement storage for the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::storage] line with the following code block: rust #[pallet::storage] pub(super) type Proofs<T: Config> = StorageMap<_, Blake2_128Concat, Vec<u8>, (T::AccountId, T::BlockNumber), ValueQuery>; Save your changes.","title":"Implement a storage map for stored items"},{"location":"tutorials/custom-pallet/#implement-callable-functions","text":"The proof-of-existence pallet exposes two callable functions to users: create_claim() allows a user to claim the existence of a file with a proof. revoke_claim() allows the owner of a claim to revoke the claim. These functions use the StorageMap to implement the following logic: If a proof has an owner and a block number, then it has been claimed. If a proof does not have an owner and a block number, then it is available to be claimed and written to storage. To implement this logic in the proof-of-existence pallet: Open the pallets/template/src/lib.rs file in a text editor. Replace the #[pallet::call] line with the following code block: ```rust // Dispatchable functions allow users to interact with the pallet and invoke state changes. // These functions materialize as \"extrinsics\", which are often compared to transactions. // Dispatchable functions must be annotated with a weight and must return a DispatchResult. #[pallet::call] impl Pallet { #[pallet::weight(1_000)] pub fn create_claim( origin: OriginFor , proof: Vec , ) -> DispatchResult { // Check that the extrinsic was signed and get the signer. // This function will return an error if the extrinsic is not signed. // https://docs.substrate.io/v3/runtime/origins let sender = ensure_signed(origin)?; // Verify that the specified proof has not already been claimed. ensure!(!Proofs::<T>::contains_key(&proof), Error::<T>::ProofAlreadyClaimed); // Get the block number from the FRAME System pallet. let current_block = <frame_system::Pallet<T>>::block_number(); // Store the proof with the sender and block number. Proofs::<T>::insert(&proof, (&sender, current_block)); // Emit an event that the claim was created. Self::deposit_event(Event::ClaimCreated(sender, proof)); Ok(()) } #[pallet::weight(10_000)] pub fn revoke_claim( origin: OriginFor<T>, proof: Vec<u8>, ) -> DispatchResult { // Check that the extrinsic was signed and get the signer. // This function will return an error if the extrinsic is not signed. // https://docs.substrate.io/v3/runtime/origins let sender = ensure_signed(origin)?; // Verify that the specified proof has been claimed. ensure!(Proofs::<T>::contains_key(&proof), Error::<T>::NoSuchProof); // Get owner of the claim. let (owner, _) = Proofs::<T>::get(&proof); // Verify that sender of the current call is the claim owner. ensure!(sender == owner, Error::<T>::NotProofOwner); // Remove claim from storage. Proofs::<T>::remove(&proof); // Emit an event that the claim was erased. Self::deposit_event(Event::ClaimRevoked(sender, proof)); Ok(()) } } ``` Save your changes and close the file. Check that your code compiles by running the following command: bash cargo check -p node-template-runtime There is a full Node Template solution here to use as a reference if you're stuck. Check the commit diff from the base template for the exact changes. />","title":"Implement callable functions"},{"location":"tutorials/custom-pallet/#build-the-runtime-with-your-new-pallet","text":"After you've copied all of the parts of the proof-of-existence pallet into the pallets/template/lib.rs file, you are ready to compile and start the node. To compile and start the updated Substrate node: Open a terminal shell. Change to the root directory for the node template. Compile the node template by running the following command: bash cargo build --release Start the node in development mode by running the following command: bash ./target/release/node-template --dev The --dev option starts the node using the predefined development chain specification. Using the --dev option ensures that you have a clean working state any time you stop and restart the node. Verify the node produces blocks.","title":"Build the runtime with your new pallet"},{"location":"tutorials/custom-pallet/#build-a-custom-front-end-component","text":"Now that you have a new blockchain running with the custom proof-of-existence pallet, let's add a custom React component to the front-end template. This React component enables you to expose the proof-of-existence capabilities and interact with the new pallet you created.","title":"Build a custom front-end component"},{"location":"tutorials/custom-pallet/#add-your-custom-react-component","text":"Open a new terminal shell on your computer, then change to the root directory where you installed the front-end template. Open the src/TemplateModule.js file in a text editor. Delete the entire contents of that file. Copy and paste the following code into the src/TemplateModule.js file: ```javascript // React and Semantic UI elements. import React, { useState, useEffect } from 'react' import { Form, Input, Grid, Message } from 'semantic-ui-react' // Pre-built Substrate front-end utilities for connecting to a node // and making a transaction. import { useSubstrate } from './substrate-lib' import { TxButton } from './substrate-lib/components' // Polkadot-JS utilities for hashing data. import { blake2AsHex } from '@polkadot/util-crypto' // Main Proof Of Existence component is exported. export function Main(props) { // Establish an API to talk to the Substrate node. const { api } = useSubstrate() // Get the selected user from the AccountSelector component. const { accountPair } = props // React hooks for all the state variables we track. // Learn more at: https://reactjs.org/docs/hooks-intro.html const [status, setStatus] = useState('') const [digest, setDigest] = useState('') const [owner, setOwner] = useState('') const [block, setBlock] = useState(0) // Our FileReader() which is accessible from our functions below. let fileReader // Takes our file, and creates a digest using the Blake2 256 hash function const bufferToDigest = () => { // Turns the file content to a hexadecimal representation. const content = Array.from(new Uint8Array(fileReader.result)) .map(b => b.toString(16).padStart(2, '0')) .join('') const hash = blake2AsHex(content, 256) setDigest(hash) } // Callback function for when a new file is selected. const handleFileChosen = file => { fileReader = new FileReader() fileReader.onloadend = bufferToDigest fileReader.readAsArrayBuffer(file) } // React hook to update the owner and block number information for a file useEffect(() => { let unsubscribe // Polkadot-JS API query to the `proofs` storage item in our pallet. // This is a subscription, so it will always get the latest value, // even if it changes. api.query.templateModule .proofs(digest, result => { // Our storage item returns a tuple, which is represented as an array. setOwner(result[0].toString()) setBlock(result[1].toNumber()) }) .then(unsub => { unsubscribe = unsub }) return () => unsubscribe && unsubscribe() // This tells the React hook to update whenever the file digest changes // (when a new file is chosen), or when the storage subscription says the // value of the storage item has updated. }, [digest, api.query.templateModule]) // We can say a file digest is claimed if the stored block number is not 0 function isClaimed() { return block !== 0 } // The actual UI elements which are returned from our component. return ( <Grid.Column> <h1>Proof of Existence</h1> {/* Show warning or success message if the file is or is not claimed. */} <Form success={!!digest && !isClaimed()} warning={isClaimed()}> <Form.Field> {/* File selector with a callback to `handleFileChosen`. */} <Input type=\"file\" id=\"file\" label=\"Your File\" onChange={e => handleFileChosen(e.target.files[0])} /> {/* Show this message if the file is available to be claimed */} <Message success header=\"File Digest Unclaimed\" content={digest} /> {/* Show this message if the file is already claimed. */} <Message warning header=\"File Digest Claimed\" list={[digest, `Owner: ${owner}`, `Block: ${block}`]} /> </Form.Field> {/* Buttons for interacting with the component. */} <Form.Field> {/* Button to create a claim. Only active if a file is selected, and not already claimed. Updates the `status`. */} <TxButton accountPair={accountPair} label={'Create Claim'} setStatus={setStatus} type=\"SIGNED-TX\" disabled={isClaimed() || !digest} attrs={{ palletRpc: 'templateModule', callable: 'createClaim', inputParams: [digest], paramFields: [true], }} /> {/* Button to revoke a claim. Only active if a file is selected, and is already claimed. Updates the `status`. */} <TxButton accountPair={accountPair} label=\"Revoke Claim\" setStatus={setStatus} type=\"SIGNED-TX\" disabled={!isClaimed() || owner !== accountPair.address} attrs={{ palletRpc: 'templateModule', callable: 'revokeClaim', inputParams: [digest], paramFields: [true], }} /> </Form.Field> {/* Status message about the transaction. */} <div style={{ overflowWrap: 'break-word' }}>{status}</div> </Form> </Grid.Column> ) } export default function TemplateModule(props) { const { api } = useSubstrate() return api.query.templateModule && api.query.templateModule.proofs ? ( ) : null } ``` Save your changes and close the file. Start the front-end template by running the following command: bash yarn start This will open up a new tab with the front-end serving at http://localhost:8000 .","title":"Add your custom react component"},{"location":"tutorials/custom-pallet/#submit-a-proof","text":"To test the proof-of-existence pallet using the new front-end component: Find the component at the bottom of the page. Click Choose file and select any file on your computer. The proof-of-existence pallet generates the hash for the selected file and displays it in the File Digest field. Because the file does not have an owner or block number, it is available to claim. Click Create Claim to take ownership of the file. Clicking Create Claim calls the create_claim function in the custom proof-of-existence pallet. The front-end component displays the file digest, account identifier, and block number for the completed transaction. Verify the claim is successful and a new claimCreated event appears in the Events component. The front-end component recognizes that the file is now claimed, and gives you the option to revoke the claim. Remember, only the owner can revoke the claim. If you select another user account, the revoke option is disabled.","title":"Submit a proof"},{"location":"tutorials/custom-pallet/#next-steps","text":"In this tutorial, you learned the basics of how to create a new custom pallet, including: How to add events, errors, storage, and callable functions to a custom pallet. How to integrate the custom pallet into the runtime. How to compile and start a node that includes your custom pallet. How you can add a React front-end component to expose the custom pallet to users. This tutorial covered the basics without diving too deeply into the code. However, there's much more you can do as you work toward building your own fully-customized blockchain. Custom pallets enable you to expose the features you want your blockchain to support. To learn more about what's possible by creating custom pallets, explore the FRAME documentation and the how-to guides . For a more challenging version of this tutorial, move onto the Substrate Kitties tutorial .","title":"Next steps"}]}